{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f34b547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Candle: 0.009393820578962441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling:   0%|          | 0/40 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\multiprocessing\\pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 149\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# ================================\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# 5) TSFRESH EXTRACTION FOR SELECT SIGNALS\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# ================================\u001b[39;00m\n\u001b[0;32m    147\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 149\u001b[0m X1  \u001b[38;5;241m=\u001b[39m \u001b[43mextract_rolling_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWILLR_15\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m X2  \u001b[38;5;241m=\u001b[39m extract_rolling_features(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWILLR_42\u001b[39m\u001b[38;5;124m'\u001b[39m,  symbol)\n\u001b[0;32m    151\u001b[0m X3  \u001b[38;5;241m=\u001b[39m extract_rolling_features(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRSI_14\u001b[39m\u001b[38;5;124m'\u001b[39m,    symbol)\n",
      "Cell \u001b[1;32mIn[5], line 62\u001b[0m, in \u001b[0;36mextract_rolling_features\u001b[1;34m(df, signal, symbol, max_shift, min_shift)\u001b[0m\n\u001b[0;32m     59\u001b[0m df_melted \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, signal]]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     60\u001b[0m df_melted[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m symbol\n\u001b[1;32m---> 62\u001b[0m df_rolled \u001b[38;5;241m=\u001b[39m \u001b[43mroll_time_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_melted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSymbols\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_sort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_timeshift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_shift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_timeshift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_shift\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m X \u001b[38;5;241m=\u001b[39m extract_features(\n\u001b[0;32m     70\u001b[0m     df_rolled\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbols\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     71\u001b[0m     column_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m     show_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     76\u001b[0m )\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Re-align the index (TSFresh creates a multi-index)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\site-packages\\tsfresh\\utilities\\dataframe_functions.py:568\u001b[0m, in \u001b[0;36mroll_time_series\u001b[1;34m(df_or_dict, column_id, column_sort, column_kind, rolling_direction, max_timeshift, min_timeshift, chunksize, n_jobs, show_warnings, disable_progressbar, distributor)\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe passed distributor is not an DistributorBaseClass object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    559\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrouped_data\u001b[39m\u001b[38;5;124m\"\u001b[39m: grouped_data,\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrolling_direction\u001b[39m\u001b[38;5;124m\"\u001b[39m: rolling_direction,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: column_id,\n\u001b[0;32m    566\u001b[0m }\n\u001b[1;32m--> 568\u001b[0m shifted_chunks \u001b[38;5;241m=\u001b[39m \u001b[43mdistributor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_roll_out_time_series\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_of_shifts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunction_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m distributor\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    577\u001b[0m df_shift \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(shifted_chunks, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\site-packages\\tsfresh\\utilities\\distribution.py:241\u001b[0m, in \u001b[0;36mIterableDistributorBaseClass.map_reduce\u001b[1;34m(self, map_function, data, function_kwargs, chunk_size, data_length)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute(\n\u001b[0;32m    237\u001b[0m             _function_with_partly_reduce, chunk_generator, map_kwargs\n\u001b[0;32m    238\u001b[0m         ),\n\u001b[0;32m    239\u001b[0m     )\n\u001b[1;32m--> 241\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\multiprocessing\\pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 861\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    863\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import MetaTrader5 as mt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from talipp.indicators import EMA, SMA, Stoch, DPO\n",
    "from joblib import dump\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score, confusion_matrix, classification_report,\n",
    "    recall_score, accuracy_score, f1_score, roc_auc_score\n",
    ")\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, impute\n",
    "from own_functions import label_data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Hardcoded credentials - as requested\n",
    "login = 51708234\n",
    "password = \"4bM&wuVJcBTnjV\"\n",
    "server = \"ICMarketsEU-Demo\"\n",
    "\n",
    "mt.initialize()\n",
    "mt.login(login, password, server)\n",
    "\n",
    "symbol = \"EURUSD\"\n",
    "timeframe = mt.TIMEFRAME_D1\n",
    "start_date = datetime(2010, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "\n",
    "# For your risk calculations\n",
    "StopLoss = 1\n",
    "TakeProfit = 1\n",
    "BreakEvenRatio = StopLoss / (StopLoss + TakeProfit)\n",
    "\n",
    "def add_rolling_features(df, window):\n",
    "    df['rolling_mean_open'] = df['open'].rolling(window=window).mean()\n",
    "    df['rolling_std_open']  = df['open'].rolling(window=window).std()\n",
    "    df['rolling_mean_close'] = df['close'].rolling(window=window).mean()\n",
    "    df['rolling_std_close']  = df['close'].rolling(window=window).std()\n",
    "    df['rolling_mean_high']  = df['high'].rolling(window=window).mean()\n",
    "    df['rolling_std_high']   = df['high'].rolling(window=window).std()\n",
    "    df['rolling_mean_low']   = df['low'].rolling(window=window).mean()\n",
    "    df['rolling_std_low']    = df['low'].rolling(window=window).std()\n",
    "    return df\n",
    "\n",
    "def add_lag_features(df, lags):\n",
    "    for lag in lags:\n",
    "        df[f'open_lag_{lag}']  = df['open'].shift(lag)\n",
    "        df[f'close_lag_{lag}'] = df['close'].shift(lag)\n",
    "        df[f'high_lag_{lag}']  = df['high'].shift(lag)\n",
    "        df[f'low_lag_{lag}']   = df['low'].shift(lag)\n",
    "    return df\n",
    "\n",
    "def extract_rolling_features(df, signal, symbol, max_shift=20, min_shift=5):\n",
    "    # Prepare for TSFresh\n",
    "    df_melted = df[['time', signal]].copy()\n",
    "    df_melted[\"Symbols\"] = symbol\n",
    "    \n",
    "    df_rolled = roll_time_series(\n",
    "        df_melted,\n",
    "        column_id=\"Symbols\",\n",
    "        column_sort=\"time\",\n",
    "        max_timeshift=max_shift,\n",
    "        min_timeshift=min_shift\n",
    "    )\n",
    "    X = extract_features(\n",
    "        df_rolled.drop(\"Symbols\", axis=1),\n",
    "        column_id=\"id\", \n",
    "        column_sort=\"time\", \n",
    "        column_value=signal,\n",
    "        impute_function=impute, \n",
    "        show_warnings=False\n",
    "    )\n",
    "    # Re-align the index (TSFresh creates a multi-index)\n",
    "    X = X.set_index(X.index.map(lambda x: x[1]), drop=True)\n",
    "    X.index.name = \"time\"\n",
    "    return X.dropna()\n",
    "\n",
    "\n",
    "\n",
    "ohlc_data = pd.DataFrame(mt.copy_rates_range(symbol, timeframe, start_date, end_date))\n",
    "ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "df = ohlc_data[['time', 'open', 'high', 'low', 'close']].copy()\n",
    "\n",
    "df['EMA_9']  = talib.EMA(df['close'], timeperiod=9)\n",
    "df['EMA_21'] = talib.EMA(df['close'], timeperiod=21)\n",
    "df['EMA_50'] = talib.EMA(df['close'], timeperiod=50)\n",
    "\n",
    "df['RSI_9']  = talib.RSI(df['close'], timeperiod=9)\n",
    "df['RSI_14'] = talib.RSI(df['close'], timeperiod=14)\n",
    "df['RSI_21'] = talib.RSI(df['close'], timeperiod=21)\n",
    "\n",
    "df['WILLR_15']  = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=15)\n",
    "df['WILLR_23']  = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=23)\n",
    "df['WILLR_42']  = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=42)\n",
    "df['WILLR_145'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=145)\n",
    "\n",
    "df['SAR'] = talib.SAR(df['high'], df['low'], acceleration=0.02, maximum=0.2)\n",
    "\n",
    "df['BB_upper'], df['BB_middle'], df['BB_lower'] = talib.BBANDS(\n",
    "    df['close'], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0\n",
    ")\n",
    "df['BB_width'] = df['BB_upper'] - df['BB_lower']\n",
    "\n",
    "df['MACD'], df['MACD_signal'], df['MACD_hist'] = talib.MACD(\n",
    "    df['close'], fastperiod=12, slowperiod=26, signalperiod=9\n",
    ")\n",
    "df['CCI_14'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "\n",
    "# Example custom rolling features\n",
    "df = add_rolling_features(df, window=5)\n",
    "\n",
    "# Drop early NaNs introduced by rolling calculations\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ================================\n",
    "# 3) LABEL INITIALIZATION\n",
    "# ================================\n",
    "df['b_flag'] = 0\n",
    "df['s_flag'] = 0\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "csv_file_path = 'EURUSD_D1_2010to2023.csv'  # Specify your desired path\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# ================================\n",
    "# 4) LABEL THE DATA (STOPLOSS/TAKEPROFIT)\n",
    "# ================================\n",
    "label_data(df, [StopLoss], [TakeProfit], 80, symbol, print_data=False)\n",
    "\n",
    "\n",
    "\n",
    "# For Open-of-Day approach, we do NOT shift b_flag by -1\n",
    "df.drop(columns=['s_flag'], inplace=True)\n",
    "\n",
    "# Optionally add lag features from the same day\n",
    "df = add_lag_features(df, lags=[1, 2, 3, 4, 5])\n",
    "\n",
    "# ================================\n",
    "# 5) TSFRESH EXTRACTION FOR SELECT SIGNALS\n",
    "# ================================\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "X1  = extract_rolling_features(df, 'WILLR_15',  symbol)\n",
    "X2  = extract_rolling_features(df, 'WILLR_42',  symbol)\n",
    "X3  = extract_rolling_features(df, 'RSI_14',    symbol)\n",
    "X4  = extract_rolling_features(df, 'MACD_hist', symbol)\n",
    "X5  = extract_rolling_features(df, 'EMA_9',     symbol)\n",
    "X6  = extract_rolling_features(df, 'EMA_21',    symbol)\n",
    "X7  = extract_rolling_features(df, 'EMA_50',    symbol)\n",
    "X9  = extract_rolling_features(df, 'RSI_9',     symbol)\n",
    "X10 = extract_rolling_features(df, 'RSI_21',    symbol)\n",
    "X11 = extract_rolling_features(df, 'WILLR_23',  symbol)\n",
    "X12 = extract_rolling_features(df, 'WILLR_145', symbol)\n",
    "X13 = extract_rolling_features(df, 'SAR',       symbol)\n",
    "X14 = extract_rolling_features(df, 'BB_width',  symbol)\n",
    "X15 = extract_rolling_features(df, 'MACD_signal', symbol)\n",
    "X16 = extract_rolling_features(df, 'CCI_14',    symbol)\n",
    "\n",
    "X_tsfresh = pd.concat(\n",
    "    [X1, X2, X3, X4, X5, X6, X7, X9, X10, X11, X12, X13, X14, X15, X16],\n",
    "    axis=1, join='inner'\n",
    ").dropna()\n",
    "\n",
    "# ================================\n",
    "# 6) MERGE TSFRESH FEATURES WITH MAIN DF\n",
    "# ================================\n",
    "df = df.set_index(pd.to_datetime(df['time']))\n",
    "df.drop(columns=['time'], inplace=True)\n",
    "\n",
    "X = X_tsfresh[X_tsfresh.index.isin(df.index)]\n",
    "X = pd.concat([df, X], axis=1, join='inner')\n",
    "\n",
    "# Now X has open, high, low, close, indicators, b_flag, plus TSFresh features.\n",
    "\n",
    "# ================================\n",
    "# 7) SHIFT FEATURES FOR OPEN-OF-DAY\n",
    "# ================================\n",
    "X_df = X.copy()\n",
    "\n",
    "target_col = 'b_flag'\n",
    "all_cols  = [c for c in X_df.columns if c != target_col]\n",
    "X_df = X_df[all_cols + [target_col]]\n",
    "\n",
    "# SHIFT all features (except b_flag) by +1 row\n",
    "feature_cols = all_cols\n",
    "X_df[feature_cols] = X_df[feature_cols].shift(1)\n",
    "\n",
    "# Drop rows with NaNs from shifting\n",
    "X_df.dropna(inplace=True)\n",
    "\n",
    "# ================================\n",
    "# 8) TSFRESH FEATURE SELECTION\n",
    "# (Apply it to the SHIFTED DataFrame)\n",
    "# ================================\n",
    "X_df = select_features(X_df, X_df[target_col], fdr_level=0.2)\n",
    "X_df = X_df[[col for col in X_df if col != target_col] + [target_col]]\n",
    "\n",
    "# ================================\n",
    "# 9) CORRELATION FILTER\n",
    "# ================================\n",
    "corr_matrix = X_df.corr().abs()\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "high_corr_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.9)]\n",
    "\n",
    "# Avoid removing the target_col if it appears in high_corr_features\n",
    "high_corr_features = [f for f in high_corr_features if f != target_col]\n",
    "\n",
    "X_df.drop(columns=high_corr_features, inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a537e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before PCA: 70\n",
      "Number of features after PCA: 15\n",
      "Confusion Matrix:\n",
      "[[187  29]\n",
      " [126  29]]\n",
      "Accuracy: 0.5822\n",
      "Precision: 0.5\n",
      "Recall: 0.1871\n",
      "F1 Score: 0.2723\n",
      "ROC-AUC: 0.513\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       216\n",
      "           1       0.50      0.19      0.27       155\n",
      "\n",
      "    accuracy                           0.58       371\n",
      "   macro avg       0.55      0.53      0.49       371\n",
      "weighted avg       0.56      0.58      0.53       371\n",
      "\n",
      "WIN/LOSS-Diff: 0.0 %\n",
      "False Positives: 29\n",
      "True Positives: 29\n",
      "Ratio total: 50.0\n",
      "BreakEvenRatio: 0.5\n",
      "_______________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================================\n",
    "# 10) TRAIN / TEST SPLIT\n",
    "# ================================\n",
    "split = int(0.90 * len(X_df))\n",
    "train_data = X_df.iloc[:split].copy()\n",
    "test_data  = X_df.iloc[split:].copy()\n",
    "\n",
    "x_train = train_data.drop(columns=[target_col]).values\n",
    "y_train = train_data[target_col].values\n",
    "x_test  = test_data.drop(columns=[target_col]).values\n",
    "y_test  = test_data[target_col].values\n",
    "\n",
    "# ================================\n",
    "# 11) SCALE FEATURES\n",
    "# ================================\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test  = scaler.transform(x_test)\n",
    "\n",
    "print(\"Number of features before PCA:\", x_train.shape[1])\n",
    "\n",
    "# ================================\n",
    "# 12) PCA\n",
    "# ================================\n",
    "pca_components = 15\n",
    "pca = PCA(n_components=pca_components, svd_solver='randomized', random_state=0)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test  = pca.transform(x_test)\n",
    "\n",
    "print(\"Number of features after PCA:\", x_train.shape[1])\n",
    "\n",
    "# ================================\n",
    "# 13) MODEL TRAINING\n",
    "# ================================\n",
    "n_estimators = 50\n",
    "class_weight = {0: 1, 1: 15}\n",
    "max_features = 'sqrt'\n",
    "random_state = 42\n",
    "\n",
    "rf_classifier_mt = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    class_weight=class_weight,\n",
    "    max_features=max_features,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "rf_classifier_mt.fit(x_train, y_train)\n",
    "y_pred_proba = rf_classifier_mt.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# ================================\n",
    "# 14) EVALUATION\n",
    "# ================================\n",
    "threshold = 0.6  # example threshold\n",
    "y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "false_positives = conf_matrix[0][1]\n",
    "true_positives  = conf_matrix[1][1]\n",
    "\n",
    "precision = precision_score(y_test, y_pred) if (false_positives + true_positives) > 0 else 0\n",
    "recall    = recall_score(y_test, y_pred)\n",
    "f1        = f1_score(y_test, y_pred)\n",
    "accuracy  = accuracy_score(y_test, y_pred)\n",
    "roc_auc   = roc_auc_score(y_test, y_pred_proba)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print('Accuracy:', round(accuracy, 4))\n",
    "print('Precision:', round(precision, 4))\n",
    "print('Recall:', round(recall, 4))\n",
    "print('F1 Score:', round(f1, 4))\n",
    "print('ROC-AUC:', round(roc_auc, 4))\n",
    "print('Classification Report:\\n', classification_rep)\n",
    "print('WIN/LOSS-Diff:', round(100 * (precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', false_positives)\n",
    "print('True Positives:', true_positives)\n",
    "if (false_positives + true_positives) > 0:\n",
    "    ratio = 100 * true_positives / (false_positives + true_positives)\n",
    "    print('Ratio total:', round(ratio, 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('_______________________________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b814e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from talipp.indicators import EMA, SMA, Stoch, DPO\n",
    "from joblib import dump\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, confusion_matrix, classification_report, recall_score, accuracy_score, f1_score, roc_auc_score\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, impute\n",
    "from own_functions import label_data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Hardcoded credentials - as requested\n",
    "login = 51708234\n",
    "password = \"4bM&wuVJcBTnjV\"\n",
    "server = \"ICMarketsEU-Demo\"\n",
    "\n",
    "mt.initialize()\n",
    "mt.login(login, password, server)\n",
    "\n",
    "symbol = \"EURUSD\"\n",
    "timeframe = mt.TIMEFRAME_D1\n",
    "start_date = datetime(2010, 1, 1)\n",
    "end_date = datetime(2024, 11, 10)\n",
    "StopLoss = 1\n",
    "TakeProfit = 1\n",
    "BreakEvenRatio = StopLoss / (StopLoss + TakeProfit)\n",
    "\n",
    "def add_rolling_features(df, window):\n",
    "    df['rolling_mean_open'] = df['open'].rolling(window=window).mean()\n",
    "    df['rolling_std_open'] = df['open'].rolling(window=window).std()\n",
    "    df['rolling_mean_close'] = df['close'].rolling(window=window).mean()\n",
    "    df['rolling_std_close'] = df['close'].rolling(window=window).std()\n",
    "    df['rolling_mean_high'] = df['high'].rolling(window=window).mean()\n",
    "    df['rolling_std_high'] = df['high'].rolling(window=window).std()\n",
    "    df['rolling_mean_low'] = df['low'].rolling(window=window).mean()\n",
    "    df['rolling_std_low'] = df['low'].rolling(window=window).std()\n",
    "    return df\n",
    "\n",
    "def add_lag_features(df, lags):\n",
    "    for lag in lags:\n",
    "        df[f'open_lag_{lag}'] = df['open'].shift(lag)\n",
    "        df[f'close_lag_{lag}'] = df['close'].shift(lag)\n",
    "        df[f'high_lag_{lag}'] = df['high'].shift(lag)\n",
    "        df[f'low_lag_{lag}'] = df['low'].shift(lag)\n",
    "    return df\n",
    "\n",
    "def extract_rolling_features(df, signal, symbol, max_shift=20, min_shift=5):\n",
    "    df_melted = df[['time', signal]].copy()\n",
    "    df_melted[\"Symbols\"] = symbol\n",
    "    df_rolled = roll_time_series(df_melted, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                                 max_timeshift=max_shift, min_timeshift=min_shift)\n",
    "    X = extract_features(df_rolled.drop(\"Symbols\", axis=1),\n",
    "                         column_id=\"id\", column_sort=\"time\", column_value=signal,\n",
    "                         impute_function=impute, show_warnings=False)\n",
    "    X = X.set_index(X.index.map(lambda x: x[1]), drop=True)\n",
    "    X.index.name = \"time\"\n",
    "    return X.dropna()\n",
    "\n",
    "# Fetch historical data\n",
    "ohlc_data = pd.DataFrame(mt.copy_rates_range(symbol, timeframe, start_date, end_date))\n",
    "ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "df = ohlc_data[['time', 'open', 'high', 'low', 'close']].copy()\n",
    "\n",
    "df['EMA_9'] = talib.EMA(df['close'], timeperiod=9)\n",
    "df['EMA_21'] = talib.EMA(df['close'], timeperiod=21)\n",
    "df['EMA_50'] = talib.EMA(df['close'], timeperiod=50)\n",
    "\n",
    "df['RSI_9'] = talib.RSI(df['close'], timeperiod=9)\n",
    "df['RSI_14'] = talib.RSI(df['close'], timeperiod=14)\n",
    "df['RSI_21'] = talib.RSI(df['close'], timeperiod=21)\n",
    "\n",
    "df['WILLR_15'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=15)\n",
    "df['WILLR_23'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=23)\n",
    "df['WILLR_42'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=42)\n",
    "df['WILLR_145'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=145)\n",
    "\n",
    "df['SAR'] = talib.SAR(df['high'], df['low'], acceleration=0.02, maximum=0.2)\n",
    "\n",
    "df['BB_upper'], df['BB_middle'], df['BB_lower'] = talib.BBANDS(df['close'], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "df['BB_width'] = df['BB_upper'] - df['BB_lower']\n",
    "\n",
    "df['MACD'], df['MACD_signal'], df['MACD_hist'] = talib.MACD(df['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "df['CCI_14'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "\n",
    "df = add_rolling_features(df, window=5)\n",
    "\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['b_flag'] = 0\n",
    "df['s_flag'] = 0\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "#csv_file_path = 'EURUSD_D1_2010to101124.csv'  # Specify your desired path\n",
    "#df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "label_data(df, [StopLoss], [TakeProfit], 80, symbol, False)\n",
    "\n",
    "df['b_flag'] = df['b_flag'].shift(-1)\n",
    "df = add_lag_features(df, lags=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number of 1s in b_flag and s_flag columns\n",
    "total_b_flags = df['b_flag'].sum()\n",
    "total_s_flags = df['s_flag'].sum()\n",
    "\n",
    "# Total number of rows in the DataFrame\n",
    "total_rows = len(df)\n",
    "\n",
    "# Calculate counts in segments of complete 100% data\n",
    "count_100_b_flags = total_b_flags\n",
    "count_100_s_flags = total_s_flags\n",
    "\n",
    "# Calculate counts in intervals of 10%\n",
    "interval_counts = []\n",
    "for i in range(0, 101, 10):\n",
    "    start_idx = int(i / 100 * total_rows)\n",
    "    end_idx = int((i + 10) / 100 * total_rows)\n",
    "    \n",
    "    interval_b_flags = df['b_flag'].iloc[start_idx:end_idx].sum()\n",
    "    interval_s_flags = df['s_flag'].iloc[start_idx:end_idx].sum()\n",
    "    \n",
    "    interval_counts.append((f'{i}% - {i+10}%', interval_b_flags, interval_s_flags))\n",
    "\n",
    "# Print results\n",
    "print(\"Total number of 1s:\")\n",
    "print(f\"b_flag: {total_b_flags}\")\n",
    "print(f\"s_flag: {total_s_flags}\")\n",
    "\n",
    "print(\"\\nCounts in segments of 100% data:\")\n",
    "print(f\"b_flag: {count_100_b_flags}\")\n",
    "print(f\"s_flag: {count_100_s_flags}\")\n",
    "\n",
    "print(\"\\nCounts in intervals of 10%:\")\n",
    "for interval, count_b, count_s in interval_counts:\n",
    "    print(f\"{interval}: b_flag={count_b}, s_flag={count_s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdd415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['s_flag'], inplace=True)\n",
    "\n",
    "X1 = extract_rolling_features(df, 'WILLR_15', symbol)\n",
    "X2 = extract_rolling_features(df, 'WILLR_42', symbol)\n",
    "X3 = extract_rolling_features(df, 'RSI_14', symbol)\n",
    "X4 = extract_rolling_features(df, 'MACD_hist', symbol)\n",
    "X5 = extract_rolling_features(df, 'EMA_9', symbol)\n",
    "X6 = extract_rolling_features(df, 'EMA_21', symbol)\n",
    "X7 = extract_rolling_features(df, 'EMA_50', symbol)\n",
    "X9 = extract_rolling_features(df, 'RSI_9', symbol)\n",
    "X10 = extract_rolling_features(df, 'RSI_21', symbol)\n",
    "X11 = extract_rolling_features(df, 'WILLR_23', symbol)\n",
    "X12 = extract_rolling_features(df, 'WILLR_145', symbol)\n",
    "X13 = extract_rolling_features(df, 'SAR', symbol)\n",
    "X14 = extract_rolling_features(df, 'BB_width', symbol)\n",
    "X15 = extract_rolling_features(df, 'MACD_signal', symbol)\n",
    "X16 = extract_rolling_features(df, 'CCI_14', symbol)\n",
    "\n",
    "# Combine all extracted features\n",
    "X = pd.concat([X1, X2, X3, X4, X5, X6, X7, X9, X10, X11, X12, X13, X14, X15, X16], axis=1, join='inner').dropna()\n",
    "\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.set_index('time')\n",
    "X = X[X.index.isin(df.index)]\n",
    "X = pd.concat([df,X], axis=1, join='inner')\n",
    "\n",
    "X_df = select_features(X, X['b_flag'])\n",
    "X_df = X_df[[col for col in X_df if col != 'b_flag'] + ['b_flag']]\n",
    "\n",
    "correlation_matrix = X_df.corr().abs()\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "high_correlation_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.9)]\n",
    "X_df = X_df.drop(columns=high_correlation_features)\n",
    "\n",
    "#original_index = X_df.index\n",
    "#X_df = X_df.shift(periods=1, axis=0)\n",
    "#X_df.index = original_index\n",
    "X_df = X_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c669a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_df[['b_flag'] + X_df.columns[:5]].head(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de92c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.90 * len(X_df))\n",
    "train_data, test_data = X_df.iloc[:split], X_df.iloc[split:]\n",
    "\n",
    "x_train = train_data.iloc[:, :-1].values\n",
    "y_train = train_data['b_flag'].values\n",
    "x_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data['b_flag'].values\n",
    "\n",
    "sc_mt = StandardScaler()\n",
    "x_train = sc_mt.fit_transform(x_train)\n",
    "x_test = sc_mt.transform(x_test)\n",
    "\n",
    "print(\"Number of features before PCA:\", x_train.shape[1])\n",
    "\n",
    "# Apply PCA to reduce dimensionality\n",
    "\n",
    "pca = PCA(n_components=10, svd_solver='randomized', random_state=0)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "\n",
    "print(\"Number of features after PCA:\", x_train.shape[1])\n",
    "\n",
    "n_estimators = 50\n",
    "class_weight = {0: 15, 1: 15}\n",
    "max_features = 'sqrt'\n",
    "random_state = 42\n",
    "\n",
    "rf_classifier_mt = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    class_weight=class_weight,\n",
    "    max_features=max_features,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "rf_classifier_mt.fit(x_train, y_train)\n",
    "y_pred_proba = rf_classifier_mt.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Add probability threshold for predicting class 1\n",
    "threshold = 0.6  # Adjust as needed to increase precision\n",
    "y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "false_positives = conf_matrix[0][1]\n",
    "true_positives = conf_matrix[1][1]\n",
    "\n",
    "precision = precision_score(y_test, y_pred) if (false_positives+true_positives) > 0 else 0\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print('Accuracy:', round(accuracy, 4))\n",
    "print('Precision:', round(precision, 4))\n",
    "print('Recall:', round(recall, 4))\n",
    "print('F1 Score:', round(f1, 4))\n",
    "print('ROC-AUC:', round(roc_auc, 4))\n",
    "print('Classification Report:\\n', classification_rep)\n",
    "print('WIN/LOSS-Diff:', round(100 * (precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', false_positives)\n",
    "print('True Positives:', true_positives)\n",
    "if (false_positives + true_positives) > 0:\n",
    "    print('Ratio total:', round(100 * (true_positives / (false_positives + true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36887e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import json\n",
    "feature_names = X_df.columns\n",
    "with open('AUDUSD_D1_3112buy/feature_names.json', 'w') as f:\n",
    "    json.dump(list(feature_names), f)\n",
    " \"\"\"/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f65221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to datetime without 'unit' since the format is already date strings\n",
    "X_df.index = pd.to_datetime(X_df.index)\n",
    "\n",
    "# Format datetime to the desired string format\n",
    "X_df.index = X_df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Creating a DataFrame for predictions with the correct index\n",
    "df_pred = pd.DataFrame(index=X_df.iloc[split:].index)  # No need for split+1\n",
    "df_pred['prediction'] = y_pred\n",
    "\n",
    "# Save to CSV\n",
    "df_pred.to_csv('predEURUSD_D1_3112buy.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece23c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
