{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cbb1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import talib\n",
    "from talipp.indicators import EMA, SMA, Stoch, DPO\n",
    "from joblib import dump\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, confusion_matrix, classification_report\n",
    "from own_functions import *\n",
    "\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, make_forecasting_frame\n",
    "from tsfresh.utilities.dataframe_functions import impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1149e9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.initialize()\n",
    "login = 51708234\n",
    "password =\"4bM&wuVJcBTnjV\"\n",
    "server = \"ICMarketsEU-Demo\"\n",
    "mt.login(login,password,server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7cca420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" csv_file_path = 'ICMT5USDCAD_2010_D1_1806.csv'  # Specify your desired path\\ndf.to_csv(csv_file_path, index=False)\\ndf \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol=\"USDCAD\"\n",
    "timeframe=mt.TIMEFRAME_D1\n",
    "#ohcl data\n",
    "ohlc_data=pd.DataFrame(mt.copy_rates_range(symbol,timeframe,datetime(2010,1,1), datetime.now()))\n",
    "ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "df=pd.DataFrame(ohlc_data)[['time','open','high','low','close']]\n",
    "\n",
    "#Indicators\n",
    "df['WILLR_15']=talib.WILLR(df['high'],df['low'],df['open'],timeperiod=15) #Williams' %R\n",
    "df['WILLR_23']=talib.WILLR(df['high'],df['low'],df['open'],timeperiod=23) #Williams' %R\n",
    "df['WILLR_42']=talib.WILLR(df['high'],df['low'],df['open'],timeperiod=42) #Williams' %R\n",
    "df['WILLR_145']=talib.WILLR(df['high'],df['low'],df['open'],timeperiod=145) #Williams' %R\n",
    "\n",
    "#Buy & Sell Flags\n",
    "df['b_flag'] = 0\n",
    "df['s_flag'] = 0\n",
    "\n",
    "df=df.dropna()\n",
    "df=df.reset_index(drop=True)\n",
    "\"\"\" csv_file_path = 'ICMT5USDCAD_2010_D1_1806.csv'  # Specify your desired path\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "df \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1ee607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Candle: 0.008727453639634657\n"
     ]
    }
   ],
   "source": [
    "StopLoss=3\n",
    "TakeProfit=4\n",
    "BreakEvenRatio=StopLoss/(StopLoss+TakeProfit)\n",
    "label_data(df,[StopLoss],[TakeProfit],80,symbol,False)\n",
    "#print('BreatEvenRatio:', BreakEvenRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af671f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 30/30 [00:11<00:00,  2.68it/s]\n",
      "Feature Extraction: 100%|██████████| 30/30 [01:30<00:00,  3.03s/it]\n",
      "Rolling: 100%|██████████| 30/30 [00:10<00:00,  2.76it/s]\n",
      "Feature Extraction: 100%|██████████| 30/30 [01:31<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WILLR_15__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.6__ql_0.0', 'WILLR_15__partial_autocorrelation__lag_4', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.6__ql_0.0', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.8__ql_0.0', 'WILLR_15__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.0', 'WILLR_15__partial_autocorrelation__lag_3', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.8__ql_0.0', 'WILLR_15__lempel_ziv_complexity__bins_3', 'WILLR_15__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.0', 'WILLR_15__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.0', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_1.0__ql_0.6', 'WILLR_15__permutation_entropy__dimension_7__tau_1', 'WILLR_15__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.0', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.0', 'WILLR_15__longest_strike_below_mean', 'WILLR_15__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.4', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_1.0__ql_0.2', 'WILLR_15__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"', 'WILLR_15__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.4', 'WILLR_15__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.0', 'WILLR_15__fft_coefficient__attr_\"abs\"__coeff_3', 'WILLR_15__large_standard_deviation__r_0.35000000000000003', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.6__ql_0.4', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_1.0__ql_0.8', 'WILLR_15__symmetry_looking__r_0.1', 'WILLR_15__approximate_entropy__m_2__r_0.9', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.4__ql_0.0', 'WILLR_15__count_above_mean', 'WILLR_15__autocorrelation__lag_4', 'WILLR_15__fft_coefficient__attr_\"abs\"__coeff_10', 'WILLR_15__approximate_entropy__m_2__r_0.7', 'WILLR_15__fft_coefficient__attr_\"abs\"__coeff_9', 'WILLR_15__count_below_mean', 'WILLR_15__skewness', 'WILLR_15__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.2', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.4__ql_0.2', 'WILLR_15__lempel_ziv_complexity__bins_2', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.8__ql_0.2', 'WILLR_15__agg_autocorrelation__f_agg_\"median\"__maxlag_40', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.4', 'WILLR_15__autocorrelation__lag_5', 'WILLR_15__partial_autocorrelation__lag_5', 'WILLR_15__ratio_beyond_r_sigma__r_3', 'WILLR_15__binned_entropy__max_bins_10', 'WILLR_15__partial_autocorrelation__lag_2', 'WILLR_15__agg_linear_trend__attr_\"slope\"__chunk_len_10__f_agg_\"min\"', 'WILLR_15__permutation_entropy__dimension_3__tau_1', 'WILLR_15__agg_autocorrelation__f_agg_\"mean\"__maxlag_40', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.6', 'WILLR_42__fft_coefficient__attr_\"abs\"__coeff_9', 'WILLR_42__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.6', 'WILLR_42__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"max\"', 'WILLR_42__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.4', 'WILLR_42__autocorrelation__lag_4', 'WILLR_42__fft_coefficient__attr_\"abs\"__coeff_10', 'WILLR_42__partial_autocorrelation__lag_4', 'WILLR_42__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"', 'WILLR_42__standard_deviation', 'WILLR_42__variance', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.4', 'WILLR_42__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.2', 'WILLR_42__agg_autocorrelation__f_agg_\"median\"__maxlag_40', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.4', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.6', 'WILLR_42__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.8', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.4', 'WILLR_42__longest_strike_below_mean', 'WILLR_42__number_peaks__n_5', 'WILLR_42__fft_coefficient__attr_\"abs\"__coeff_1', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.2', 'WILLR_42__autocorrelation__lag_2', 'WILLR_42__autocorrelation__lag_5', 'WILLR_42__fourier_entropy__bins_2', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.2', 'WILLR_42__agg_autocorrelation__f_agg_\"mean\"__maxlag_40', 'WILLR_42__symmetry_looking__r_0.1', 'WILLR_42__percentage_of_reoccurring_values_to_all_values', 'WILLR_42__has_duplicate', 'WILLR_42__ratio_value_number_to_time_series_length', 'WILLR_42__percentage_of_reoccurring_datapoints_to_all_datapoints', 'WILLR_42__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.2', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.0', 'WILLR_42__large_standard_deviation__r_0.35000000000000003', 'WILLR_42__partial_autocorrelation__lag_5', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.4', 'WILLR_42__partial_autocorrelation__lag_3', 'WILLR_42__cid_ce__normalize_True', 'WILLR_42__approximate_entropy__m_2__r_0.9', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.6__ql_0.0', 'WILLR_42__linear_trend__attr_\"pvalue\"', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.6__ql_0.4', 'WILLR_42__sum_of_reoccurring_data_points', 'WILLR_42__sum_of_reoccurring_values', 'WILLR_42__approximate_entropy__m_2__r_0.7', 'WILLR_42__fft_coefficient__attr_\"abs\"__coeff_2', 'WILLR_42__permutation_entropy__dimension_5__tau_1', 'WILLR_42__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.8__ql_0.4', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.4', 'WILLR_42__minimum', 'WILLR_42__absolute_maximum', 'WILLR_42__lempel_ziv_complexity__bins_5', 'WILLR_42__fft_coefficient__attr_\"abs\"__coeff_5', 'WILLR_42__change_quantiles__f_agg_\"mean\"__isabs_False__qh_1.0__ql_0.8', 'WILLR_42__approximate_entropy__m_2__r_0.5', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.0', 'WILLR_42__range_count__max_1__min_-1', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.0', 'WILLR_42__mean_n_absolute_max__number_of_maxima_7', 'WILLR_42__fourier_entropy__bins_100', 'WILLR_42__sample_entropy', 'WILLR_42__fourier_entropy__bins_10', 'WILLR_42__quantile__q_0.2', 'WILLR_42__autocorrelation__lag_8', 'WILLR_42__number_crossing_m__m_-1', 'WILLR_42__autocorrelation__lag_3', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.6']\n"
     ]
    }
   ],
   "source": [
    "#target='b_flag'\n",
    "target='s_flag'\n",
    "\n",
    "selected_signal='WILLR_15'\n",
    "\n",
    "df_melted = df[['time', selected_signal]].copy()\n",
    "df_melted[\"Symbols\"] = symbol\n",
    "\n",
    "df_rolled = roll_time_series(df_melted, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                             max_timeshift=20, min_timeshift=5)\n",
    "\n",
    "X = extract_features(df_rolled.drop(\"Symbols\", axis=1), \n",
    "                     column_id=\"id\", column_sort=\"time\", column_value=selected_signal, \n",
    "                     impute_function=impute, show_warnings=False)\n",
    "\n",
    "X = X.set_index(X.index.map(lambda x: x[1]), drop=True)\n",
    "X.index.name = \"time\"\n",
    "X=X.dropna()\n",
    "\n",
    "\n",
    "selected_signal='WILLR_42'\n",
    "\n",
    "df_melted = df[['time', selected_signal]].copy()\n",
    "df_melted[\"Symbols\"] = symbol\n",
    "\n",
    "df_rolled = roll_time_series(df_melted, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                             max_timeshift=20, min_timeshift=5)\n",
    "\n",
    "X3 = extract_features(df_rolled.drop(\"Symbols\", axis=1), \n",
    "                     column_id=\"id\", column_sort=\"time\", column_value=selected_signal, \n",
    "                     impute_function=impute, show_warnings=False)\n",
    "\n",
    "X3 = X3.set_index(X3.index.map(lambda x: x[1]), drop=True)\n",
    "X3.index.name = \"time\"\n",
    "X3=X3.dropna()\n",
    "\n",
    "\n",
    "df=df.set_index('time')\n",
    "df = df[df.index.isin(X.index)]\n",
    "\n",
    "X = select_features(X, df[target])\n",
    "X3 = select_features(X3, df[target])\n",
    "\n",
    "df = pd.concat([X, X3, df], axis=1)\n",
    "df=df.drop(columns=['high','low','close','open'])\n",
    "\n",
    "\n",
    "X_selected = select_features(X, df[target])\n",
    "X3_selected = select_features(X3, df[target])\n",
    "\n",
    "# Get the list of selected feature names\n",
    "selected_feature_names_X = list(X_selected.columns)\n",
    "selected_feature_names_X3 = list(X3_selected.columns)\n",
    "\n",
    "# Combine lists if you need a single list for all selected features\n",
    "combined_selected_features = selected_feature_names_X + selected_feature_names_X3\n",
    "\n",
    "print(combined_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef883039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' sum_fp=0\\nsum_tp=0\\n\\nsplit=int(0.90*len(df))\\n\\ntrain_data, test_data = df.iloc[0:split], df.iloc[split+1:len(df)]\\n\\n#Train data\\nx_train = train_data.iloc[:, 0:len(df.columns)-2].values\\ny_train = train_data.iloc[:, df.columns.get_loc(target)].values\\n#Test data\\nx_test = test_data.iloc[:, 0:len(df.columns)-2].values\\ny_test = test_data.iloc[:, df.columns.get_loc(target)].values\\n\\n\\n#Scale Data\\nsc_mt=StandardScaler()\\n\\nx_train=sc_mt.fit_transform(x_train)\\n\\nx_test=sc_mt.transform(x_test)\\n\\n#dump(sc_mt,\\'Dump_USDCAD_H4Sell\\\\scaler.joblib\\')\\n\\n# Hyperparameter\\nn_estimators = 100\\nclass_weight = {0: 15, 1: 6}\\nmax_features = \\'log2\\'\\nrandom_state = 1\\n\\n# Initialise RandomForestClassifier\\nrf_classifier_mt = RandomForestClassifier(\\n    n_estimators=n_estimators,\\n    class_weight=class_weight,\\n    max_features=max_features,\\n    random_state=random_state\\n)\\n\\n# Train Modell\\nrf_classifier_mt.fit(x_train, y_train)\\n\\n#dump(rf_classifier_mt,\\'Dump_USDCAD_H4Sell\\\\model.joblib\\')\\n\\n# Predict\\ny_pred = rf_classifier_mt.predict(x_test)\\n\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred))\\n\\nfalse_positives = confusion_matrix(y_test, y_pred)[0][1]\\ntrue_positives = confusion_matrix(y_test, y_pred)[1][1]\\n\\nsum_fp=sum_fp+false_positives\\nsum_tp=sum_tp+true_positives\\n\\n#print(\"\\nClassification Report:\")\\n#print(classification_report(y_test, y_pred))\\n\\nprecision = precision_score(y_test, y_pred)\\n#print(\"\\nPrecision Score:\", round(precision,2))\\n#print(\\'BreakEvenRatio:\\', round(BreakEvenRatio,2))\\n#print(\\'\\n\\')\\nprint(\\'WIN/LOSS-Diff:\\', round(100*(precision-BreakEvenRatio),2), \\'%\\')\\nprint(\\'sum_fp:\\', sum_fp)\\nprint(\\'sum_tp:\\', sum_tp)\\n#print(\\'Diff:\\', sum_tp-sum_fp)\\nprint(\\'precision:\\',precision)\\nprint(\\'Ratio total:\\', round(100*(sum_tp/(sum_fp+sum_tp)) ,2))\\nprint(\\'BreakEvenRatio:\\', round(BreakEvenRatio,2))\\nprint(\\'____________________________________________________________________________________________________________________________\\') '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" sum_fp=0\n",
    "sum_tp=0\n",
    "\n",
    "split=int(0.90*len(df))\n",
    "\n",
    "train_data, test_data = df.iloc[0:split], df.iloc[split+1:len(df)]\n",
    "\n",
    "#Train data\n",
    "x_train = train_data.iloc[:, 0:len(df.columns)-2].values\n",
    "y_train = train_data.iloc[:, df.columns.get_loc(target)].values\n",
    "#Test data\n",
    "x_test = test_data.iloc[:, 0:len(df.columns)-2].values\n",
    "y_test = test_data.iloc[:, df.columns.get_loc(target)].values\n",
    "\n",
    "\n",
    "#Scale Data\n",
    "sc_mt=StandardScaler()\n",
    "\n",
    "x_train=sc_mt.fit_transform(x_train)\n",
    "\n",
    "x_test=sc_mt.transform(x_test)\n",
    "\n",
    "#dump(sc_mt,'Dump_USDCAD_H4Sell\\scaler.joblib')\n",
    "\n",
    "# Hyperparameter\n",
    "n_estimators = 100\n",
    "class_weight = {0: 15, 1: 6}\n",
    "max_features = 'log2'\n",
    "random_state = 1\n",
    "\n",
    "# Initialise RandomForestClassifier\n",
    "rf_classifier_mt = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    class_weight=class_weight,\n",
    "    max_features=max_features,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "# Train Modell\n",
    "rf_classifier_mt.fit(x_train, y_train)\n",
    "\n",
    "#dump(rf_classifier_mt,'Dump_USDCAD_H4Sell\\model.joblib')\n",
    "\n",
    "# Predict\n",
    "y_pred = rf_classifier_mt.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "false_positives = confusion_matrix(y_test, y_pred)[0][1]\n",
    "true_positives = confusion_matrix(y_test, y_pred)[1][1]\n",
    "\n",
    "sum_fp=sum_fp+false_positives\n",
    "sum_tp=sum_tp+true_positives\n",
    "\n",
    "#print(\"\\nClassification Report:\")\n",
    "#print(classification_report(y_test, y_pred))\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "#print(\"\\nPrecision Score:\", round(precision,2))\n",
    "#print('BreakEvenRatio:', round(BreakEvenRatio,2))\n",
    "#print('\\n')\n",
    "print('WIN/LOSS-Diff:', round(100*(precision-BreakEvenRatio),2), '%')\n",
    "print('sum_fp:', sum_fp)\n",
    "print('sum_tp:', sum_tp)\n",
    "#print('Diff:', sum_tp-sum_fp)\n",
    "print('precision:',precision)\n",
    "print('Ratio total:', round(100*(sum_tp/(sum_fp+sum_tp)) ,2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio,2))\n",
    "print('____________________________________________________________________________________________________________________________') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7f65221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" df.index = pd.to_datetime(df.index, unit='s')\\ndf.index = df.index.strftime('%Y-%m-%d %H:%M:%S')\\ndf_pred = pd.DataFrame(index=df.iloc[split+1:len(df)].index)\\ndf_pred['prediction'] = y_pred\\ndf_pred.to_csv('predictUSDCAD_D1Sell.csv') \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" df.index = pd.to_datetime(df.index, unit='s')\n",
    "df.index = df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_pred = pd.DataFrame(index=df.iloc[split+1:len(df)].index)\n",
    "df_pred['prediction'] = y_pred\n",
    "df_pred.to_csv('predictUSDCAD_D1Sell.csv') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92ba1e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[226  29]\n",
      " [ 85  20]]\n",
      "\n",
      "Metrics:\n",
      "WIN/LOSS-Diff: -2.04 %\n",
      "sum_fp: 29\n",
      "sum_tp: 20\n",
      "precision: 0.40816326530612246\n",
      "Ratio total: 40.82\n",
      "BreakEvenRatio: 0.43\n",
      "____________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from joblib import dump\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Set timezone to UTC\n",
    "utc_tz = pytz.utc\n",
    "\n",
    "\n",
    "# Initialize counters\n",
    "sum_fp = 0\n",
    "sum_tp = 0\n",
    "\n",
    "# Split data\n",
    "split = int(0.90 * len(df))\n",
    "train_data, test_data = df.iloc[0:split], df.iloc[split+1:len(df)]\n",
    "\n",
    "# Train data\n",
    "x_train = train_data.iloc[:, 0:len(df.columns)-2].values\n",
    "y_train = train_data.iloc[:, df.columns.get_loc(target)].values\n",
    "\n",
    "# Test data\n",
    "x_test = test_data.iloc[:, 0:len(df.columns)-2].values\n",
    "y_test = test_data.iloc[:, df.columns.get_loc(target)].values\n",
    "\n",
    "# Scale Data\n",
    "sc_mt = StandardScaler()\n",
    "x_train = sc_mt.fit_transform(x_train)\n",
    "x_test = sc_mt.transform(x_test)\n",
    "dump(sc_mt, 'AdaBoost_USDCAD_D1Sell/scaler.joblib')\n",
    "\n",
    "# Hyperparameters\n",
    "n_estimators = 80\n",
    "class_weight = {0: 1, 1: 15}\n",
    "max_features = 'log2'\n",
    "random_state = 1\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_classifier_mt = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    class_weight=class_weight,\n",
    "    max_features=max_features,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "# Initialize AdaBoostClassifier with RandomForest as the base estimator\n",
    "ada_classifier_mt = AdaBoostClassifier(\n",
    "    base_estimator=rf_classifier_mt,\n",
    "    n_estimators=80,\n",
    "    learning_rate=1.0,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "ada_classifier_mt.fit(x_train, y_train)\n",
    "dump(ada_classifier_mt, 'AdaBoost_USDCAD_D1Sell/model.joblib')\n",
    "\n",
    "# Predict\n",
    "y_pred = ada_classifier_mt.predict(x_test)\n",
    "\n",
    "# Metrics Calculation\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "false_positives = cm[0][1]\n",
    "true_positives = cm[1][1]\n",
    "\n",
    "sum_fp += false_positives\n",
    "sum_tp += true_positives\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"WIN/LOSS-Diff: {round(100*(precision-BreakEvenRatio), 2)} %\")\n",
    "print(f\"sum_fp: {sum_fp}\")\n",
    "print(f\"sum_tp: {sum_tp}\")\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"Ratio total: {round(100*(sum_tp / (sum_fp + sum_tp)), 2)}\")\n",
    "print(f\"BreakEvenRatio: {round(BreakEvenRatio, 2)}\")\n",
    "print('____________________________________________________________________________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6833ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.index = pd.to_datetime(df.index, unit='s')\n",
    "df.index = df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_pred = pd.DataFrame(index=df.iloc[split+1:len(df)].index)\n",
    "df_pred['prediction'] = y_pred\n",
    "df_pred.to_csv('predictadaboostUSDCAD_D1Sell.csv')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36887e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
