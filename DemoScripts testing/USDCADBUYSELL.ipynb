{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MetaTrader 5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import time\n",
    "from joblib import load\n",
    "import logging\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, impute\n",
    "import talib\n",
    "import os\n",
    "import threading\n",
    "\n",
    "logging.basicConfig(filename='trading_USDCAD_Buy_Sell_D1.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def init_mt5_connection(login, password, server):\n",
    "    if not mt5.initialize(login=login, password=password, server=server):\n",
    "        logging.error(f\"initialize() failed, error code = {mt5.last_error()}\")\n",
    "        sys.exit()\n",
    "    logging.info(\"Connected to MetaTrader 5\")\n",
    "    print(\"Connected to MetaTrader 5\")\n",
    "\n",
    "def fetch_latest_candle(symbol, timeframe):\n",
    "    latest_candles = mt5.copy_rates_from_pos(symbol, timeframe, 0, 1)\n",
    "    return latest_candles[0] if len(latest_candles) > 0 else None\n",
    "\n",
    "def fetch_historical_data(symbol, timeframe, start_date, end_date):\n",
    "    logging.info(f\"Fetching historical data for {symbol}\")\n",
    "    data = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    ohlc_data = pd.DataFrame(data)\n",
    "    ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "    return ohlc_data[['time', 'open', 'high', 'low', 'close']]\n",
    "\n",
    "def add_rolling_features(df, window):\n",
    "    logging.info(\"Adding rolling features\")\n",
    "    df['rolling_mean_open'] = df['open'].rolling(window=window).mean()\n",
    "    df['rolling_std_open'] = df['open'].rolling(window=window).std()\n",
    "    df['rolling_mean_close'] = df['close'].rolling(window=window).mean()\n",
    "    df['rolling_std_close'] = df['close'].rolling(window=window).std()\n",
    "    df['rolling_mean_high'] = df['high'].rolling(window=window).mean()\n",
    "    df['rolling_std_high'] = df['high'].rolling(window=window).std()\n",
    "    df['rolling_mean_low'] = df['low'].rolling(window=window).mean()\n",
    "    df['rolling_std_low'] = df['low'].rolling(window=window).std()\n",
    "    return df\n",
    "\n",
    "def add_lag_features(df, lags):\n",
    "    logging.info(\"Adding lag features\")\n",
    "    for lag in lags:\n",
    "        df[f'open_lag_{lag}'] = df['open'].shift(lag)\n",
    "        df[f'close_lag_{lag}'] = df['close'].shift(lag)\n",
    "        df[f'high_lag_{lag}'] = df['high'].shift(lag)\n",
    "        df[f'low_lag_{lag}'] = df['low'].shift(lag)\n",
    "    return df\n",
    "\n",
    "def calculate_indicators(df):\n",
    "    logging.info(\"Calculating indicators\")\n",
    "    for period in [15, 23, 42, 145]:\n",
    "        df[f'WILLR_{period}'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=period)\n",
    "    return df\n",
    "\n",
    "def align_features_with_json(df, features_json):\n",
    "    expected_features = features_json\n",
    "    missing_features = [feat for feat in expected_features if feat not in df.columns]\n",
    "    extra_features = [feat for feat in df.columns if feat not in expected_features]\n",
    "    \n",
    "    logging.info(f\"Missing features: {missing_features}\")\n",
    "    logging.info(f\"Extra features: {extra_features}\")\n",
    "    \n",
    "    for feat in missing_features:\n",
    "        df[feat] = 0\n",
    "\n",
    "    df = df[expected_features]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_data_for_features(df, symbol, signals, selected_features):\n",
    "    logging.info(f\"Processing data for feature extraction for {symbol}\")\n",
    "    X_combined = pd.DataFrame(index=df['time'])\n",
    "    \n",
    "    for signal in signals:\n",
    "        df_melted = df[['time', signal]].copy()\n",
    "        df_melted[\"Symbols\"] = symbol\n",
    "        df_rolled = roll_time_series(df_melted, column_id=\"Symbols\", column_sort=\"time\", max_timeshift=20, min_timeshift=5)\n",
    "        X = extract_features(df_rolled.drop(\"Symbols\", axis=1), column_id=\"id\", column_sort=\"time\", column_value=signal, impute_function=impute, show_warnings=False)\n",
    "        X = X.set_index(X.index.map(lambda x: x[1]), drop=True)\n",
    "        selected_features_X = [feature for feature in selected_features if feature in X.columns]\n",
    "        X_filtered = X[selected_features_X]\n",
    "        X_combined = X_combined.merge(X_filtered, left_index=True, right_index=True, how='left')\n",
    "        X_combined = X_combined.dropna()\n",
    "    return X_combined\n",
    "\n",
    "def fetch_and_process_data(symbol, timeframe, signals, selected_features, start_date, end_date):\n",
    "    logging.info(f\"Fetching and processing data for {symbol}\")\n",
    "    df = fetch_historical_data(symbol, timeframe, start_date, end_date)\n",
    "    df = calculate_indicators(df)\n",
    "    df = add_rolling_features(df, window=5)\n",
    "    df = add_lag_features(df, lags=[1, 2, 3, 4, 5])\n",
    "    \n",
    "    logging.info(f\"NaNs before drop for {symbol}: {df.isnull().sum().sum()}\")\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    logging.info(f\"NaNs after drop for {symbol}: {df.isnull().sum().sum()}\")\n",
    "\n",
    "    features = process_data_for_features(df, symbol, signals, selected_features)\n",
    "    df = df.set_index('time')\n",
    "    combined_df = df.merge(features, left_index=True, right_index=True, how='left')\n",
    "    combined_df = combined_df[selected_features]\n",
    "    logging.info(f\"NaNs after merging for {symbol}: {combined_df.isnull().sum().sum()}\")\n",
    "    combined_df = combined_df.dropna()\n",
    "    logging.info(f\"Final NaNs for {symbol}: {combined_df.isnull().sum().sum()}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "def calculate_prices(entry_price, risk_reward_ratio, mean_candle_size):\n",
    "    logging.info(\"Calculating SL and TP prices\")\n",
    "    risk_part, reward_part = map(int, risk_reward_ratio.split(':'))\n",
    "    risk_amount = mean_candle_size * risk_part\n",
    "    reward_amount = mean_candle_size * reward_part\n",
    "    sl_price = entry_price - risk_amount\n",
    "    tp_price = entry_price + reward_amount\n",
    "    return sl_price, tp_price\n",
    "\n",
    "def place_order(symbol, volume, sl_price, tp_price, trade_type):\n",
    "    logging.info(f\"Placing {trade_type} order for {symbol}\")\n",
    "    \n",
    "    symbol_info = mt5.symbol_info(symbol)\n",
    "    if symbol_info is None or not symbol_info.visible or symbol_info.trade_mode == mt5.SYMBOL_TRADE_MODE_DISABLED:\n",
    "        logging.error(f\"Market for {symbol} is closed or unavailable.\")\n",
    "        print(f\"Market for {symbol} is closed. Cannot place order.\")\n",
    "        return\n",
    "\n",
    "    price = mt5.symbol_info_tick(symbol).ask if trade_type == \"Buy\" else mt5.symbol_info_tick(symbol).bid\n",
    "    order_type = mt5.ORDER_TYPE_BUY if trade_type == \"Buy\" else mt5.ORDER_TYPE_SELL\n",
    "    \n",
    "    request = {\n",
    "        \"action\": mt5.TRADE_ACTION_DEAL,\n",
    "        \"symbol\": symbol,\n",
    "        \"volume\": volume,\n",
    "        \"type\": order_type,\n",
    "        \"price\": price,\n",
    "        \"sl\": sl_price,\n",
    "        \"tp\": tp_price,\n",
    "        \"deviation\": 10,\n",
    "        \"magic\": 0,\n",
    "        \"comment\": f\"Python script {trade_type} order\",\n",
    "        \"type_time\": mt5.ORDER_TIME_GTC,\n",
    "        \"type_filling\": mt5.ORDER_FILLING_IOC,\n",
    "    }\n",
    "    \n",
    "    result = mt5.order_send(request)\n",
    "    \n",
    "    if result and result.retcode == mt5.TRADE_RETCODE_DONE:\n",
    "        logging.info(f\"{trade_type} order placed successfully for {symbol}.\")\n",
    "        print(f\"{trade_type} order placed successfully for {symbol}.\")\n",
    "    else:\n",
    "        logging.error(f\"Order placement failed for {symbol}: {result.retcode} - {mt5.last_error()}\")\n",
    "        print(f\"Order placement failed for {symbol}: {result.retcode} - {mt5.last_error()}\")\n",
    "\n",
    "def apply_custom_threshold(probas, custom_threshold):\n",
    "    return (probas >= custom_threshold).astype(int)\n",
    "\n",
    "def predict_and_trade(scaler, model, symbol, volume, timeframe, risk_reward_ratio, mean_candle_size, start_date, end_date, features_json, trade_type, threshold=None):\n",
    "    logging.info(f\"Starting prediction and trading process for {symbol} - {trade_type}\")\n",
    "    signals = ['WILLR_15', 'WILLR_42']\n",
    "    df_processed = fetch_and_process_data(symbol, timeframe, signals, features_json, start_date, end_date)\n",
    "    original_index = df_processed.index\n",
    "    df_processed = df_processed.shift(periods=1, axis=0).dropna()\n",
    "    df_processed.index = original_index\n",
    "    df_processed = align_features_with_json(df_processed, features_json)\n",
    "    logging.info(f\"Number of features for {symbol} - {trade_type}: {df_processed.shape[1]}\")\n",
    "    scaled_data = scaler.transform(df_processed)\n",
    "    probas = model.predict_proba(scaled_data)[:, 1]\n",
    "    custom_threshold = threshold if threshold is not None else 0.5\n",
    "    y_pred = apply_custom_threshold(probas, custom_threshold)\n",
    "    \n",
    "    df_pred = pd.DataFrame(index=df_processed.index)\n",
    "    df_pred['prediction'] = y_pred\n",
    "    save_predictions_to_csv(df_pred, symbol, trade_type)\n",
    "    \n",
    "    if len(y_pred) > 1 and y_pred[-1] == 1:\n",
    "        entry_price = mt5.symbol_info_tick(symbol).ask if trade_type == \"Buy\" else mt5.symbol_info_tick(symbol).bid\n",
    "        sl_price, tp_price = calculate_prices(entry_price, risk_reward_ratio, mean_candle_size)\n",
    "        place_order(symbol, volume, sl_price, tp_price, trade_type)\n",
    "    else:\n",
    "        logging.info(f\"No {trade_type} signal generated for {symbol}. Doing nothing.\")\n",
    "        print(f\"No {trade_type} signal generated for {symbol}. Doing nothing.\")\n",
    "\n",
    "def save_predictions_to_csv(df_pred, symbol, trade_type):\n",
    "    logging.info(f\"Saving {trade_type} predictions to CSV for {symbol}\")\n",
    "    file_path = f'predict_{symbol}_D1_3112_{trade_type}.csv'\n",
    "    if not os.path.isfile(file_path):\n",
    "        df_pred.to_csv(file_path, index=True)\n",
    "    else:\n",
    "        df_pred.to_csv(file_path, mode='a', header=False, index=True)\n",
    "\n",
    "def process_pair(config, utc_from, utc_to):\n",
    "    logging.info(f\"Processing pair: {config['symbol']} for Buy and Sell\")\n",
    "    buyscaler, buymodel, sellscaler, sellmodel = None, None, None, None\n",
    "    try:\n",
    "        buyscaler = load(config[\"buy_scaler_path\"])\n",
    "        buymodel = load(config[\"buy_model_path\"])\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Buy model or scaler missing for {config['symbol']}: {e}\")\n",
    "        print(f\"Buy model or scaler missing for {config['symbol']}: {e}\")\n",
    "    try:\n",
    "        sellscaler = load(config[\"sell_scaler_path\"])\n",
    "        sellmodel = load(config[\"sell_model_path\"])\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Sell model or scaler missing for {config['symbol']}: {e}\")\n",
    "        print(f\"Sell model or scaler missing for {config['symbol']}: {e}\")\n",
    "    \n",
    "    with open(config[\"features_path\"], 'r') as f:\n",
    "        feature_names = json.load(f)\n",
    "    buy_features = feature_names[:-1]\n",
    "    sell_features = feature_names[:-1]\n",
    "\n",
    "    last_candle = fetch_latest_candle(config[\"symbol\"], config[\"timeframe\"])\n",
    "    if last_candle is None:\n",
    "        logging.error(f\"Failed to fetch initial candle data for {config['symbol']}.\")\n",
    "        print(f\"Failed to fetch initial candle data for {config['symbol']}.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            current_candle = fetch_latest_candle(config[\"symbol\"], config[\"timeframe\"])\n",
    "            if current_candle and current_candle['open'] != last_candle['open']:\n",
    "                if buyscaler is not None and buymodel is not None:\n",
    "                    predict_and_trade(\n",
    "                        buyscaler, buymodel, config[\"symbol\"], config[\"volume\"], config[\"timeframe\"],\n",
    "                        config[\"buy_risk_reward_ratio\"], config[\"mean_candle_size\"], utc_from, utc_to, buy_features, \"Buy\",\n",
    "                        threshold=config.get(\"buy_threshold\", None)\n",
    "                    )\n",
    "                if sellscaler is not None and sellmodel is not None:\n",
    "                    predict_and_trade(\n",
    "                        sellscaler, sellmodel, config[\"symbol\"], config[\"volume\"], config[\"timeframe\"],\n",
    "                        config[\"sell_risk_reward_ratio\"], config[\"mean_candle_size\"], utc_from, utc_to, sell_features, \"Sell\",\n",
    "                        threshold=config.get(\"sell_threshold\", None)\n",
    "                    )\n",
    "                last_candle = current_candle\n",
    "            time.sleep(60)\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(f\"Script terminated by user for {config['symbol']}.\")\n",
    "        print(f\"Script terminated by user for {config['symbol']}.\")\n",
    "    finally:\n",
    "        mt5.shutdown()\n",
    "        logging.info(f\"MetaTrader 5 connection closed for {config['symbol']}.\")\n",
    "        print(f\"MetaTrader 5 connection closed for {config['symbol']}.\")\n",
    "\n",
    "def main():\n",
    "    config = {'login': 51708234, 'password': '4bM&wuVJcBTnjV', 'server': 'ICMarketsEU-Demo'}\n",
    "    init_mt5_connection(config['login'], config['password'], config['server'])\n",
    "    \n",
    "    usdcad_config = {\n",
    "        \"symbol\": \"USDCAD\",\n",
    "        \"timeframe\": mt5.TIMEFRAME_D1,\n",
    "        \"volume\": 0.1,\n",
    "        \"mean_candle_size\": 0.088,\n",
    "        \"buy_risk_reward_ratio\": \"2:3\",\n",
    "        \"sell_risk_reward_ratio\": \"2:3\",\n",
    "        \"buy_scaler_path\": 'USDCAD_D1_3112_BuyNEW/scaler.joblib',\n",
    "        \"buy_model_path\": 'USDCAD_D1_3112_BuyNEW/model.joblib',\n",
    "        \"sell_scaler_path\": 'USDCAD_D1_3112_Sell/scaler.joblib',\n",
    "        \"sell_model_path\": 'USDCAD_D1_3112_Sell/model.joblib',\n",
    "        \"features_path\": 'USDCAD_D1_3112_Sell/feature_names.json'\n",
    "    }\n",
    "\n",
    "    utc_from = datetime(2023, 5, 1, tzinfo=pytz.utc)\n",
    "    utc_to = datetime.now(pytz.utc)\n",
    "\n",
    "    process_pair(usdcad_config, utc_from, utc_to)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forex_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
