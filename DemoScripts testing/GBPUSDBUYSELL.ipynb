{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MetaTrader 5\n",
      "Sell model or scaler missing for GBPUSD: [Errno 2] No such file or directory: 'GBPUSD_D1_3112_Sell/scaler_fold_1.joblib'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\site-packages\\tsfresh\\utilities\\dataframe_functions.py:520: UserWarning: Your time stamps are not uniformly sampled, which makes rolling nonsensical in some domains.\n",
      "  warnings.warn(\n",
      "Rolling: 100%|██████████| 36/36 [00:02<00:00, 13.06it/s]\n",
      "Feature Extraction: 100%|██████████| 35/35 [00:04<00:00,  7.23it/s]\n",
      "c:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\site-packages\\tsfresh\\utilities\\dataframe_functions.py:520: UserWarning: Your time stamps are not uniformly sampled, which makes rolling nonsensical in some domains.\n",
      "  warnings.warn(\n",
      "Rolling: 100%|██████████| 36/36 [00:02<00:00, 12.87it/s]\n",
      "Feature Extraction: 100%|██████████| 35/35 [00:08<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaTrader 5 connection closed for GBPUSD.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 206 elements, new values have 207 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 274\u001b[0m\n\u001b[0;32m    271\u001b[0m     process_pair(gbpusd_config, utc_from, utc_to)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 274\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 271\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    268\u001b[0m utc_from \u001b[38;5;241m=\u001b[39m datetime(\u001b[38;5;241m2023\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m, tzinfo\u001b[38;5;241m=\u001b[39mpytz\u001b[38;5;241m.\u001b[39mutc)\n\u001b[0;32m    269\u001b[0m utc_to \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow(pytz\u001b[38;5;241m.\u001b[39mutc)\n\u001b[1;32m--> 271\u001b[0m \u001b[43mprocess_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgbpusd_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc_from\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc_to\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 229\u001b[0m, in \u001b[0;36mprocess_pair\u001b[1;34m(config, utc_from, utc_to)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_candle \u001b[38;5;129;01mand\u001b[39;00m current_candle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m last_candle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buyscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m buymodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 229\u001b[0m         \u001b[43mpredict_and_trade\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbuyscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuymodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msymbol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvolume\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeframe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbuy_risk_reward_ratio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean_candle_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc_from\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuy_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBuy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m            \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbuy_threshold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sellscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m sellmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m         predict_and_trade(\n\u001b[0;32m    236\u001b[0m             sellscaler, sellmodel, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeframe\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    237\u001b[0m             config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msell_risk_reward_ratio\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_candle_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], utc_from, utc_to, sell_features, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSell\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    238\u001b[0m             threshold\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msell_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m         )\n",
      "Cell \u001b[1;32mIn[1], line 169\u001b[0m, in \u001b[0;36mpredict_and_trade\u001b[1;34m(scaler, model, symbol, volume, timeframe, risk_reward_ratio, mean_candle_size, start_date, end_date, features_json, trade_type, threshold)\u001b[0m\n\u001b[0;32m    167\u001b[0m original_index \u001b[38;5;241m=\u001b[39m df_processed\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m    168\u001b[0m df_processed \u001b[38;5;241m=\u001b[39m df_processed\u001b[38;5;241m.\u001b[39mshift(periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m--> 169\u001b[0m \u001b[43mdf_processed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m \u001b[38;5;241m=\u001b[39m original_index\n\u001b[0;32m    170\u001b[0m df_processed \u001b[38;5;241m=\u001b[39m align_features_with_json(df_processed, features_json)\n\u001b[0;32m    171\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of features for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrade_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_processed\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\site-packages\\pandas\\core\\generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6312\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6315\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\site-packages\\pandas\\core\\generic.py:814\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    813\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\site-packages\\pandas\\core\\internals\\base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 206 elements, new values have 207 elements"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import time\n",
    "from joblib import load\n",
    "import logging\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, impute\n",
    "import talib\n",
    "import os\n",
    "import threading\n",
    "\n",
    "logging.basicConfig(filename='trading_GBPUSD_Buy_Sell_D1.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def init_mt5_connection(login, password, server):\n",
    "    if not mt5.initialize(login=login, password=password, server=server):\n",
    "        logging.error(f\"initialize() failed, error code = {mt5.last_error()}\")\n",
    "        sys.exit()\n",
    "    logging.info(\"Connected to MetaTrader 5\")\n",
    "    print(\"Connected to MetaTrader 5\")\n",
    "\n",
    "def fetch_latest_candle(symbol, timeframe):\n",
    "    latest_candles = mt5.copy_rates_from_pos(symbol, timeframe, 0, 1)\n",
    "    return latest_candles[0] if len(latest_candles) > 0 else None\n",
    "\n",
    "def fetch_historical_data(symbol, timeframe, start_date, end_date):\n",
    "    logging.info(f\"Fetching historical data for {symbol}\")\n",
    "    data = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    ohlc_data = pd.DataFrame(data)\n",
    "    ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "    return ohlc_data[['time', 'open', 'high', 'low', 'close']]\n",
    "\n",
    "def add_rolling_features(df, window):\n",
    "    logging.info(\"Adding rolling features\")\n",
    "    df['rolling_mean_open'] = df['open'].rolling(window=window).mean()\n",
    "    df['rolling_std_open'] = df['open'].rolling(window=window).std()\n",
    "    df['rolling_mean_close'] = df['close'].rolling(window=window).mean()\n",
    "    df['rolling_std_close'] = df['close'].rolling(window=window).std()\n",
    "    df['rolling_mean_high'] = df['high'].rolling(window=window).mean()\n",
    "    df['rolling_std_high'] = df['high'].rolling(window=window).std()\n",
    "    df['rolling_mean_low'] = df['low'].rolling(window=window).mean()\n",
    "    df['rolling_std_low'] = df['low'].rolling(window=window).std()\n",
    "    return df\n",
    "\n",
    "def add_lag_features(df, lags):\n",
    "    logging.info(\"Adding lag features\")\n",
    "    for lag in lags:\n",
    "        df[f'open_lag_{lag}'] = df['open'].shift(lag)\n",
    "        df[f'close_lag_{lag}'] = df['close'].shift(lag)\n",
    "        df[f'high_lag_{lag}'] = df['high'].shift(lag)\n",
    "        df[f'low_lag_{lag}'] = df['low'].shift(lag)\n",
    "    return df\n",
    "\n",
    "def calculate_indicators(df):\n",
    "    logging.info(\"Calculating indicators\")\n",
    "    for period in [15, 23, 42, 145]:\n",
    "        df[f'WILLR_{period}'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=period)\n",
    "    return df\n",
    "\n",
    "def align_features_with_json(df, features_json):\n",
    "    expected_features = features_json\n",
    "    missing_features = [feat for feat in expected_features if feat not in df.columns]\n",
    "    extra_features = [feat for feat in df.columns if feat not in expected_features]\n",
    "    \n",
    "    logging.info(f\"Missing features: {missing_features}\")\n",
    "    logging.info(f\"Extra features: {extra_features}\")\n",
    "    \n",
    "    for feat in missing_features:\n",
    "        df[feat] = 0\n",
    "\n",
    "    df = df[expected_features]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_data_for_features(df, symbol, signals, selected_features):\n",
    "    logging.info(f\"Processing data for feature extraction for {symbol}\")\n",
    "    X_combined = pd.DataFrame(index=df['time'])\n",
    "    \n",
    "    for signal in signals:\n",
    "        df_melted = df[['time', signal]].copy()\n",
    "        df_melted[\"Symbols\"] = symbol\n",
    "        df_rolled = roll_time_series(df_melted, column_id=\"Symbols\", column_sort=\"time\", max_timeshift=20, min_timeshift=5)\n",
    "        X = extract_features(df_rolled.drop(\"Symbols\", axis=1), column_id=\"id\", column_sort=\"time\", column_value=signal, impute_function=impute, show_warnings=False)\n",
    "        X = X.set_index(X.index.map(lambda x: x[1]), drop=True)\n",
    "        selected_features_X = [feature for feature in selected_features if feature in X.columns]\n",
    "        X_filtered = X[selected_features_X]\n",
    "        X_combined = X_combined.merge(X_filtered, left_index=True, right_index=True, how='left')\n",
    "        X_combined = X_combined.dropna()\n",
    "    return X_combined\n",
    "\n",
    "def fetch_and_process_data(symbol, timeframe, signals, selected_features, start_date, end_date):\n",
    "    logging.info(f\"Fetching and processing data for {symbol}\")\n",
    "    df = fetch_historical_data(symbol, timeframe, start_date, end_date)\n",
    "    df = calculate_indicators(df)\n",
    "    df = add_rolling_features(df, window=5)\n",
    "    df = add_lag_features(df, lags=[1, 2, 3, 4, 5])\n",
    "    \n",
    "    logging.info(f\"NaNs before drop for {symbol}: {df.isnull().sum().sum()}\")\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    logging.info(f\"NaNs after drop for {symbol}: {df.isnull().sum().sum()}\")\n",
    "\n",
    "    features = process_data_for_features(df, symbol, signals, selected_features)\n",
    "    df = df.set_index('time')\n",
    "    combined_df = df.merge(features, left_index=True, right_index=True, how='left')\n",
    "    combined_df = combined_df[selected_features]\n",
    "    logging.info(f\"NaNs after merging for {symbol}: {combined_df.isnull().sum().sum()}\")\n",
    "    combined_df = combined_df.dropna()\n",
    "    logging.info(f\"Final NaNs for {symbol}: {combined_df.isnull().sum().sum()}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "def calculate_prices(entry_price, risk_reward_ratio, mean_candle_size):\n",
    "    logging.info(\"Calculating SL and TP prices\")\n",
    "    risk_part, reward_part = map(int, risk_reward_ratio.split(':'))\n",
    "    risk_amount = mean_candle_size * risk_part\n",
    "    reward_amount = mean_candle_size * reward_part\n",
    "    sl_price = entry_price - risk_amount\n",
    "    tp_price = entry_price + reward_amount\n",
    "    return sl_price, tp_price\n",
    "\n",
    "def place_order(symbol, volume, sl_price, tp_price, trade_type):\n",
    "    logging.info(f\"Placing {trade_type} order for {symbol}\")\n",
    "    \n",
    "    symbol_info = mt5.symbol_info(symbol)\n",
    "    if symbol_info is None or not symbol_info.visible or symbol_info.trade_mode == mt5.SYMBOL_TRADE_MODE_DISABLED:\n",
    "        logging.error(f\"Market for {symbol} is closed or unavailable.\")\n",
    "        print(f\"Market for {symbol} is closed. Cannot place order.\")\n",
    "        return\n",
    "\n",
    "    price = mt5.symbol_info_tick(symbol).ask if trade_type == \"Buy\" else mt5.symbol_info_tick(symbol).bid\n",
    "    order_type = mt5.ORDER_TYPE_BUY if trade_type == \"Buy\" else mt5.ORDER_TYPE_SELL\n",
    "    \n",
    "    request = {\n",
    "        \"action\": mt5.TRADE_ACTION_DEAL,\n",
    "        \"symbol\": symbol,\n",
    "        \"volume\": volume,\n",
    "        \"type\": order_type,\n",
    "        \"price\": price,\n",
    "        \"sl\": sl_price,\n",
    "        \"tp\": tp_price,\n",
    "        \"deviation\": 10,\n",
    "        \"magic\": 0,\n",
    "        \"comment\": f\"Python script {trade_type} order\",\n",
    "        \"type_time\": mt5.ORDER_TIME_GTC,\n",
    "        \"type_filling\": mt5.ORDER_FILLING_IOC,\n",
    "    }\n",
    "    \n",
    "    result = mt5.order_send(request)\n",
    "    \n",
    "    if result and result.retcode == mt5.TRADE_RETCODE_DONE:\n",
    "        logging.info(f\"{trade_type} order placed successfully for {symbol}.\")\n",
    "        print(f\"{trade_type} order placed successfully for {symbol}.\")\n",
    "    else:\n",
    "        logging.error(f\"Order placement failed for {symbol}: {result.retcode} - {mt5.last_error()}\")\n",
    "        print(f\"Order placement failed for {symbol}: {result.retcode} - {mt5.last_error()}\")\n",
    "\n",
    "def apply_custom_threshold(probas, custom_threshold):\n",
    "    return (probas >= custom_threshold).astype(int)\n",
    "\n",
    "def predict_and_trade(scaler, model, symbol, volume, timeframe, risk_reward_ratio, mean_candle_size, start_date, end_date, features_json, trade_type, threshold=None):\n",
    "    logging.info(f\"Starting prediction and trading process for {symbol} - {trade_type}\")\n",
    "    signals = ['WILLR_15', 'WILLR_42']\n",
    "    df_processed = fetch_and_process_data(symbol, timeframe, signals, features_json, start_date, end_date)\n",
    "    original_index = df_processed.index\n",
    "    df_processed = df_processed.shift(periods=1, axis=0).dropna()\n",
    "    df_processed.index = original_index\n",
    "    df_processed = align_features_with_json(df_processed, features_json)\n",
    "    logging.info(f\"Number of features for {symbol} - {trade_type}: {df_processed.shape[1]}\")\n",
    "    scaled_data = scaler.transform(df_processed)\n",
    "    probas = model.predict_proba(scaled_data)[:, 1]\n",
    "    custom_threshold = threshold if threshold is not None else 0.5\n",
    "    y_pred = apply_custom_threshold(probas, custom_threshold)\n",
    "    \n",
    "    df_pred = pd.DataFrame(index=df_processed.index)\n",
    "    df_pred['prediction'] = y_pred\n",
    "    save_predictions_to_csv(df_pred, symbol, trade_type)\n",
    "    \n",
    "    if len(y_pred) > 1 and y_pred[-1] == 1:\n",
    "        entry_price = mt5.symbol_info_tick(symbol).ask if trade_type == \"Buy\" else mt5.symbol_info_tick(symbol).bid\n",
    "        sl_price, tp_price = calculate_prices(entry_price, risk_reward_ratio, mean_candle_size)\n",
    "        place_order(symbol, volume, sl_price, tp_price, trade_type)\n",
    "    else:\n",
    "        logging.info(f\"No {trade_type} signal generated for {symbol}. Doing nothing.\")\n",
    "        print(f\"No {trade_type} signal generated for {symbol}. Doing nothing.\")\n",
    "\n",
    "def save_predictions_to_csv(df_pred, symbol, trade_type):\n",
    "    logging.info(f\"Saving {trade_type} predictions to CSV for {symbol}\")\n",
    "    file_path = f'predict_{symbol}_D1_3112_{trade_type}.csv'\n",
    "    if not os.path.isfile(file_path):\n",
    "        df_pred.to_csv(file_path, index=True)\n",
    "    else:\n",
    "        df_pred.to_csv(file_path, mode='a', header=False, index=True)\n",
    "\n",
    "def process_pair(config, utc_from, utc_to):\n",
    "    logging.info(f\"Processing pair: {config['symbol']} for Buy and Sell\")\n",
    "    buyscaler, buymodel, sellscaler, sellmodel = None, None, None, None\n",
    "    try:\n",
    "        buyscaler = load(config[\"buy_scaler_path\"])\n",
    "        buymodel = load(config[\"buy_model_path\"])\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Buy model or scaler missing for {config['symbol']}: {e}\")\n",
    "        print(f\"Buy model or scaler missing for {config['symbol']}: {e}\")\n",
    "    try:\n",
    "        sellscaler = load(config[\"sell_scaler_path\"])\n",
    "        sellmodel = load(config[\"sell_model_path\"])\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Sell model or scaler missing for {config['symbol']}: {e}\")\n",
    "        print(f\"Sell model or scaler missing for {config['symbol']}: {e}\")\n",
    "    \n",
    "    with open(config[\"features_path\"], 'r') as f:\n",
    "        feature_names = json.load(f)\n",
    "    buy_features = feature_names[:-1]\n",
    "    sell_features = feature_names[:-1]\n",
    "\n",
    "    last_candle = fetch_latest_candle(config[\"symbol\"], config[\"timeframe\"])\n",
    "    if last_candle is None:\n",
    "        logging.error(f\"Failed to fetch initial candle data for {config['symbol']}.\")\n",
    "        print(f\"Failed to fetch initial candle data for {config['symbol']}.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            current_candle = fetch_latest_candle(config[\"symbol\"], config[\"timeframe\"])\n",
    "            if current_candle and current_candle['open'] != last_candle['open']:\n",
    "                if buyscaler is not None and buymodel is not None:\n",
    "                    predict_and_trade(\n",
    "                        buyscaler, buymodel, config[\"symbol\"], config[\"volume\"], config[\"timeframe\"],\n",
    "                        config[\"buy_risk_reward_ratio\"], config[\"mean_candle_size\"], utc_from, utc_to, buy_features, \"Buy\",\n",
    "                        threshold=config.get(\"buy_threshold\", None)\n",
    "                    )\n",
    "                if sellscaler is not None and sellmodel is not None:\n",
    "                    predict_and_trade(\n",
    "                        sellscaler, sellmodel, config[\"symbol\"], config[\"volume\"], config[\"timeframe\"],\n",
    "                        config[\"sell_risk_reward_ratio\"], config[\"mean_candle_size\"], utc_from, utc_to, sell_features, \"Sell\",\n",
    "                        threshold=config.get(\"sell_threshold\", None)\n",
    "                    )\n",
    "                last_candle = current_candle\n",
    "            time.sleep(60)\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(f\"Script terminated by user for {config['symbol']}.\")\n",
    "        print(f\"Script terminated by user for {config['symbol']}.\")\n",
    "    finally:\n",
    "        mt5.shutdown()\n",
    "        logging.info(f\"MetaTrader 5 connection closed for {config['symbol']}.\")\n",
    "        print(f\"MetaTrader 5 connection closed for {config['symbol']}.\")\n",
    "\n",
    "def main():\n",
    "    config = {'login': 51708234, 'password': '4bM&wuVJcBTnjV', 'server': 'ICMarketsEU-Demo'}\n",
    "    init_mt5_connection(config['login'], config['password'], config['server'])\n",
    "    \n",
    "    gbpusd_config = {\n",
    "        \"symbol\": \"GBPUSD\",\n",
    "        \"timeframe\": mt5.TIMEFRAME_D1,\n",
    "        \"volume\": 0.1,\n",
    "        \"mean_candle_size\": 0.013,\n",
    "        \"buy_risk_reward_ratio\": \"1:1\",\n",
    "        \"buy_scaler_path\": 'GBPUSD_D1_3112_NEWBuy/scaler_fold_1.joblib',\n",
    "        \"buy_model_path\": 'GBPUSD_D1_3112_NEWBuy/best_model_fold_1.joblib',\n",
    "        \"sell_scaler_path\": 'GBPUSD_D1_3112_Sell/scaler_fold_1.joblib',\n",
    "        \"sell_model_path\": 'GBPUSD_D1_3112_Sell/best_model_fold_1.joblib',\n",
    "        \"features_path\": 'GBPUSD_D1_3112_NEWBuy/feature_names.json',\n",
    "        \"buy_threshold\": 0.55\n",
    "    }\n",
    "\n",
    "    utc_from = datetime(2023, 5, 1, tzinfo=pytz.utc)\n",
    "    utc_to = datetime.now(pytz.utc)\n",
    "\n",
    "    process_pair(gbpusd_config, utc_from, utc_to)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import time\n",
    "from joblib import load\n",
    "import logging\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, impute\n",
    "import talib\n",
    "import os\n",
    "import threading\n",
    "\n",
    "logging.basicConfig(filename='trading_GBPUSDCAD_Buy_D1.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Function to load configuration (adjusted for direct input in notebook)\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as config_file:\n",
    "        return json.load(config_file)\n",
    "\n",
    "# Initialize connection to MetaTrader 5\n",
    "def init_mt5_connection(login, password, server):\n",
    "    if not mt5.initialize(login=login, password=password, server=server):\n",
    "        logging.error(f\"initialize() failed, error code = {mt5.last_error()}\")\n",
    "        sys.exit()\n",
    "    logging.info(\"Connected to MetaTrader 5\")\n",
    "    print(\"Connected to MetaTrader 5\")\n",
    "\n",
    "# Fetch the latest candle\n",
    "def fetch_latest_candle(symbol, timeframe):\n",
    "    latest_candles = mt5.copy_rates_from_pos(symbol, timeframe, 0, 1)\n",
    "    return latest_candles[0] if len(latest_candles) > 0 else None\n",
    "\n",
    "# Fetch historical data\n",
    "def fetch_historical_data(symbol, timeframe, start_date, end_date):\n",
    "    logging.info(f\"Fetching historical data for {symbol}\")\n",
    "    print(f\"Fetching historical data for {symbol}\")\n",
    "    data = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    ohlc_data = pd.DataFrame(data)\n",
    "    ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "    return ohlc_data[['time', 'open', 'high', 'low', 'close']]\n",
    "\n",
    "def add_rolling_features(df, window):\n",
    "    logging.info(\"Adding rolling features\")\n",
    "    df['rolling_mean_open'] = df['open'].rolling(window=window).mean()\n",
    "    df['rolling_std_open'] = df['open'].rolling(window=window).std()\n",
    "    df['rolling_mean_close'] = df['close'].rolling(window=window).mean()\n",
    "    df['rolling_std_close'] = df['close'].rolling(window=window).std()\n",
    "    df['rolling_mean_high'] = df['high'].rolling(window=window).mean()\n",
    "    df['rolling_std_high'] = df['high'].rolling(window=window).std()\n",
    "    df['rolling_mean_low'] = df['low'].rolling(window=window).mean()\n",
    "    df['rolling_std_low'] = df['low'].rolling(window=window).std()\n",
    "    return df\n",
    "\n",
    "# Function to add lag features\n",
    "def add_lag_features(df, lags):\n",
    "    logging.info(\"Adding lag features\")\n",
    "    for lag in lags:\n",
    "        df[f'open_lag_{lag}'] = df['open'].shift(lag)\n",
    "        df[f'close_lag_{lag}'] = df['close'].shift(lag)\n",
    "        df[f'high_lag_{lag}'] = df['high'].shift(lag)\n",
    "        df[f'low_lag_{lag}'] = df['low'].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Calculate indicators\n",
    "def calculate_indicators(df):\n",
    "    logging.info(\"Calculating indicators\")\n",
    "    for period in [15, 23, 42, 145]:\n",
    "        df[f'WILLR_{period}'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=period)\n",
    "    return df\n",
    "\n",
    "# Process data for feature extraction\n",
    "def process_data_for_features(df, symbol, signals, selected_features):\n",
    "    logging.info(f\"Processing data for feature extraction for {symbol}\")\n",
    "    X_combined = pd.DataFrame(index=df['time'])\n",
    "    \n",
    "    for signal in signals:\n",
    "        df_melted = df[['time', signal]].copy()\n",
    "        df_melted[\"Symbols\"] = symbol\n",
    "        df_rolled = roll_time_series(df_melted, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                                     max_timeshift=20, min_timeshift=5)\n",
    "        X = extract_features(df_rolled.drop(\"Symbols\", axis=1), column_id=\"id\", column_sort=\"time\", \n",
    "                             column_value=signal, impute_function=impute, show_warnings=False)\n",
    "        X = X.set_index(X.index.map(lambda x: x[1]), drop=True)\n",
    "        \n",
    "        # Filter features\n",
    "        selected_features_X = [feature for feature in selected_features if feature in X.columns]\n",
    "        X_filtered = X[selected_features_X]\n",
    "        \n",
    "        X_combined = X_combined.merge(X_filtered, left_index=True, right_index=True, how='left')\n",
    "        X_combined = X_combined.dropna()\n",
    "    return X_combined\n",
    "\n",
    "# Combine buy data\n",
    "def fetch_and_process_data(symbol, timeframe, signals, selected_features, start_date, end_date):\n",
    "    logging.info(f\"Fetching and processing data for {symbol}\")\n",
    "    print(f\"Fetching and processing data for {symbol}\")\n",
    "    df = fetch_historical_data(symbol, timeframe, start_date, end_date)\n",
    "    df = calculate_indicators(df)\n",
    "    df = add_rolling_features(df, window=5)\n",
    "    df = add_lag_features(df, lags=[1, 2, 3, 4, 5])\n",
    "    \n",
    "    # Log the number of NaNs before dropping\n",
    "    logging.info(f\"NaNs before drop for {symbol}: {df.isnull().sum().sum()}\")\n",
    "\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    # Log the state after dropping NaNs\n",
    "    logging.info(f\"NaNs after drop for {symbol}: {df.isnull().sum().sum()}\")\n",
    "\n",
    "    features = process_data_for_features(df, symbol, signals, selected_features)\n",
    "    df = df.set_index('time')\n",
    "    combined_df = df.merge(features, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # Handle missing values in the combined dataset\n",
    "    combined_df = combined_df[selected_features]\n",
    "    \n",
    "    # Log the state of NaNs after merging\n",
    "    logging.info(f\"NaNs after merging for {symbol}: {combined_df.isnull().sum().sum()}\")\n",
    "    \n",
    "    combined_df = combined_df.dropna()\n",
    "    \n",
    "    # Log final NaN count\n",
    "    logging.info(f\"Final NaNs for {symbol}: {combined_df.isnull().sum().sum()}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Calculate SL and TP based on entry price and specified percentages\n",
    "def calculate_prices(entry_price, risk_reward_ratio, mean_candle_size):\n",
    "    logging.info(\"Calculating SL and TP prices\")\n",
    "    risk_part, reward_part = map(int, risk_reward_ratio.split(':'))\n",
    "    risk_amount = mean_candle_size * risk_part\n",
    "    reward_amount = mean_candle_size * reward_part\n",
    "    sl_price = entry_price - risk_amount\n",
    "    tp_price = entry_price + reward_amount\n",
    "    return sl_price, tp_price\n",
    "\n",
    "# Place order\n",
    "def place_order(symbol, volume, sl_price, tp_price):\n",
    "    logging.info(f\"Placing order for {symbol}\")\n",
    "    \n",
    "    # Check if the market is open for the symbol\n",
    "    symbol_info = mt5.symbol_info(symbol)\n",
    "    if symbol_info is None:\n",
    "        logging.error(f\"Failed to get symbol info for {symbol}.\")\n",
    "        return\n",
    "    \n",
    "    if not symbol_info.visible or symbol_info.trade_mode == mt5.SYMBOL_TRADE_MODE_DISABLED:\n",
    "        logging.error(f\"Market for {symbol} is currently closed or not available for trading.\")\n",
    "        print(f\"Market for {symbol} is closed. Cannot place order.\")\n",
    "        return\n",
    "\n",
    "    # Proceed with order placement\n",
    "    price = mt5.symbol_info_tick(symbol).ask\n",
    "    \n",
    "    request = {\n",
    "        \"action\": mt5.TRADE_ACTION_DEAL,\n",
    "        \"symbol\": symbol,\n",
    "        \"volume\": volume,\n",
    "        \"type\": mt5.ORDER_TYPE_BUY,\n",
    "        \"price\": price,\n",
    "        \"sl\": sl_price,\n",
    "        \"tp\": tp_price,\n",
    "        \"deviation\": 10,\n",
    "        \"magic\": 0,\n",
    "        \"comment\": \"Python script open\",\n",
    "        \"type_time\": mt5.ORDER_TIME_GTC,\n",
    "        \"type_filling\": mt5.ORDER_FILLING_IOC,\n",
    "    }\n",
    "    \n",
    "    result = mt5.order_send(request)\n",
    "    \n",
    "    if result and result.retcode == mt5.TRADE_RETCODE_DONE:\n",
    "        logging.info(f\"Order placed successfully for {symbol}.\")\n",
    "        print(f\"Order placed successfully for {symbol}.\")\n",
    "    elif result.retcode == 10018:  # Market closed\n",
    "        logging.error(f\"Market closed for {symbol}. Order not placed.\")\n",
    "        print(f\"Market closed for {symbol}. Order not placed.\")\n",
    "    else:\n",
    "        logging.error(f\"Order placement failed for {symbol}: {result.retcode if result else 'No response'} - {mt5.last_error()}\")\n",
    "        print(f\"Order placement failed for {symbol}: {result.retcode if result else 'No response'} - {mt5.last_error()}\")\n",
    "\n",
    "\n",
    "# Function to apply the custom threshold\n",
    "def apply_custom_threshold(probas, custom_threshold):\n",
    "    return (probas >= custom_threshold).astype(int)\n",
    "\n",
    "# Predict and trade\n",
    "def predict_and_trade(buyscaler, buymodel, symbol, volume, timeframe, risk_reward_ratio, mean_candle_size, start_date, end_date, buy_features):\n",
    "    logging.info(f\"Starting prediction and trading process for {symbol}\")\n",
    "    print(f\"Starting prediction and trading process for {symbol}\")\n",
    "    buy_signals = ['WILLR_15', 'WILLR_42']\n",
    "    \n",
    "    # Fetch and process data\n",
    "    df_buy = fetch_and_process_data(symbol, timeframe, buy_signals, buy_features, start_date, end_date)\n",
    "\n",
    "    # Shift the data as was done during training\n",
    "    logging.info(f\"Shifting the data for {symbol}\")\n",
    "    original_index = df_buy.index\n",
    "    shifted_df_buy = df_buy.shift(periods=1, axis=0)\n",
    "    shifted_df_buy.index = original_index\n",
    "    df_buy = shifted_df_buy.dropna()  # Drop NaNs after shifting\n",
    "\n",
    "    # Align the features with what the scaler expects\n",
    "    df_buy = df_buy[buy_features]\n",
    "\n",
    "    # Scale the data\n",
    "    logging.info(f\"Scaling the data for {symbol}\")\n",
    "    scaled_buy = buyscaler.transform(df_buy)\n",
    "    \n",
    "    # Predict probabilities and apply custom threshold\n",
    "    logging.info(f\"Predicting for {symbol}\")\n",
    "    probas_buy = buymodel.predict_proba(scaled_buy)[:, 1]\n",
    "    custom_threshold = 0.5  # If you have a specific threshold, set it here\n",
    "    y_pred = apply_custom_threshold(probas_buy, custom_threshold)\n",
    "    \n",
    "    # Create a DataFrame to hold prediction data with index matching test data\n",
    "    df_pred = pd.DataFrame(index=df_buy.index)\n",
    "    df_pred['prediction'] = y_pred\n",
    "    \n",
    "    # Save predictions to CSV\n",
    "    save_predictions_to_csv(df_pred, symbol)\n",
    "    \n",
    "    if len(y_pred) > 1 and y_pred[-1] == 1:  # If the second-last prediction is a buy signal\n",
    "        entry_price = mt5.symbol_info_tick(symbol).ask\n",
    "        sl_price, tp_price = calculate_prices(entry_price, risk_reward_ratio, mean_candle_size)\n",
    "        place_order(symbol, volume, sl_price, tp_price)\n",
    "    else:\n",
    "        logging.info(f\"No Buy signal generated for {symbol}. Doing nothing.\")\n",
    "        print(f\"No Buy signal generated for {symbol}. Doing nothing.\")\n",
    "\n",
    "\n",
    "def save_predictions_to_csv(df_pred, symbol):\n",
    "    logging.info(f\"Saving predictions to CSV for {symbol}\")\n",
    "    file_path = f'predict_{symbol}_D1_3112_Buy.csv'\n",
    "    if not os.path.isfile(file_path):\n",
    "        df_pred.to_csv(file_path, index=True)\n",
    "    else:\n",
    "        df_pred.to_csv(file_path, mode='a', header=False, index=True)\n",
    "\n",
    "# Function to process each pair in a separate thread\n",
    "def process_pair(config, utc_from, utc_to):\n",
    "    logging.info(f\"Processing pair: {config['symbol']}\")\n",
    "    print(f\"Processing pair: {config['symbol']}\")\n",
    "    \n",
    "    buyscaler = load(config[\"scaler_path\"])\n",
    "    buymodel = load(config[\"model_path\"])\n",
    "    with open(config[\"features_path\"], 'r') as f:\n",
    "        feature_names = json.load(f)\n",
    "    buy_features = feature_names[:-1]  # Exclude the last feature from the list\n",
    "\n",
    "    last_candle = fetch_latest_candle(config[\"symbol\"], config[\"timeframe\"])\n",
    "    if last_candle is None:\n",
    "        logging.error(f\"Failed to fetch initial candle data for {config['symbol']}.\")\n",
    "        print(f\"Failed to fetch initial candle data for {config['symbol']}.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            current_candle = fetch_latest_candle(config[\"symbol\"], config[\"timeframe\"])\n",
    "            if current_candle and current_candle['open'] != last_candle['open']:\n",
    "                predict_and_trade(\n",
    "                    buyscaler, buymodel, config[\"symbol\"], config[\"volume\"], config[\"timeframe\"],\n",
    "                    config[\"risk_reward_ratio\"], config[\"mean_candle_size\"], utc_from, utc_to, buy_features\n",
    "                )\n",
    "                last_candle = current_candle\n",
    "            time.sleep(60)\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(f\"Script terminated by user for {config['symbol']}.\")\n",
    "        print(f\"Script terminated by user for {config['symbol']}.\")\n",
    "    finally:\n",
    "        mt5.shutdown()\n",
    "        logging.info(f\"MetaTrader 5 connection closed for {config['symbol']}.\")\n",
    "        print(f\"MetaTrader 5 connection closed for {config['symbol']}.\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Sample configuration, replace with your actual configuration details\n",
    "    config = {'login': 51708234, 'password': '4bM&wuVJcBTnjV', 'server': 'ICMarketsEU-Demo'}\n",
    "\n",
    "    init_mt5_connection(config['login'], config['password'], config['server'])\n",
    "    \n",
    "    # Configuration for GBPUSD\n",
    "    gbpusd_config = {\n",
    "        \"symbol\": \"GBPUSD\",\n",
    "        \"timeframe\": mt5.TIMEFRAME_D1,\n",
    "        \"volume\": 0.1,\n",
    "        \"mean_candle_size\": 0.013,\n",
    "        \"risk_reward_ratio\": \"1:1\",\n",
    "        \"scaler_path\": 'GBPUSD_D1_3112_NEWBuy/scaler_fold_1.joblib',\n",
    "        \"model_path\": 'GBPUSD_D1_3112_NEWBuy/best_model_fold_1.joblib',\n",
    "        \"features_path\": 'GBPUSD_D1_3112_NEWBuy/feature_names.json'\n",
    "    }\n",
    "\n",
    "    # Configuration for USDCAD\n",
    "    usdcad_config = {\n",
    "        \"symbol\": \"USDCAD\",\n",
    "        \"timeframe\": mt5.TIMEFRAME_D1,\n",
    "        \"volume\": 0.1,\n",
    "        \"mean_candle_size\": 0.088,\n",
    "        \"risk_reward_ratio\": \"2:3\",\n",
    "        \"scaler_path\": 'USDCAD_D1_3112_BuyNEW/scaler.joblib',\n",
    "        \"model_path\": 'USDCAD_D1_3112_BuyNEW/model.joblib',\n",
    "        \"features_path\": 'USDCAD_D1_3112_BuyNEW/feature_names.json' \n",
    "    }\n",
    "\n",
    "    # Load the configurations\n",
    "    configs = [gbpusd_config, usdcad_config]\n",
    "\n",
    "    utc_from = datetime(2023, 5, 1, tzinfo=pytz.utc)\n",
    "    utc_to = datetime.now(pytz.utc)\n",
    "\n",
    "    threads = []\n",
    "    for config in configs:\n",
    "        thread = threading.Thread(target=process_pair, args=(config, utc_from, utc_to))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forex_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
