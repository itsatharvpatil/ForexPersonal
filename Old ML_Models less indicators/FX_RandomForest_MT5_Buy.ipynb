{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cbb1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import talib\n",
    "from talipp.indicators import EMA, SMA, Stoch, DPO\n",
    "from joblib import dump\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, confusion_matrix, classification_report\n",
    "from own_functions import *\n",
    "import os\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, make_forecasting_frame\n",
    "from tsfresh.utilities.dataframe_functions import impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1149e9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.initialize()\n",
    "login = 51708234\n",
    "password =\"4bM&wuVJcBTnjV\"\n",
    "server = \"ICMarketsEU-Demo\"\n",
    "mt.login(login,password,server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7cca420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" csv_file_path = 'ICMT5EURUSD2010_3112_D1.csv'  # Specify your desired path\\ndf.to_csv(csv_file_path, index=False)\\ndf \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol = \"USDCAD\"\n",
    "timeframe = mt.TIMEFRAME_D1\n",
    "ohlc_data = pd.DataFrame(mt.copy_rates_range(symbol, timeframe, datetime(2010, 1, 1), datetime(2024, 10, 8)))\n",
    "ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "df = ohlc_data[['time', 'open', 'high', 'low', 'close']].copy()\n",
    "\n",
    "\n",
    "def add_rolling_features(df, window):\n",
    "    df['rolling_mean_open'] = df['open'].rolling(window=window).mean()\n",
    "    df['rolling_std_open'] = df['open'].rolling(window=window).std()\n",
    "    df['rolling_mean_close'] = df['close'].rolling(window=window).mean()\n",
    "    df['rolling_std_close'] = df['close'].rolling(window=window).std()\n",
    "    df['rolling_mean_high'] = df['high'].rolling(window=window).mean()\n",
    "    df['rolling_std_high'] = df['high'].rolling(window=window).std()\n",
    "    df['rolling_mean_low'] = df['low'].rolling(window=window).mean()\n",
    "    df['rolling_std_low'] = df['low'].rolling(window=window).std()\n",
    "    return df\n",
    "\n",
    "# Function to add lag features\n",
    "def add_lag_features(df, lags):\n",
    "    for lag in lags:\n",
    "        df[f'open_lag_{lag}'] = df['open'].shift(lag)\n",
    "        df[f'close_lag_{lag}'] = df['close'].shift(lag)\n",
    "        df[f'high_lag_{lag}'] = df['high'].shift(lag)\n",
    "        df[f'low_lag_{lag}'] = df['low'].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Indicators\n",
    "# Calculate indicators\n",
    "df['WILLR_15'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=15)\n",
    "df['WILLR_23'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=23)\n",
    "df['WILLR_42'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=42)\n",
    "df['WILLR_145'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=145)\n",
    "\n",
    "df = add_rolling_features(df, window=5)\n",
    "df = add_lag_features(df, lags=[1, 2, 3, 4, 5])\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Buy & Sell Flags\n",
    "df['b_flag'] = 0\n",
    "df['s_flag'] = 0\n",
    "\n",
    "# Dropping NaN values and resetting index\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "\"\"\" csv_file_path = 'ICMT5EURUSD2010_3112_D1.csv'  # Specify your desired path\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "df \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118e1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visual Inspection: Plot the time series data\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['time'], df['close'], label='Close Price')\n",
    "plt.title('GBPUSD Close Price')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Summary Statistics\n",
    "print(df[['open', 'high', 'low', 'close', 'WILLR_15', 'WILLR_23', 'WILLR_42', 'WILLR_145']].describe())\n",
    "\n",
    "# Outlier Detection using IQR\n",
    "def detect_outliers_iqr(data):\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR)))\n",
    "    return outliers\n",
    "\n",
    "outliers = df[['open', 'high', 'low', 'close']].apply(detect_outliers_iqr)\n",
    "print(outliers.sum())  # Count of outliers in each column\n",
    "\n",
    "# Plotting boxplots to visualize outliers\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(data=df[['open', 'high', 'low', 'close']])\n",
    "plt.title('Boxplot of OHLC Prices')\n",
    "plt.show()\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a1ee607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Candle: 0.00637524509803922\n"
     ]
    }
   ],
   "source": [
    "StopLoss = 2\n",
    "TakeProfit = 3\n",
    "BreakEvenRatio=StopLoss/(StopLoss+TakeProfit)\n",
    "label_data(df,[StopLoss],[TakeProfit],80,symbol,False)\n",
    "#print('BreatEvenRatio:', BreakEvenRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d36f2e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of 1s:\n",
      "b_flag: 81\n",
      "s_flag: 24\n",
      "\n",
      "Counts in segments of 100% data:\n",
      "b_flag: 81\n",
      "s_flag: 24\n",
      "\n",
      "Counts in intervals of 10%:\n",
      "0% - 10%: b_flag=0, s_flag=20\n",
      "10% - 20%: b_flag=15, s_flag=2\n",
      "20% - 30%: b_flag=19, s_flag=0\n",
      "30% - 40%: b_flag=14, s_flag=0\n",
      "40% - 50%: b_flag=21, s_flag=0\n",
      "50% - 60%: b_flag=11, s_flag=2\n",
      "60% - 70%: b_flag=1, s_flag=0\n",
      "70% - 80%: b_flag=0, s_flag=0\n",
      "80% - 90%: b_flag=0, s_flag=0\n",
      "90% - 100%: b_flag=0, s_flag=0\n",
      "100% - 110%: b_flag=0, s_flag=0\n"
     ]
    }
   ],
   "source": [
    "# Calculate total number of 1s in b_flag and s_flag columns\n",
    "total_b_flags = df['b_flag'].sum()\n",
    "total_s_flags = df['s_flag'].sum()\n",
    "\n",
    "# Total number of rows in the DataFrame\n",
    "total_rows = len(df)\n",
    "\n",
    "# Calculate counts in segments of complete 100% data\n",
    "count_100_b_flags = total_b_flags\n",
    "count_100_s_flags = total_s_flags\n",
    "\n",
    "# Calculate counts in intervals of 10%\n",
    "interval_counts = []\n",
    "for i in range(0, 101, 10):\n",
    "    start_idx = int(i / 100 * total_rows)\n",
    "    end_idx = int((i + 10) / 100 * total_rows)\n",
    "    \n",
    "    interval_b_flags = df['b_flag'].iloc[start_idx:end_idx].sum()\n",
    "    interval_s_flags = df['s_flag'].iloc[start_idx:end_idx].sum()\n",
    "    \n",
    "    interval_counts.append((f'{i}% - {i+10}%', interval_b_flags, interval_s_flags))\n",
    "\n",
    "# Print results\n",
    "print(\"Total number of 1s:\")\n",
    "print(f\"b_flag: {total_b_flags}\")\n",
    "print(f\"s_flag: {total_s_flags}\")\n",
    "\n",
    "print(\"\\nCounts in segments of 100% data:\")\n",
    "print(f\"b_flag: {count_100_b_flags}\")\n",
    "print(f\"s_flag: {count_100_s_flags}\")\n",
    "\n",
    "print(\"\\nCounts in intervals of 10%:\")\n",
    "for interval, count_b, count_s in interval_counts:\n",
    "    print(f\"{interval}: b_flag={count_b}, s_flag={count_s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0af671f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 34/34 [00:02<00:00, 12.28it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:04<00:00,  8.62it/s]\n",
      "Rolling: 100%|██████████| 34/34 [00:02<00:00, 12.09it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:04<00:00,  8.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\n# Ensure b_flag is at the end after feature selection\\nX_df = select_features(X, X['b_flag'])\\nX_df = X_df[[col for col in X_df if col != 'b_flag'] + ['b_flag']]\\n\\ncorrelation_matrix = X_df.corr().abs()\\nupper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\\nhigh_correlation_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.9)]\\nX_df = X_df.drop(columns=high_correlation_features)\\n\\n# Get the list of selected feature names\\nselected_feature_names_X = list(X_df.columns)\\n\\n# Combine lists if you need a single list for all selected features\\n\\nprint(selected_feature_names_X ) \""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature extraction\n",
    "df.drop(columns=['s_flag'], inplace=True)\n",
    "\n",
    "selected_signal_1 = 'WILLR_15'\n",
    "df_melted_1 = df[['time', selected_signal_1]].copy()\n",
    "df_melted_1[\"Symbols\"] = symbol\n",
    "\n",
    "df_rolled_1 = roll_time_series(df_melted_1, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                               max_timeshift=20, min_timeshift=5)\n",
    "\n",
    "X1 = extract_features(df_rolled_1.drop(\"Symbols\", axis=1), \n",
    "                      column_id=\"id\", column_sort=\"time\", column_value=selected_signal_1, \n",
    "                      impute_function=impute, show_warnings=False)\n",
    "\n",
    "X1 = X1.set_index(X1.index.map(lambda x: x[1]), drop=True)\n",
    "X1.index.name = \"time\"\n",
    "X1 = X1.dropna()\n",
    "\n",
    "selected_signal_2 = 'WILLR_42'\n",
    "df_melted_2 = df[['time', selected_signal_2]].copy()\n",
    "df_melted_2[\"Symbols\"] = symbol\n",
    "\n",
    "df_rolled_2 = roll_time_series(df_melted_2, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                               max_timeshift=20, min_timeshift=5)\n",
    "\n",
    "X2 = extract_features(df_rolled_2.drop(\"Symbols\", axis=1), \n",
    "                      column_id=\"id\", column_sort=\"time\", column_value=selected_signal_2, \n",
    "                      impute_function=impute, show_warnings=False)\n",
    "\n",
    "X2 = X2.set_index(X2.index.map(lambda x: x[1]), drop=True)\n",
    "X2.index.name = \"time\"\n",
    "X2 = X2.dropna()\n",
    "\n",
    "X = pd.concat([X1, X2], axis=1, join='inner')\n",
    "X = X.dropna()\n",
    "\n",
    "# Align indices\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.set_index('time')\n",
    "df = df[df.index.isin(X.index)]\n",
    "\n",
    "X = pd.concat([X, df], axis=1, join='inner')\n",
    "\n",
    "# Ensure b_flag is at the end after feature selection\n",
    "X_df = select_features(X, X['b_flag'])\n",
    "X_df = X_df[[col for col in X_df if col != 'b_flag'] + ['b_flag']]\n",
    "\n",
    "correlation_matrix = X_df.corr().abs()\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "high_correlation_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.9)]\n",
    "X_df = X_df.drop(columns=high_correlation_features)\n",
    "\n",
    "# Get the list of selected feature names\n",
    "selected_feature_names_X = list(X_df.columns)\n",
    "\n",
    "# Combine lists if you need a single list for all selected features\n",
    "\n",
    "print(selected_feature_names_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from scipy import stats\n",
    "\n",
    "# Removing outliers using Z-score\n",
    "z_scores = stats.zscore(X_df.select_dtypes(include=[float, int]))\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X_df_clean = X_df[filtered_entries]\n",
    "\n",
    "print(\"Data shape after removing outliers:\", X_df_clean.shape)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_df_scaled = X_df_clean.copy()\n",
    "X_df_scaled.iloc[:, :-1] = scaler.fit_transform(X_df_scaled.iloc[:, :-1])\n",
    "\n",
    "print(\"Data after scaling:\")\n",
    "print(X_df_scaled.head())\n",
    "\n",
    "# Visualizing the data\n",
    "plt.figure(figsize=(14, 7))\n",
    "for feature in X_df_scaled.columns[:-1]:  # Exclude the 'b_flag'\n",
    "    plt.plot(X_df_scaled.index, X_df_scaled[feature], label=feature)\n",
    "plt.title('Selected Features Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Feature Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Analyzing the distribution of the selected features\n",
    "X_df_scaled.hist(bins=50, figsize=(20, 15))\n",
    "plt.suptitle('Histogram of Selected Features')\n",
    "plt.show()\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting the distribution of each feature\n",
    "for feature in X_df_scaled.columns[:-1]:  # Exclude the 'b_flag'\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.distplot(X_df_scaled[feature], bins=50)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.show()\n",
    "\n",
    "# Checking for anomalies using boxplots again\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(data=X_df_scaled.iloc[:, :-1])  # Exclude the 'b_flag'\n",
    "plt.title('Boxplot of Selected Features After Scaling')\n",
    "plt.show()\n",
    "# Example: Removing values beyond a certain z-score threshold\n",
    "threshold = 3\n",
    "z_scores = np.abs(stats.zscore(X_df_scaled.select_dtypes(include=[float, int])))\n",
    "X_df_cleaned = X_df_scaled[(z_scores < threshold).all(axis=1)]\n",
    "\n",
    "print(\"Data shape after removing noise:\", X_df_cleaned.shape)\n",
    "# Summary Statistics\n",
    "print(X_df_cleaned.describe())\n",
    "\n",
    "# Correlation Analysis\n",
    "plt.figure(figsize=(14, 7))\n",
    "correlation_matrix = X_df_cleaned.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Cleaned and Scaled Features')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance (if applicable)\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model = RandomForestClassifier()\n",
    "# model.fit(X_df_cleaned.drop('b_flag', axis=1), X_df_cleaned['b_flag'])\n",
    "\n",
    "# Feature importance\n",
    "# importances = model.feature_importances_\n",
    "# feature_names = X_df_cleaned.columns[:-1]  # Exclude the 'b_flag'\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plotting the feature importance\n",
    "# plt.figure(figsize=(14, 7))\n",
    "# plt.title(\"Feature Importance\")\n",
    "# plt.bar(range(X_df_cleaned.shape[1] - 1), importances[indices], align=\"center\")\n",
    "# plt.xticks(range(X_df_cleaned.shape[1] - 1), feature_names[indices], rotation=90)\n",
    "# plt.xlim([-1, X_df_cleaned.shape[1] - 1])\n",
    "# plt.show()\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3380c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# Rechecking for any remaining noise\n",
    "plt.figure(figsize=(14, 7))\n",
    "for feature in X_df_scaled.columns[:-1]:  # Exclude the 'b_flag'\n",
    "    sns.distplot(X_df_scaled[feature], bins=50, kde=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.show()\n",
    "# Rechecking summary statistics\n",
    "print(X_df_clean.describe())\n",
    "\n",
    "# Rechecking correlation\n",
    "plt.figure(figsize=(14, 7))\n",
    "correlation_matrix = X_df_clean.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Cleaned Features')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a target variable 'b_flag'\n",
    "X_features = X_df_clean.drop('b_flag', axis=1)\n",
    "y_target = X_df_clean['b_flag']\n",
    "\n",
    "# Train a RandomForestClassifier to get feature importances\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_features, y_target)\n",
    "\n",
    "# Feature importance\n",
    "importances = model.feature_importances_\n",
    "feature_names = X_features.columns\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    " # Plotting the feature importance\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.bar(range(X_features.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_features.shape[1]), feature_names[indices], rotation=90)\n",
    "plt.xlim([-1, X_features.shape[1]])\n",
    "plt.show() \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1560f5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Training Data):\n",
      "[[1619    0]\n",
      " [ 279  889]]\n",
      "Training Data Results:\n",
      "WIN/LOSS-Diff: 60.0 %\n",
      "False Positives: 0\n",
      "True Positives: 889\n",
      "Precision: 1.0\n",
      "Accuracy: 0.8998923573735199\n",
      "Recall: 0.7611301369863014\n",
      "F1 Score: 0.8643655809431211\n",
      "ROC AUC: 0.9993336830615889\n",
      "Ratio Total: 100.0\n",
      "BreakEvenRatio: 0.4\n",
      "____________________________________________________________________________________________________________________________\n",
      "Confusion Matrix (Testing Data):\n",
      "[[356  10]\n",
      " [301  30]]\n",
      "Testing Data Results:\n",
      "WIN/LOSS-Diff: 35.0 %\n",
      "False Positives: 10\n",
      "True Positives: 30\n",
      "Precision: 0.75\n",
      "Accuracy: 0.5538020086083214\n",
      "Recall: 0.09063444108761329\n",
      "F1 Score: 0.16172506738544473\n",
      "ROC AUC: 0.6517425255476863\n",
      "Ratio Total: 75.0\n",
      "BreakEvenRatio: 0.4\n",
      "____________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "from joblib import dump\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sum_fp = 0\n",
    "sum_tp = 0\n",
    "\n",
    "# Ensure the time series order is preserved in the split\n",
    "split = int(0.80 * len(X_df))\n",
    "train_data, test_data = X_df.iloc[:split], X_df.iloc[split:]\n",
    "\n",
    "# Train data\n",
    "x_train = train_data.iloc[:, :-1].values\n",
    "y_train = train_data['b_flag'].values\n",
    "# Test data\n",
    "x_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data['b_flag'].values\n",
    "\n",
    "# Scale Data\n",
    "sc_mt = StandardScaler()\n",
    "x_train = sc_mt.fit_transform(x_train)\n",
    "x_test = sc_mt.transform(x_test)\n",
    "\n",
    "os.makedirs('USDCAD_D1_3112_BuyNEW', exist_ok=True)\n",
    "dump(sc_mt, 'USDCAD_D1_3112_BuyNEW/scaler.joblib')\n",
    "\n",
    "# Initialise RandomForestClassifier with fixed hyperparameters\n",
    "rf_classifier_mt = RandomForestClassifier(\n",
    "    n_estimators=120,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='log2',\n",
    "    class_weight={0: 10, 1: 5},\n",
    "    random_state=10\n",
    "\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "rf_classifier_mt.fit(x_train, y_train)\n",
    "\n",
    "dump(rf_classifier_mt, 'USDCAD_D1_3112_BuyNEW/model.joblib')\n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred = rf_classifier_mt.predict(x_train)\n",
    "\n",
    "print(\"Confusion Matrix (Training Data):\")\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "print(cm_train)\n",
    "\n",
    "train_false_positives = cm_train[0][1]\n",
    "train_true_positives = cm_train[1][1]\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train, rf_classifier_mt.predict_proba(x_train)[:, 1])\n",
    "\n",
    "print('Training Data Results:')\n",
    "print('WIN/LOSS-Diff:', round(100 * (train_precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', train_false_positives)\n",
    "print('True Positives:', train_true_positives)\n",
    "print('Precision:', train_precision)\n",
    "print('Accuracy:', train_accuracy)\n",
    "print('Recall:', train_recall)\n",
    "print('F1 Score:', train_f1)\n",
    "print('ROC AUC:', train_roc_auc)\n",
    "print('Ratio Total:', round(100 * (train_true_positives / (train_false_positives + train_true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n",
    "\n",
    "# Predict on testing data\n",
    "y_test_pred = rf_classifier_mt.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix (Testing Data):\")\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm_test)\n",
    "\n",
    "test_false_positives = cm_test[0][1]\n",
    "test_true_positives = cm_test[1][1]\n",
    "\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, rf_classifier_mt.predict_proba(x_test)[:, 1])\n",
    "\n",
    "print('Testing Data Results:')\n",
    "print('WIN/LOSS-Diff:', round(100 * (test_precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', test_false_positives)\n",
    "print('True Positives:', test_true_positives)\n",
    "print('Precision:', test_precision)\n",
    "print('Accuracy:', test_accuracy)\n",
    "print('Recall:', test_recall)\n",
    "print('F1 Score:', test_f1)\n",
    "print('ROC AUC:', test_roc_auc)\n",
    "print('Ratio Total:', round(100 * (test_true_positives / (test_false_positives + test_true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c62de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from joblib import load\n",
    "\n",
    "buyscaler = load('USDCAD_D1_3112_BuyNEW/scaler.joblib')\n",
    "buymodel = load('USDCAD_D1_3112_BuyNEW/model.joblib')\n",
    "with open('USDCAD_D1_3112_BuyNEW/feature_names.json', 'r') as f:\n",
    "        feature_names = json.load(f)\n",
    "\n",
    "buy_features = feature_names[:-1] \n",
    "\n",
    "df_new = X[buy_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "932a24ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>WILLR_42__mean_second_derivative_central</th>\n",
       "      <th>WILLR_15__mean_second_derivative_central</th>\n",
       "      <th>WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.0</th>\n",
       "      <th>WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.6__ql_0.0</th>\n",
       "      <th>WILLR_15__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.0</th>\n",
       "      <th>WILLR_42__agg_linear_trend__attr_\"rvalue\"__chunk_len_10__f_agg_\"mean\"</th>\n",
       "      <th>WILLR_15__agg_linear_trend__attr_\"slope\"__chunk_len_10__f_agg_\"mean\"</th>\n",
       "      <th>WILLR_15</th>\n",
       "      <th>WILLR_15__agg_linear_trend__attr_\"rvalue\"__chunk_len_10__f_agg_\"mean\"</th>\n",
       "      <th>...</th>\n",
       "      <th>WILLR_42__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.6__ql_0.0</th>\n",
       "      <th>WILLR_42__linear_trend__attr_\"stderr\"</th>\n",
       "      <th>WILLR_15__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"var\"</th>\n",
       "      <th>WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.8__ql_0.0</th>\n",
       "      <th>WILLR_42__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.0</th>\n",
       "      <th>WILLR_15__fft_coefficient__attr_\"imag\"__coeff_3</th>\n",
       "      <th>WILLR_42__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.0</th>\n",
       "      <th>WILLR_15__fft_coefficient__attr_\"abs\"__coeff_5</th>\n",
       "      <th>WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.6__ql_0.0</th>\n",
       "      <th>WILLR_15__autocorrelation__lag_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-24</th>\n",
       "      <td>1.36932</td>\n",
       "      <td>-1.845411</td>\n",
       "      <td>-2.203622</td>\n",
       "      <td>1.975411</td>\n",
       "      <td>7.217288</td>\n",
       "      <td>66.931515</td>\n",
       "      <td>-0.047990</td>\n",
       "      <td>0.298664</td>\n",
       "      <td>-85.276074</td>\n",
       "      <td>0.049459</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.872647</td>\n",
       "      <td>0.948949</td>\n",
       "      <td>336.523046</td>\n",
       "      <td>-4.168300</td>\n",
       "      <td>18.838334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.898103</td>\n",
       "      <td>57.099015</td>\n",
       "      <td>-4.168300</td>\n",
       "      <td>-1.563104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-27</th>\n",
       "      <td>1.36341</td>\n",
       "      <td>-0.475498</td>\n",
       "      <td>-0.869932</td>\n",
       "      <td>6.173313</td>\n",
       "      <td>4.074362</td>\n",
       "      <td>50.952401</td>\n",
       "      <td>-0.047990</td>\n",
       "      <td>0.298664</td>\n",
       "      <td>-91.449387</td>\n",
       "      <td>0.049459</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.879568</td>\n",
       "      <td>0.739363</td>\n",
       "      <td>336.523046</td>\n",
       "      <td>-4.669553</td>\n",
       "      <td>16.064803</td>\n",
       "      <td>2.488806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.099015</td>\n",
       "      <td>-4.074362</td>\n",
       "      <td>-1.553675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-28</th>\n",
       "      <td>1.36156</td>\n",
       "      <td>-3.112423</td>\n",
       "      <td>-0.574886</td>\n",
       "      <td>5.272969</td>\n",
       "      <td>4.173783</td>\n",
       "      <td>40.776027</td>\n",
       "      <td>-0.047990</td>\n",
       "      <td>0.298664</td>\n",
       "      <td>-95.822011</td>\n",
       "      <td>0.049459</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.643956</td>\n",
       "      <td>1.768419</td>\n",
       "      <td>336.523046</td>\n",
       "      <td>-4.610167</td>\n",
       "      <td>133.279795</td>\n",
       "      <td>-11.002999</td>\n",
       "      <td>265.593769</td>\n",
       "      <td>57.099015</td>\n",
       "      <td>-4.173783</td>\n",
       "      <td>-0.985320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-29</th>\n",
       "      <td>1.35716</td>\n",
       "      <td>0.475221</td>\n",
       "      <td>0.619694</td>\n",
       "      <td>7.249218</td>\n",
       "      <td>7.249218</td>\n",
       "      <td>68.704425</td>\n",
       "      <td>-0.047990</td>\n",
       "      <td>0.298664</td>\n",
       "      <td>-84.620294</td>\n",
       "      <td>0.049459</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.405028</td>\n",
       "      <td>1.387253</td>\n",
       "      <td>336.523046</td>\n",
       "      <td>-1.974853</td>\n",
       "      <td>116.750746</td>\n",
       "      <td>-10.649080</td>\n",
       "      <td>206.836057</td>\n",
       "      <td>57.099015</td>\n",
       "      <td>0.218593</td>\n",
       "      <td>-0.861414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-30</th>\n",
       "      <td>1.35887</td>\n",
       "      <td>-0.609518</td>\n",
       "      <td>-0.752164</td>\n",
       "      <td>5.272969</td>\n",
       "      <td>7.814067</td>\n",
       "      <td>65.839414</td>\n",
       "      <td>-0.047990</td>\n",
       "      <td>0.298664</td>\n",
       "      <td>-94.128909</td>\n",
       "      <td>0.049459</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.888854</td>\n",
       "      <td>1.117328</td>\n",
       "      <td>336.523046</td>\n",
       "      <td>-3.051105</td>\n",
       "      <td>103.824386</td>\n",
       "      <td>-29.179151</td>\n",
       "      <td>170.945595</td>\n",
       "      <td>28.433618</td>\n",
       "      <td>-2.213209</td>\n",
       "      <td>-0.859817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-26</th>\n",
       "      <td>1.35032</td>\n",
       "      <td>0.075055</td>\n",
       "      <td>0.103258</td>\n",
       "      <td>3.542563</td>\n",
       "      <td>5.953425</td>\n",
       "      <td>73.902806</td>\n",
       "      <td>-0.962137</td>\n",
       "      <td>-27.968892</td>\n",
       "      <td>-94.294447</td>\n",
       "      <td>-0.868408</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.007269</td>\n",
       "      <td>0.337193</td>\n",
       "      <td>909.462456</td>\n",
       "      <td>-3.508327</td>\n",
       "      <td>45.349402</td>\n",
       "      <td>-60.426459</td>\n",
       "      <td>13.407579</td>\n",
       "      <td>98.612786</td>\n",
       "      <td>-0.759477</td>\n",
       "      <td>0.207799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-27</th>\n",
       "      <td>1.34869</td>\n",
       "      <td>0.290639</td>\n",
       "      <td>0.265004</td>\n",
       "      <td>3.850410</td>\n",
       "      <td>5.047632</td>\n",
       "      <td>69.491264</td>\n",
       "      <td>-0.965645</td>\n",
       "      <td>-26.437978</td>\n",
       "      <td>-99.684090</td>\n",
       "      <td>-0.907135</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.097691</td>\n",
       "      <td>0.347235</td>\n",
       "      <td>970.865201</td>\n",
       "      <td>-3.625909</td>\n",
       "      <td>43.035299</td>\n",
       "      <td>-107.668869</td>\n",
       "      <td>11.598583</td>\n",
       "      <td>43.233748</td>\n",
       "      <td>-0.446875</td>\n",
       "      <td>0.138326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-28</th>\n",
       "      <td>1.34436</td>\n",
       "      <td>-0.181574</td>\n",
       "      <td>-0.046450</td>\n",
       "      <td>3.850410</td>\n",
       "      <td>5.805650</td>\n",
       "      <td>77.311069</td>\n",
       "      <td>-0.912093</td>\n",
       "      <td>-15.058530</td>\n",
       "      <td>-86.393939</td>\n",
       "      <td>-0.747985</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.184085</td>\n",
       "      <td>0.378684</td>\n",
       "      <td>985.128441</td>\n",
       "      <td>-1.902726</td>\n",
       "      <td>40.287461</td>\n",
       "      <td>-137.388680</td>\n",
       "      <td>10.764050</td>\n",
       "      <td>40.151236</td>\n",
       "      <td>1.211498</td>\n",
       "      <td>0.061855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-29</th>\n",
       "      <td>1.34808</td>\n",
       "      <td>0.022254</td>\n",
       "      <td>0.052360</td>\n",
       "      <td>3.850410</td>\n",
       "      <td>5.805650</td>\n",
       "      <td>69.750599</td>\n",
       "      <td>-0.887895</td>\n",
       "      <td>-10.767998</td>\n",
       "      <td>-84.790155</td>\n",
       "      <td>-0.680866</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.948262</td>\n",
       "      <td>0.416371</td>\n",
       "      <td>936.513583</td>\n",
       "      <td>-0.998407</td>\n",
       "      <td>39.438024</td>\n",
       "      <td>-113.865411</td>\n",
       "      <td>7.865531</td>\n",
       "      <td>70.163877</td>\n",
       "      <td>1.211498</td>\n",
       "      <td>0.002319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-30</th>\n",
       "      <td>1.34840</td>\n",
       "      <td>0.794923</td>\n",
       "      <td>1.022315</td>\n",
       "      <td>3.850410</td>\n",
       "      <td>5.805650</td>\n",
       "      <td>54.552586</td>\n",
       "      <td>-0.838520</td>\n",
       "      <td>-5.282644</td>\n",
       "      <td>-81.716298</td>\n",
       "      <td>-0.459573</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.080310</td>\n",
       "      <td>0.406132</td>\n",
       "      <td>644.017566</td>\n",
       "      <td>0.216527</td>\n",
       "      <td>38.485007</td>\n",
       "      <td>-64.180005</td>\n",
       "      <td>8.901752</td>\n",
       "      <td>73.237911</td>\n",
       "      <td>1.211498</td>\n",
       "      <td>-0.014215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               open  WILLR_42__mean_second_derivative_central  \\\n",
       "time                                                            \n",
       "2023-11-24  1.36932                                 -1.845411   \n",
       "2023-11-27  1.36341                                 -0.475498   \n",
       "2023-11-28  1.36156                                 -3.112423   \n",
       "2023-11-29  1.35716                                  0.475221   \n",
       "2023-11-30  1.35887                                 -0.609518   \n",
       "...             ...                                       ...   \n",
       "2024-08-26  1.35032                                  0.075055   \n",
       "2024-08-27  1.34869                                  0.290639   \n",
       "2024-08-28  1.34436                                 -0.181574   \n",
       "2024-08-29  1.34808                                  0.022254   \n",
       "2024-08-30  1.34840                                  0.794923   \n",
       "\n",
       "            WILLR_15__mean_second_derivative_central  \\\n",
       "time                                                   \n",
       "2023-11-24                                 -2.203622   \n",
       "2023-11-27                                 -0.869932   \n",
       "2023-11-28                                 -0.574886   \n",
       "2023-11-29                                  0.619694   \n",
       "2023-11-30                                 -0.752164   \n",
       "...                                              ...   \n",
       "2024-08-26                                  0.103258   \n",
       "2024-08-27                                  0.265004   \n",
       "2024-08-28                                 -0.046450   \n",
       "2024-08-29                                  0.052360   \n",
       "2024-08-30                                  1.022315   \n",
       "\n",
       "            WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.0  \\\n",
       "time                                                                               \n",
       "2023-11-24                                           1.975411                      \n",
       "2023-11-27                                           6.173313                      \n",
       "2023-11-28                                           5.272969                      \n",
       "2023-11-29                                           7.249218                      \n",
       "2023-11-30                                           5.272969                      \n",
       "...                                                       ...                      \n",
       "2024-08-26                                           3.542563                      \n",
       "2024-08-27                                           3.850410                      \n",
       "2024-08-28                                           3.850410                      \n",
       "2024-08-29                                           3.850410                      \n",
       "2024-08-30                                           3.850410                      \n",
       "\n",
       "            WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.6__ql_0.0  \\\n",
       "time                                                                               \n",
       "2023-11-24                                           7.217288                      \n",
       "2023-11-27                                           4.074362                      \n",
       "2023-11-28                                           4.173783                      \n",
       "2023-11-29                                           7.249218                      \n",
       "2023-11-30                                           7.814067                      \n",
       "...                                                       ...                      \n",
       "2024-08-26                                           5.953425                      \n",
       "2024-08-27                                           5.047632                      \n",
       "2024-08-28                                           5.805650                      \n",
       "2024-08-29                                           5.805650                      \n",
       "2024-08-30                                           5.805650                      \n",
       "\n",
       "            WILLR_15__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.0  \\\n",
       "time                                                                               \n",
       "2023-11-24                                          66.931515                      \n",
       "2023-11-27                                          50.952401                      \n",
       "2023-11-28                                          40.776027                      \n",
       "2023-11-29                                          68.704425                      \n",
       "2023-11-30                                          65.839414                      \n",
       "...                                                       ...                      \n",
       "2024-08-26                                          73.902806                      \n",
       "2024-08-27                                          69.491264                      \n",
       "2024-08-28                                          77.311069                      \n",
       "2024-08-29                                          69.750599                      \n",
       "2024-08-30                                          54.552586                      \n",
       "\n",
       "            WILLR_42__agg_linear_trend__attr_\"rvalue\"__chunk_len_10__f_agg_\"mean\"  \\\n",
       "time                                                                                \n",
       "2023-11-24                                          -0.047990                       \n",
       "2023-11-27                                          -0.047990                       \n",
       "2023-11-28                                          -0.047990                       \n",
       "2023-11-29                                          -0.047990                       \n",
       "2023-11-30                                          -0.047990                       \n",
       "...                                                       ...                       \n",
       "2024-08-26                                          -0.962137                       \n",
       "2024-08-27                                          -0.965645                       \n",
       "2024-08-28                                          -0.912093                       \n",
       "2024-08-29                                          -0.887895                       \n",
       "2024-08-30                                          -0.838520                       \n",
       "\n",
       "            WILLR_15__agg_linear_trend__attr_\"slope\"__chunk_len_10__f_agg_\"mean\"  \\\n",
       "time                                                                               \n",
       "2023-11-24                                           0.298664                      \n",
       "2023-11-27                                           0.298664                      \n",
       "2023-11-28                                           0.298664                      \n",
       "2023-11-29                                           0.298664                      \n",
       "2023-11-30                                           0.298664                      \n",
       "...                                                       ...                      \n",
       "2024-08-26                                         -27.968892                      \n",
       "2024-08-27                                         -26.437978                      \n",
       "2024-08-28                                         -15.058530                      \n",
       "2024-08-29                                         -10.767998                      \n",
       "2024-08-30                                          -5.282644                      \n",
       "\n",
       "             WILLR_15  \\\n",
       "time                    \n",
       "2023-11-24 -85.276074   \n",
       "2023-11-27 -91.449387   \n",
       "2023-11-28 -95.822011   \n",
       "2023-11-29 -84.620294   \n",
       "2023-11-30 -94.128909   \n",
       "...               ...   \n",
       "2024-08-26 -94.294447   \n",
       "2024-08-27 -99.684090   \n",
       "2024-08-28 -86.393939   \n",
       "2024-08-29 -84.790155   \n",
       "2024-08-30 -81.716298   \n",
       "\n",
       "            WILLR_15__agg_linear_trend__attr_\"rvalue\"__chunk_len_10__f_agg_\"mean\"  \\\n",
       "time                                                                                \n",
       "2023-11-24                                           0.049459                       \n",
       "2023-11-27                                           0.049459                       \n",
       "2023-11-28                                           0.049459                       \n",
       "2023-11-29                                           0.049459                       \n",
       "2023-11-30                                           0.049459                       \n",
       "...                                                       ...                       \n",
       "2024-08-26                                          -0.868408                       \n",
       "2024-08-27                                          -0.907135                       \n",
       "2024-08-28                                          -0.747985                       \n",
       "2024-08-29                                          -0.680866                       \n",
       "2024-08-30                                          -0.459573                       \n",
       "\n",
       "            ...  \\\n",
       "time        ...   \n",
       "2023-11-24  ...   \n",
       "2023-11-27  ...   \n",
       "2023-11-28  ...   \n",
       "2023-11-29  ...   \n",
       "2023-11-30  ...   \n",
       "...         ...   \n",
       "2024-08-26  ...   \n",
       "2024-08-27  ...   \n",
       "2024-08-28  ...   \n",
       "2024-08-29  ...   \n",
       "2024-08-30  ...   \n",
       "\n",
       "            WILLR_42__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.6__ql_0.0  \\\n",
       "time                                                                                \n",
       "2023-11-24                                          -4.872647                       \n",
       "2023-11-27                                          -4.879568                       \n",
       "2023-11-28                                         -12.643956                       \n",
       "2023-11-29                                         -10.405028                       \n",
       "2023-11-30                                          -9.888854                       \n",
       "...                                                       ...                       \n",
       "2024-08-26                                          -3.007269                       \n",
       "2024-08-27                                          -3.097691                       \n",
       "2024-08-28                                          -2.184085                       \n",
       "2024-08-29                                          -1.948262                       \n",
       "2024-08-30                                          -1.080310                       \n",
       "\n",
       "            WILLR_42__linear_trend__attr_\"stderr\"  \\\n",
       "time                                                \n",
       "2023-11-24                               0.948949   \n",
       "2023-11-27                               0.739363   \n",
       "2023-11-28                               1.768419   \n",
       "2023-11-29                               1.387253   \n",
       "2023-11-30                               1.117328   \n",
       "...                                           ...   \n",
       "2024-08-26                               0.337193   \n",
       "2024-08-27                               0.347235   \n",
       "2024-08-28                               0.378684   \n",
       "2024-08-29                               0.416371   \n",
       "2024-08-30                               0.406132   \n",
       "\n",
       "            WILLR_15__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"var\"  \\\n",
       "time                                                                                  \n",
       "2023-11-24                                         336.523046                         \n",
       "2023-11-27                                         336.523046                         \n",
       "2023-11-28                                         336.523046                         \n",
       "2023-11-29                                         336.523046                         \n",
       "2023-11-30                                         336.523046                         \n",
       "...                                                       ...                         \n",
       "2024-08-26                                         909.462456                         \n",
       "2024-08-27                                         970.865201                         \n",
       "2024-08-28                                         985.128441                         \n",
       "2024-08-29                                         936.513583                         \n",
       "2024-08-30                                         644.017566                         \n",
       "\n",
       "            WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.8__ql_0.0  \\\n",
       "time                                                                                \n",
       "2023-11-24                                          -4.168300                       \n",
       "2023-11-27                                          -4.669553                       \n",
       "2023-11-28                                          -4.610167                       \n",
       "2023-11-29                                          -1.974853                       \n",
       "2023-11-30                                          -3.051105                       \n",
       "...                                                       ...                       \n",
       "2024-08-26                                          -3.508327                       \n",
       "2024-08-27                                          -3.625909                       \n",
       "2024-08-28                                          -1.902726                       \n",
       "2024-08-29                                          -0.998407                       \n",
       "2024-08-30                                           0.216527                       \n",
       "\n",
       "            WILLR_42__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.0  \\\n",
       "time                                                                              \n",
       "2023-11-24                                          18.838334                     \n",
       "2023-11-27                                          16.064803                     \n",
       "2023-11-28                                         133.279795                     \n",
       "2023-11-29                                         116.750746                     \n",
       "2023-11-30                                         103.824386                     \n",
       "...                                                       ...                     \n",
       "2024-08-26                                          45.349402                     \n",
       "2024-08-27                                          43.035299                     \n",
       "2024-08-28                                          40.287461                     \n",
       "2024-08-29                                          39.438024                     \n",
       "2024-08-30                                          38.485007                     \n",
       "\n",
       "            WILLR_15__fft_coefficient__attr_\"imag\"__coeff_3  \\\n",
       "time                                                          \n",
       "2023-11-24                                         0.000000   \n",
       "2023-11-27                                         2.488806   \n",
       "2023-11-28                                       -11.002999   \n",
       "2023-11-29                                       -10.649080   \n",
       "2023-11-30                                       -29.179151   \n",
       "...                                                     ...   \n",
       "2024-08-26                                       -60.426459   \n",
       "2024-08-27                                      -107.668869   \n",
       "2024-08-28                                      -137.388680   \n",
       "2024-08-29                                      -113.865411   \n",
       "2024-08-30                                       -64.180005   \n",
       "\n",
       "            WILLR_42__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.0  \\\n",
       "time                                                                              \n",
       "2023-11-24                                          31.898103                     \n",
       "2023-11-27                                           0.000000                     \n",
       "2023-11-28                                         265.593769                     \n",
       "2023-11-29                                         206.836057                     \n",
       "2023-11-30                                         170.945595                     \n",
       "...                                                       ...                     \n",
       "2024-08-26                                          13.407579                     \n",
       "2024-08-27                                          11.598583                     \n",
       "2024-08-28                                          10.764050                     \n",
       "2024-08-29                                           7.865531                     \n",
       "2024-08-30                                           8.901752                     \n",
       "\n",
       "            WILLR_15__fft_coefficient__attr_\"abs\"__coeff_5  \\\n",
       "time                                                         \n",
       "2023-11-24                                       57.099015   \n",
       "2023-11-27                                       57.099015   \n",
       "2023-11-28                                       57.099015   \n",
       "2023-11-29                                       57.099015   \n",
       "2023-11-30                                       28.433618   \n",
       "...                                                    ...   \n",
       "2024-08-26                                       98.612786   \n",
       "2024-08-27                                       43.233748   \n",
       "2024-08-28                                       40.151236   \n",
       "2024-08-29                                       70.163877   \n",
       "2024-08-30                                       73.237911   \n",
       "\n",
       "            WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.6__ql_0.0  \\\n",
       "time                                                                                \n",
       "2023-11-24                                          -4.168300                       \n",
       "2023-11-27                                          -4.074362                       \n",
       "2023-11-28                                          -4.173783                       \n",
       "2023-11-29                                           0.218593                       \n",
       "2023-11-30                                          -2.213209                       \n",
       "...                                                       ...                       \n",
       "2024-08-26                                          -0.759477                       \n",
       "2024-08-27                                          -0.446875                       \n",
       "2024-08-28                                           1.211498                       \n",
       "2024-08-29                                           1.211498                       \n",
       "2024-08-30                                           1.211498                       \n",
       "\n",
       "            WILLR_15__autocorrelation__lag_5  \n",
       "time                                          \n",
       "2023-11-24                         -1.563104  \n",
       "2023-11-27                         -1.553675  \n",
       "2023-11-28                         -0.985320  \n",
       "2023-11-29                         -0.861414  \n",
       "2023-11-30                         -0.859817  \n",
       "...                                      ...  \n",
       "2024-08-26                          0.207799  \n",
       "2024-08-27                          0.138326  \n",
       "2024-08-28                          0.061855  \n",
       "2024-08-29                          0.002319  \n",
       "2024-08-30                         -0.014215  \n",
       "\n",
       "[199 rows x 133 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = buyscaler.transform(df_new)\n",
    "y_pred =buymodel.predict(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9373d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "feature_names = X_df.columns\n",
    "with open('USDCAD_D1_3112_BuyNEW/feature_names.json', 'w') as f:\n",
    "    json.dump(list(feature_names), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98126f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from joblib import dump\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sum_fp = 0\n",
    "sum_tp = 0\n",
    "\n",
    "# TimeSeriesSplit for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Directory to save model and scaler\n",
    "os.makedirs('Dump_GBPUSD_D1_3112_Buy', exist_ok=True)\n",
    "\n",
    "# Initialise RandomForestClassifier with fixed hyperparameters\n",
    "rf_classifier_mt = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=40,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=0,\n",
    "    max_leaf_nodes=20,\n",
    "    bootstrap=True,\n",
    "    oob_score=True,\n",
    "    ccp_alpha=0,\n",
    "    class_weight={0: 10, 1: 15}\n",
    ")\n",
    "\n",
    "# Ensure the time series order is preserved in the split\n",
    "X = X_df.iloc[:, :-1].values\n",
    "y = X_df['b_flag'].values\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(X_df)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    # Train data\n",
    "    x_train, y_train = X[train_index], y[train_index]\n",
    "    # Test data\n",
    "    x_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "    # Scale Data\n",
    "    sc_mt = StandardScaler()\n",
    "    x_train = sc_mt.fit_transform(x_train)\n",
    "    x_test = sc_mt.transform(x_test)\n",
    "\n",
    "    # Save scaler\n",
    "    dump(sc_mt, f'Dump_GBPUSD_D1_3112_Buy/scaler_fold_{fold + 1}.joblib')\n",
    "\n",
    "    # Train Model\n",
    "    rf_classifier_mt.fit(x_train, y_train)\n",
    "\n",
    "    # Save the trained model\n",
    "    dump(rf_classifier_mt, f'Dump_GBPUSD_D1_3112_Buy/model_fold_{fold + 1}.joblib')\n",
    "\n",
    "    # Predict on training data\n",
    "    y_train_pred = rf_classifier_mt.predict(x_train)\n",
    "\n",
    "    print(\"Confusion Matrix (Training Data):\")\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    print(cm_train)\n",
    "\n",
    "    train_false_positives = cm_train[0][1]\n",
    "    train_true_positives = cm_train[1][1]\n",
    "\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    train_roc_auc = roc_auc_score(y_train, rf_classifier_mt.predict_proba(x_train)[:, 1])\n",
    "\n",
    "    print('Training Data Results:')\n",
    "    print('WIN/LOSS-Diff:', round(100 * (train_precision - BreakEvenRatio), 2), '%')\n",
    "    print('False Positives:', train_false_positives)\n",
    "    print('True Positives:', train_true_positives)\n",
    "    print('Precision:', train_precision)\n",
    "    print('Accuracy:', train_accuracy)\n",
    "    print('Recall:', train_recall)\n",
    "    print('F1 Score:', train_f1)\n",
    "    print('ROC AUC:', train_roc_auc)\n",
    "    print('Ratio Total:', round(100 * (train_true_positives / (train_false_positives + train_true_positives)), 2))\n",
    "    print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "    print('____________________________________________________________________________________________________________________________')\n",
    "\n",
    "    # Predict on testing data\n",
    "    y_test_pred = rf_classifier_mt.predict(x_test)\n",
    "\n",
    "    print(\"Confusion Matrix (Testing Data):\")\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "    print(cm_test)\n",
    "\n",
    "    test_false_positives = cm_test[0][1]\n",
    "    test_true_positives = cm_test[1][1]\n",
    "\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    test_roc_auc = roc_auc_score(y_test, rf_classifier_mt.predict_proba(x_test)[:, 1])\n",
    "\n",
    "    print('Testing Data Results:')\n",
    "    print('WIN/LOSS-Diff:', round(100 * (test_precision - BreakEvenRatio), 2), '%')\n",
    "    print('False Positives:', test_false_positives)\n",
    "    print('True Positives:', test_true_positives)\n",
    "    print('Precision:', test_precision)\n",
    "    print('Accuracy:', test_accuracy)\n",
    "    print('Recall:', test_recall)\n",
    "    print('F1 Score:', test_f1)\n",
    "    print('ROC AUC:', test_roc_auc)\n",
    "    print('Ratio Total:', round(100 * (test_true_positives / (test_false_positives + test_true_positives)), 2))\n",
    "    print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "    print('____________________________________________________________________________________________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from joblib import dump\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Ensure reproducibility\n",
    "random_state = 0\n",
    "\n",
    "# TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize accumulators for overall metrics\n",
    "overall_metrics = {\n",
    "    'train': {'precision_sum': 0, 'accuracy_sum': 0, 'recall_sum': 0, 'f1_sum': 0, 'roc_auc_sum': 0},\n",
    "    'test': {'precision_sum': 0, 'accuracy_sum': 0, 'recall_sum': 0, 'f1_sum': 0, 'roc_auc_sum': 0},\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_score = float('-inf')\n",
    "\n",
    "fold_idx = 1\n",
    "for train_index, test_index in tscv.split(X_df):\n",
    "    train_data, test_data = X_df.iloc[train_index], X_df.iloc[test_index]\n",
    "\n",
    "    # Train data\n",
    "    x_train = train_data.iloc[:, :-1].values\n",
    "    y_train = train_data['b_flag'].values\n",
    "    # Test data\n",
    "    x_test = test_data.iloc[:, :-1].values\n",
    "    y_test = test_data['b_flag'].values\n",
    "\n",
    "    # Scale Data\n",
    "    sc_mt = StandardScaler()\n",
    "    x_train = sc_mt.fit_transform(x_train)\n",
    "    x_test = sc_mt.transform(x_test)\n",
    "\n",
    "    os.makedirs('Dump_GBPUSD_D1_3112_Buy', exist_ok=True)\n",
    "    dump(sc_mt, 'Dump_GBPUSD_D1_3112_Buy/scaler.joblib')\n",
    "\n",
    "    # Initialize RandomForestClassifier with fixed hyperparameters\n",
    "    rf_classifier_mt = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=40,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        random_state=random_state,\n",
    "        max_leaf_nodes=20,\n",
    "        bootstrap=True,\n",
    "        oob_score=True,\n",
    "        ccp_alpha=0,\n",
    "        class_weight={0:10, 1:15}\n",
    "    )\n",
    "\n",
    "    # Train Model\n",
    "    rf_classifier_mt.fit(x_train, y_train)\n",
    "\n",
    "    dump(rf_classifier_mt, f'Dump_GBPUSD_D1_3112_Buy/model_fold_{fold_idx}.joblib')\n",
    "\n",
    "    # Predict on training data\n",
    "    y_train_pred = rf_classifier_mt.predict(x_train)\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    train_false_positives = cm_train[0][1]\n",
    "    train_true_positives = cm_train[1][1]\n",
    "\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    train_roc_auc = roc_auc_score(y_train, rf_classifier_mt.predict_proba(x_train)[:, 1])\n",
    "\n",
    "    overall_metrics['train']['precision_sum'] += train_precision\n",
    "    overall_metrics['train']['accuracy_sum'] += train_accuracy\n",
    "    overall_metrics['train']['recall_sum'] += train_recall\n",
    "    overall_metrics['train']['f1_sum'] += train_f1\n",
    "    overall_metrics['train']['roc_auc_sum'] += train_roc_auc\n",
    "\n",
    "    # Predict on testing data\n",
    "    y_test_pred = rf_classifier_mt.predict(x_test)\n",
    "\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "    test_false_positives = cm_test[0][1]\n",
    "    test_true_positives = cm_test[1][1]\n",
    "\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    test_roc_auc = roc_auc_score(y_test, rf_classifier_mt.predict_proba(x_test)[:, 1])\n",
    "\n",
    "    overall_metrics['test']['precision_sum'] += test_precision\n",
    "    overall_metrics['test']['accuracy_sum'] += test_accuracy\n",
    "    overall_metrics['test']['recall_sum'] += test_recall\n",
    "    overall_metrics['test']['f1_sum'] += test_f1\n",
    "    overall_metrics['test']['roc_auc_sum'] += test_roc_auc\n",
    "\n",
    "    if test_f1 > best_score:\n",
    "        best_score = test_f1\n",
    "        best_model = rf_classifier_mt\n",
    "        best_fold_idx = fold_idx\n",
    "\n",
    "        if fold_idx == 4:\n",
    "            test_predictions = pd.DataFrame({\n",
    "                'time': test_data.index,\n",
    "                'actual': y_test,\n",
    "                'predicted': y_test_pred\n",
    "            })\n",
    "            test_predictions.to_csv('test_predictions_fold_4.csv', index=False)\n",
    "\n",
    "    fold_idx += 1\n",
    "\n",
    "# Average metrics across all folds\n",
    "avg_train_precision = overall_metrics['train']['precision_sum'] / tscv.get_n_splits()\n",
    "avg_train_accuracy = overall_metrics['train']['accuracy_sum'] / tscv.get_n_splits()\n",
    "avg_train_recall = overall_metrics['train']['recall_sum'] / tscv.get_n_splits()\n",
    "avg_train_f1 = overall_metrics['train']['f1_sum'] / tscv.get_n_splits()\n",
    "avg_train_roc_auc = overall_metrics['train']['roc_auc_sum'] / tscv.get_n_splits()\n",
    "\n",
    "avg_test_precision = overall_metrics['test']['precision_sum'] / tscv.get_n_splits()\n",
    "avg_test_accuracy = overall_metrics['test']['accuracy_sum'] / tscv.get_n_splits()\n",
    "avg_test_recall = overall_metrics['test']['recall_sum'] / tscv.get_n_splits()\n",
    "avg_test_f1 = overall_metrics['test']['f1_sum'] / tscv.get_n_splits()\n",
    "avg_test_roc_auc = overall_metrics['test']['roc_auc_sum'] / tscv.get_n_splits()\n",
    "\n",
    "print(\"Average Metrics Across All Folds (Training):\")\n",
    "print('Precision:', avg_train_precision)\n",
    "print('Accuracy:', avg_train_accuracy)\n",
    "print('Recall:', avg_train_recall)\n",
    "print('F1 Score:', avg_train_f1)\n",
    "print('ROC AUC:', avg_train_roc_auc)\n",
    "print('____________________________________________________________________________________________________________________________')\n",
    "print(\"Average Metrics Across All Folds (Testing):\")\n",
    "print('Precision:', avg_test_precision)\n",
    "print('Accuracy:', avg_test_accuracy)\n",
    "print('Recall:', avg_test_recall)\n",
    "print('F1 Score:', avg_test_f1)\n",
    "print('ROC AUC:', avg_test_roc_auc)\n",
    "print('____________________________________________________________________________________________________________________________')\n",
    "print(f'Best model found in fold {best_fold_idx} with F1 score: {best_score}')\n",
    "\n",
    "# Save the best model\n",
    "best_model_path = 'Dump_GBPUSD_D1_3112_Buy/best_model.joblib'\n",
    "dump(best_model, best_model_path)\n",
    "print(f'Saved the best model to {best_model_path}')\n",
    "# Final Training on Full Training Data\n",
    "final_train_data = X_df\n",
    "x_final_train = final_train_data.iloc[:, :-1].values\n",
    "y_final_train = final_train_data['b_flag'].values\n",
    "\n",
    "# Scale Data\n",
    "sc_final = StandardScaler()\n",
    "x_final_train = sc_final.fit_transform(x_final_train)\n",
    "\n",
    "# Train Final Model\n",
    "final_rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=40,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=random_state,\n",
    "    max_leaf_nodes=20,\n",
    "    bootstrap=True,\n",
    "    oob_score=True,\n",
    "    ccp_alpha=0,\n",
    "    class_weight={0:10, 1:15}\n",
    ")\n",
    "\n",
    "final_rf_classifier.fit(x_final_train, y_final_train)\n",
    "\n",
    "# Save Final Model and Scaler\n",
    "os.makedirs('Final_Model_GBPUSD_D1_3112_Buy', exist_ok=True)\n",
    "dump(sc_final, 'Final_Model_GBPUSD_D1_3112_Buy/scaler_final.joblib')\n",
    "dump(final_rf_classifier, 'Final_Model_GBPUSD_D1_3112_Buy/final_model.joblib')\n",
    "print('Final model and scaler saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe98c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa83e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "final_model_path = 'Final_Model_GBPUSD_D1_3112_Buy/final_model.joblib'\n",
    "scaler_path = 'Final_Model_GBPUSD_D1_3112_Buy/scaler_final.joblib'\n",
    "final_model = load(final_model_path)\n",
    "scaler = load(scaler_path)\n",
    "\n",
    "test_data = X_df\n",
    "\n",
    "x_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data['b_flag'].values\n",
    "\n",
    "# Scale Data\n",
    "x_test = scaler.transform(test_data)\n",
    "\n",
    "y_test_pred = rf_classifier_mt.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix (Testing Data):\")\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm_test)\n",
    "\n",
    "test_false_positives = cm_test[0][1]\n",
    "test_true_positives = cm_test[1][1]\n",
    "\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, rf_classifier_mt.predict_proba(x_test)[:, 1])\n",
    "\n",
    "print('Testing Data Results:')\n",
    "print('WIN/LOSS-Diff:', round(100 * (test_precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', test_false_positives)\n",
    "print('True Positives:', test_true_positives)\n",
    "print('Precision:', test_precision)\n",
    "print('Accuracy:', test_accuracy)\n",
    "print('Recall:', test_recall)\n",
    "print('F1 Score:', test_f1)\n",
    "print('ROC AUC:', test_roc_auc)\n",
    "print('Ratio Total:', round(100 * (test_true_positives / (test_false_positives + test_true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef883039",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sum_fp = 0\n",
    "sum_tp = 0\n",
    "\n",
    "\n",
    "# Ensure the time series order is preserved in the split\n",
    "split = int(0.90 * len(X_df))\n",
    "train_data, test_data = X_df.iloc[:split], X_df.iloc[split:]\n",
    "\n",
    "# Train data\n",
    "x_train = train_data.iloc[:, :-1].values\n",
    "y_train = train_data['b_flag'].values\n",
    "# Test data\n",
    "x_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data['b_flag'].values\n",
    "\n",
    "# Scale Data\n",
    "sc_mt = StandardScaler()\n",
    "x_train = sc_mt.fit_transform(x_train)\n",
    "x_test = sc_mt.transform(x_test)\n",
    "\n",
    "os.makedirs('Dump_GBPUSD_D1_3112_Buy', exist_ok=True)\n",
    "dump(sc_mt, 'Dump_GBPUSD_D1_3112_Buy/scaler.joblib')\n",
    "\n",
    "# Define hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialise RandomForestClassifier with GridSearchCV\n",
    "rf_classifier_mt = RandomForestClassifier(random_state=27)\n",
    "grid_search = GridSearchCV(estimator=rf_classifier_mt, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Train Model with GridSearchCV\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_rf_classifier_mt = grid_search.best_estimator_\n",
    "\n",
    "dump(best_rf_classifier_mt, 'Dump_GBPUSD_D1_3112_Buy/model.joblib')\n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred = best_rf_classifier_mt.predict(x_train)\n",
    "\n",
    "print(\"Confusion Matrix (Training Data):\")\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "print(cm_train)\n",
    "\n",
    "train_false_positives = cm_train[0][1]\n",
    "train_true_positives = cm_train[1][1]\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train, best_rf_classifier_mt.predict_proba(x_train)[:, 1])\n",
    "\n",
    "print('Training Data Results:')\n",
    "print('WIN/LOSS-Diff:', round(100 * (train_precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', train_false_positives)\n",
    "print('True Positives:', train_true_positives)\n",
    "print('Precision:', train_precision)\n",
    "print('Accuracy:', train_accuracy)\n",
    "print('Recall:', train_recall)\n",
    "print('F1 Score:', train_f1)\n",
    "print('ROC AUC:', train_roc_auc)\n",
    "print('Ratio Total:', round(100 * (train_true_positives / (train_false_positives + train_true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n",
    "\n",
    "# Predict on testing data\n",
    "y_test_pred = best_rf_classifier_mt.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix (Testing Data):\")\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm_test)\n",
    "\n",
    "test_false_positives = cm_test[0][1]\n",
    "test_true_positives = cm_test[1][1]\n",
    "\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, best_rf_classifier_mt.predict_proba(x_test)[:, 1])\n",
    "\n",
    "print('Testing Data Results:')\n",
    "print('WIN/LOSS-Diff:', round(100 * (test_precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', test_false_positives)\n",
    "print('True Positives:', test_true_positives)\n",
    "print('Precision:', test_precision)\n",
    "print('Accuracy:', test_accuracy)\n",
    "print('Recall:', test_recall)\n",
    "print('F1 Score:', test_f1)\n",
    "print('ROC AUC:', test_roc_auc)\n",
    "print('Ratio Total:', round(100 * (test_true_positives / (test_false_positives + test_true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef311f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from joblib import dump\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, impute\n",
    "from sklearn.feature_selection import RFE\n",
    "import os\n",
    "\n",
    "# Initialize MetaTrader\n",
    "mt.initialize()\n",
    "login = 51708234\n",
    "password = \"4bM&wuVJcBTnjV\"\n",
    "server = \"ICMarketsEU-Demo\"\n",
    "mt.login(login, password, server)\n",
    "\n",
    "# Get data\n",
    "symbol = \"GBPUSD\"\n",
    "timeframe = mt.TIMEFRAME_D1\n",
    "ohlc_data = pd.DataFrame(mt.copy_rates_range(symbol, timeframe, datetime(2015, 1, 1), datetime.now()))\n",
    "ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "df = ohlc_data[['time', 'open', 'high', 'low', 'close']].copy()\n",
    "\n",
    "# Indicators\n",
    "df['WILLR_15'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=15)\n",
    "df['WILLR_23'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=23)\n",
    "df['WILLR_42'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=42)\n",
    "df['WILLR_145'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=145)\n",
    "\n",
    "# Shift the entire DataFrame down by one row\n",
    "shifted_df = df.copy()\n",
    "shifted_df[['open', 'high', 'low', 'close', 'WILLR_15', 'WILLR_23', 'WILLR_42', 'WILLR_145']] = shifted_df[['open', 'high', 'low', 'close', 'WILLR_15', 'WILLR_23', 'WILLR_42', 'WILLR_145']].shift(1)\n",
    "\n",
    "df = shifted_df\n",
    "\n",
    "# Buy & Sell Flags\n",
    "df['b_flag'] = 0\n",
    "df['s_flag'] = 0\n",
    "\n",
    "# Dropping NaN values and resetting index\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Label the data\n",
    "StopLoss = 1\n",
    "TakeProfit = 2\n",
    "BreakEvenRatio = StopLoss / (StopLoss + TakeProfit)\n",
    "label_data(df, [StopLoss], [TakeProfit], 80, symbol, False)\n",
    "\n",
    "# Feature extraction\n",
    "df.drop(columns=['s_flag'], inplace=True)\n",
    "\n",
    "selected_signal_1 = 'WILLR_15'\n",
    "df_melted_1 = df[['time', selected_signal_1]].copy()\n",
    "df_melted_1[\"Symbols\"] = symbol\n",
    "\n",
    "df_rolled_1 = roll_time_series(df_melted_1, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                               max_timeshift=20, min_timeshift=5)\n",
    "\n",
    "X1 = extract_features(df_rolled_1.drop(\"Symbols\", axis=1), \n",
    "                      column_id=\"id\", column_sort=\"time\", column_value=selected_signal_1, \n",
    "                      impute_function=impute, show_warnings=False)\n",
    "\n",
    "X1 = X1.set_index(X1.index.map(lambda x: x[1]), drop=True)\n",
    "X1.index.name = \"time\"\n",
    "X1 = X1.dropna()\n",
    "\n",
    "selected_signal_2 = 'WILLR_42'\n",
    "df_melted_2 = df[['time', selected_signal_2]].copy()\n",
    "df_melted_2[\"Symbols\"] = symbol\n",
    "\n",
    "df_rolled_2 = roll_time_series(df_melted_2, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                               max_timeshift=20, min_timeshift=5)\n",
    "\n",
    "X2 = extract_features(df_rolled_2.drop(\"Symbols\", axis=1), \n",
    "                      column_id=\"id\", column_sort=\"time\", column_value=selected_signal_2, \n",
    "                      impute_function=impute, show_warnings=False)\n",
    "\n",
    "X2 = X2.set_index(X2.index.map(lambda x: x[1]), drop=True)\n",
    "X2.index.name = \"time\"\n",
    "X2 = X2.dropna()\n",
    "\n",
    "X = pd.concat([X1, X2], axis=1, join='inner')\n",
    "X = X.dropna()\n",
    "\n",
    "# Align indices\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.set_index('time')\n",
    "df = df[df.index.isin(X.index)]\n",
    "\n",
    "X = pd.concat([X, df], axis=1, join='inner')\n",
    "\n",
    "# Ensure b_flag is at the end after feature selection\n",
    "X_df = select_features(X, X['b_flag'])\n",
    "X_df = X_df[[col for col in X_df if col != 'b_flag'] + ['b_flag']]\n",
    "\n",
    "# Addressing Collinearity\n",
    "correlation_matrix = X_df.drop(columns=['b_flag']).corr()\n",
    "threshold = 0.9\n",
    "high_corr_pairs = np.where(np.abs(correlation_matrix) > threshold)\n",
    "high_corr_pairs = [(correlation_matrix.index[x], correlation_matrix.columns[y]) \n",
    "                   for x, y in zip(*high_corr_pairs) if x != y and x < y]\n",
    "\n",
    "def remove_high_corr_features(corr_pairs, data):\n",
    "    to_drop = set()\n",
    "    for (feature1, feature2) in corr_pairs:\n",
    "        to_drop.add(feature1)  # You can choose to drop feature1 or feature2 based on domain knowledge or preference\n",
    "    return data.drop(columns=list(to_drop))\n",
    "\n",
    "X_df_reduced = remove_high_corr_features(high_corr_pairs, X_df.drop(columns=['b_flag']))\n",
    "\n",
    "# Apply RFE to select top features\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=27)\n",
    "rfe = RFE(estimator=clf, n_features_to_select=10)  # Adjust the number of features to select\n",
    "rfe.fit(X_df_reduced, X_df['b_flag'])\n",
    "\n",
    "X_rfe_selected = X_df_reduced.iloc[:, rfe.get_support()]\n",
    "X_rfe_selected['b_flag'] = X_df['b_flag'].values\n",
    "\n",
    "# Ensure the time series order is preserved in the split\n",
    "split = int(0.90 * len(X_rfe_selected))\n",
    "train_data, test_data = X_rfe_selected.iloc[:split], X_rfe_selected.iloc[split:]\n",
    "\n",
    "# Train data\n",
    "x_train = train_data.iloc[:, :-1].values\n",
    "y_train = train_data['b_flag'].values\n",
    "# Test data\n",
    "x_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data['b_flag'].values\n",
    "\n",
    "# Scale Data\n",
    "sc_mt = StandardScaler()\n",
    "x_train = sc_mt.fit_transform(x_train)\n",
    "x_test = sc_mt.transform(x_test)\n",
    "\n",
    "os.makedirs('Dump_GBPUSD_D1_3112_Buy', exist_ok=True)\n",
    "dump(sc_mt, 'Dump_GBPUSD_D1_3112_Buy/scaler.joblib')\n",
    "\n",
    "# Initialise RandomForestClassifier with fixed hyperparameters\n",
    "rf_classifier_mt = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=27\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "rf_classifier_mt.fit(x_train, y_train)\n",
    "\n",
    "dump(rf_classifier_mt, 'Dump_GBPUSD_D1_3112_Buy/model.joblib')\n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred = rf_classifier_mt.predict(x_train)\n",
    "\n",
    "print(\"Confusion Matrix (Training Data):\")\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "print(cm_train)\n",
    "\n",
    "train_false_positives = cm_train[0][1]\n",
    "train_true_positives = cm_train[1][1]\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train, rf_classifier_mt.predict_proba(x_train)[:, 1])\n",
    "\n",
    "print('Training Data Results:')\n",
    "print('WIN/LOSS-Diff:', round(100 * (train_precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', train_false_positives)\n",
    "print('True Positives:', train_true_positives)\n",
    "print('Precision:', train_precision)\n",
    "print('Accuracy:', train_accuracy)\n",
    "print('Recall:', train_recall)\n",
    "print('F1 Score:', train_f1)\n",
    "print('ROC AUC:', train_roc_auc)\n",
    "print('Ratio Total:', round(100 * (train_true_positives / (train_false_positives + train_true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n",
    "\n",
    "# Predict on testing data\n",
    "y_test_pred = rf_classifier_mt.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix (Testing Data):\")\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm_test)\n",
    "\n",
    "test_false_positives = cm_test[0][1]\n",
    "test_true_positives = cm_test[1][1]\n",
    "\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, rf_classifier_mt.predict_proba(x_test)[:, 1])\n",
    "\n",
    "print('Testing Data Results:')\n",
    "print('WIN/LOSS-Diff:', round(100 * (test_precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', test_false_positives)\n",
    "print('True Positives:', test_true_positives)\n",
    "print('Precision:', test_precision)\n",
    "print('Accuracy:', test_accuracy)\n",
    "print('Recall:', test_recall)\n",
    "print('F1 Score:', test_f1)\n",
    "print('ROC AUC:', test_roc_auc)\n",
    "print('Ratio Total:', round(100 * (test_true_positives / (test_false_positives + test_true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379280fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from joblib import dump\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, impute\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "import os\n",
    "\n",
    "# Initialize MetaTrader\n",
    "mt.initialize()\n",
    "login = 51708234\n",
    "password = \"4bM&wuVJcBTnjV\"\n",
    "server = \"ICMarketsEU-Demo\"\n",
    "mt.login(login, password, server)\n",
    "\n",
    "# Get data\n",
    "symbol = \"GBPUSD\"\n",
    "timeframe = mt.TIMEFRAME_D1\n",
    "ohlc_data = pd.DataFrame(mt.copy_rates_range(symbol, timeframe, datetime(2010, 1, 1), datetime.now()))\n",
    "ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "df = ohlc_data[['time', 'open', 'high', 'low', 'close']].copy()\n",
    "\n",
    "# Indicators\n",
    "df['WILLR_15'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=15)\n",
    "df['WILLR_23'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=23)\n",
    "df['WILLR_42'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=42)\n",
    "df['WILLR_145'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=145)\n",
    "\n",
    "# Shift the entire DataFrame down by one row\n",
    "shifted_df = df.copy()\n",
    "shifted_df[['open', 'high', 'low', 'close', 'WILLR_15', 'WILLR_23', 'WILLR_42', 'WILLR_145']] = shifted_df[['open', 'high', 'low', 'close', 'WILLR_15', 'WILLR_23', 'WILLR_42', 'WILLR_145']].shift(1)\n",
    "\n",
    "df = shifted_df\n",
    "\n",
    "# Buy & Sell Flags\n",
    "df['b_flag'] = 0\n",
    "df['s_flag'] = 0\n",
    "\n",
    "# Dropping NaN values and resetting index\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Label the data\n",
    "StopLoss = 1\n",
    "TakeProfit = 2\n",
    "BreakEvenRatio = StopLoss / (StopLoss + TakeProfit)\n",
    "label_data(df, [StopLoss], [TakeProfit], 80, symbol, False)\n",
    "\n",
    "# Feature extraction\n",
    "df.drop(columns=['s_flag'], inplace=True)\n",
    "\n",
    "selected_signal_1 = 'WILLR_15'\n",
    "df_melted_1 = df[['time', selected_signal_1]].copy()\n",
    "df_melted_1[\"Symbols\"] = symbol\n",
    "\n",
    "df_rolled_1 = roll_time_series(df_melted_1, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                               max_timeshift=20, min_timeshift=5)\n",
    "\n",
    "X1 = extract_features(df_rolled_1.drop(\"Symbols\", axis=1), \n",
    "                      column_id=\"id\", column_sort=\"time\", column_value=selected_signal_1, \n",
    "                      impute_function=impute, show_warnings=False)\n",
    "\n",
    "X1 = X1.set_index(X1.index.map(lambda x: x[1]), drop=True)\n",
    "X1.index.name = \"time\"\n",
    "X1 = X1.dropna()\n",
    "\n",
    "selected_signal_2 = 'WILLR_42'\n",
    "df_melted_2 = df[['time', selected_signal_2]].copy()\n",
    "df_melted_2[\"Symbols\"] = symbol\n",
    "\n",
    "df_rolled_2 = roll_time_series(df_melted_2, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                               max_timeshift=20, min_timeshift=5)\n",
    "\n",
    "X2 = extract_features(df_rolled_2.drop(\"Symbols\", axis=1), \n",
    "                      column_id=\"id\", column_sort=\"time\", column_value=selected_signal_2, \n",
    "                      impute_function=impute, show_warnings=False)\n",
    "\n",
    "X2 = X2.set_index(X2.index.map(lambda x: x[1]), drop=True)\n",
    "X2.index.name = \"time\"\n",
    "X2 = X2.dropna()\n",
    "\n",
    "X = pd.concat([X1, X2], axis=1, join='inner')\n",
    "X = X.dropna()\n",
    "\n",
    "# Align indices\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.set_index('time')\n",
    "df = df[df.index.isin(X.index)]\n",
    "\n",
    "X = pd.concat([X, df], axis=1, join='inner')\n",
    "\n",
    "# Ensure b_flag is at the end after feature selection\n",
    "X_df = select_features(X, X['b_flag'])\n",
    "X_df = X_df[[col for col in X_df if col != 'b_flag'] + ['b_flag']]\n",
    "\n",
    "# Addressing Collinearity\n",
    "def remove_high_corr_features(data, threshold=0.9):\n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = data.corr()\n",
    "    \n",
    "    # Find pairs of highly correlated features\n",
    "    high_corr_pairs = np.where(np.abs(correlation_matrix) > threshold)\n",
    "    high_corr_pairs = [(correlation_matrix.index[x], correlation_matrix.columns[y]) \n",
    "                       for x, y in zip(*high_corr_pairs) if x != y and x < y]\n",
    "    \n",
    "    # Function to remove one feature from each pair of highly correlated features\n",
    "    to_drop = set()\n",
    "    for (feature1, feature2) in high_corr_pairs:\n",
    "        to_drop.add(feature1)  # You can choose to drop feature1 or feature2 based on domain knowledge or preference\n",
    "    \n",
    "    # Drop the identified features\n",
    "    return data.drop(columns=list(to_drop))\n",
    "\n",
    "# Apply the function to remove highly correlated features\n",
    "X_df_reduced = remove_high_corr_features(X_df.drop(columns=['b_flag']), threshold=0.8)\n",
    "\n",
    "# Ensure the time series order is preserved in the split\n",
    "split = int(0.80 * len(X_df_reduced))\n",
    "train_data, test_data = X_df_reduced.iloc[:split], X_df_reduced.iloc[split:]\n",
    "\n",
    "# Train data\n",
    "x_train = train_data.values\n",
    "y_train = X_df.loc[train_data.index, 'b_flag'].values\n",
    "# Test data\n",
    "x_test = test_data.values\n",
    "y_test = X_df.loc[test_data.index, 'b_flag'].values\n",
    "\n",
    "# Scale Data\n",
    "sc_mt = StandardScaler()\n",
    "x_train = sc_mt.fit_transform(x_train)\n",
    "x_test = sc_mt.transform(x_test)\n",
    "\n",
    "os.makedirs('Dump_GBPUSD_D1_3112_Buy', exist_ok=True)\n",
    "dump(sc_mt, 'Dump_GBPUSD_D1_3112_Buy/scaler.joblib')\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV with TimeSeriesSplit\n",
    "param_grid = {\n",
    "    'rfe__n_features_to_select': [5, 10, 15],  # RFE hyperparameters\n",
    "    'clf__n_estimators': [50, 100, 150],\n",
    "    'clf__max_depth': [10, 20, None],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 4],\n",
    "    'clf__max_features': ['sqrt', 'log2', None],\n",
    "    'clf__random_state': [0, 27, 42]  # Add multiple random states\n",
    "}\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFE(estimator=RandomForestClassifier(), step=1)),  # RFE with default estimator\n",
    "    ('clf', RandomForestClassifier())  # Classifier\n",
    "])\n",
    "\n",
    "# Use TimeSeriesSplit for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=tscv, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Retrieve the best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Train Model\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "dump(best_model, 'Dump_GBPUSD_D1_3112_Buy/model.joblib')\n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred = best_model.predict(x_train)\n",
    "\n",
    "print(\"Confusion Matrix (Training Data):\")\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "print(cm_train)\n",
    "\n",
    "train_false_positives = cm_train[0][1]\n",
    "train_true_positives = cm_train[1][1]\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train, best_model.predict_proba(x_train)[:, 1])\n",
    "\n",
    "print('Training Data Results:')\n",
    "print('WIN/LOSS-Diff:', round(100 * (train_precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', train_false_positives)\n",
    "print('True Positives:', train_true_positives)\n",
    "print('Precision:', train_precision)\n",
    "print('Accuracy:', train_accuracy)\n",
    "print('Recall:', train_recall)\n",
    "print('F1 Score:', train_f1)\n",
    "print('ROC AUC:', train_roc_auc)\n",
    "print('Ratio Total:', round(100 * (train_true_positives / (train_false_positives + train_true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n",
    "\n",
    "# Predict on testing data\n",
    "y_test_pred = best_model.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix (Testing Data):\")\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm_test)\n",
    "\n",
    "test_false_positives = cm_test[0][1]\n",
    "test_true_positives = cm_test[1][1]\n",
    "\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, best_model.predict_proba(x_test)[:, 1])\n",
    "\n",
    "print('Testing Data Results:')\n",
    "print('WIN/LOSS-Diff:', round(100 * (test_precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', test_false_positives)\n",
    "print('True Positives:', test_true_positives)\n",
    "print('Precision:', test_precision)\n",
    "print('Accuracy:', test_accuracy)\n",
    "print('Recall:', test_recall)\n",
    "print('F1 Score:', test_f1)\n",
    "print('ROC AUC:', test_roc_auc)\n",
    "print('Ratio Total:', round(100 * (test_true_positives / (test_false_positives + test_true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d0988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from joblib import dump\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, impute\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "import os\n",
    "from own_functions import *\n",
    "\n",
    "# Initialize MetaTrader\n",
    "mt.initialize()\n",
    "login = 51708234\n",
    "password = \"4bM&wuVJcBTnjV\"\n",
    "server = \"ICMarketsEU-Demo\"\n",
    "mt.login(login, password, server)\n",
    "\n",
    "# Get data\n",
    "symbol = \"GBPUSD\"\n",
    "timeframe = mt.TIMEFRAME_D1\n",
    "ohlc_data = pd.DataFrame(mt.copy_rates_range(symbol, timeframe, datetime(2015, 1, 1), datetime.now()))\n",
    "ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "df = ohlc_data[['time', 'open', 'high', 'low', 'close']].copy()\n",
    "\n",
    "# Indicators\n",
    "df['WILLR_15'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=15)\n",
    "df['WILLR_23'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=23)\n",
    "df['WILLR_42'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=42)\n",
    "df['WILLR_145'] = talib.WILLR(df['high'], df['low'], df ['close'], timeperiod=145)\n",
    "\n",
    "# Shift the entire DataFrame down by one row\n",
    "shifted_df = df.copy()\n",
    "shifted_df[['open', 'high', 'low', 'close', 'WILLR_15', 'WILLR_23', 'WILLR_42', 'WILLR_145']] = shifted_df[['open', 'high', 'low', 'close', 'WILLR_15', 'WILLR_23', 'WILLR_42', 'WILLR_145']].shift(1)\n",
    "\n",
    "df = shifted_df\n",
    "\n",
    "# Buy & Sell Flags\n",
    "df['b_flag'] = 0\n",
    "df['s_flag'] = 0\n",
    "\n",
    "# Dropping NaN values and resetting index\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Label the data\n",
    "StopLoss = 1\n",
    "TakeProfit = 2\n",
    "BreakEvenRatio = StopLoss / (StopLoss + TakeProfit)\n",
    "label_data(df, [StopLoss], [TakeProfit], 80, symbol, False)\n",
    "\n",
    "# Feature extraction\n",
    "df.drop(columns=['s_flag'], inplace=True)\n",
    "\n",
    "selected_signal_1 = 'WILLR_15'\n",
    "df_melted_1 = df[['time', selected_signal_1]].copy()\n",
    "df_melted_1[\"Symbols\"] = symbol\n",
    "\n",
    "df_rolled_1 = roll_time_series(df_melted_1, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                               max_timeshift=20, min_timeshift=5)\n",
    "\n",
    "X1 = extract_features(df_rolled_1.drop(\"Symbols\", axis=1), \n",
    "                      column_id=\"id\", column_sort=\"time\", column_value=selected_signal_1, \n",
    "                      impute_function=impute, show_warnings=False)\n",
    "\n",
    "X1 = X1.set_index(X1.index.map(lambda x: x[1]), drop=True)\n",
    "X1.index.name = \"time\"\n",
    "X1 = X1.dropna()\n",
    "\n",
    "selected_signal_2 = 'WILLR_42'\n",
    "df_melted_2 = df[['time', selected_signal_2]].copy()\n",
    "df_melted_2[\"Symbols\"] = symbol\n",
    "\n",
    "df_rolled_2 = roll_time_series(df_melted_2, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                               max_timeshift=20, min_timeshift=5)\n",
    "\n",
    "X2 = extract_features(df_rolled_2.drop(\"Symbols\", axis=1), \n",
    "                      column_id=\"id\", column_sort=\"time\", column_value=selected_signal_2, \n",
    "                      impute_function=impute, show_warnings=False)\n",
    "\n",
    "X2 = X2.set_index(X2.index.map(lambda x: x[1]), drop=True)\n",
    "X2.index.name = \"time\"\n",
    "X2 = X2.dropna()\n",
    "\n",
    "X = pd.concat([X1, X2], axis=1, join='inner')\n",
    "X = X.dropna()\n",
    "\n",
    "# Align indices\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.set_index('time')\n",
    "df = df[df.index.isin(X.index)]\n",
    "\n",
    "X = pd.concat([X, df], axis=1, join='inner')\n",
    "\n",
    "# Ensure b_flag is at the end after feature selection\n",
    "X_df = select_features(X, X['b_flag'])\n",
    "X_df = X_df[[col for col in X_df if col != 'b_flag'] + ['b_flag']]\n",
    "\n",
    "# Addressing Collinearity\n",
    "def remove_high_corr_features(data, threshold=0.8):\n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = data.corr()\n",
    "    \n",
    "    # Find pairs of highly correlated features\n",
    "    high_corr_pairs = np.where(np.abs(correlation_matrix) > threshold)\n",
    "    high_corr_pairs = [(correlation_matrix.index[x], correlation_matrix.columns[y]) \n",
    "                       for x, y in zip(*high_corr_pairs) if x != y and x < y]\n",
    "    \n",
    "    # Function to remove one feature from each pair of highly correlated features\n",
    "    to_drop = set()\n",
    "    for (feature1, feature2) in high_corr_pairs:\n",
    "        to_drop.add(feature1)  # You can choose to drop feature1 or feature2 based on domain knowledge or preference\n",
    "    \n",
    "    # Drop the identified features\n",
    "    return data.drop(columns=list(to_drop))\n",
    "\n",
    "# Apply the function to remove highly correlated features\n",
    "X_df_reduced = remove_high_corr_features(X_df.drop(columns=['b_flag']), threshold=0.8)\n",
    "\n",
    "# Ensure the time series order is preserved in the split\n",
    "split = int(0.80 * len(X_df_reduced))\n",
    "train_data, test_data = X_df_reduced.iloc[:split], X_df_reduced.iloc[split:]\n",
    "\n",
    "# Train data\n",
    "x_train = train_data.values\n",
    "y_train = X_df.loc[train_data.index, 'b_flag'].values\n",
    "# Test data\n",
    "x_test = test_data.values\n",
    "y_test = X_df.loc[test_data.index, 'b_flag'].values\n",
    "\n",
    "# Scale Data\n",
    "sc_mt = StandardScaler()\n",
    "x_train = sc_mt.fit_transform(x_train)\n",
    "x_test = sc_mt.transform(x_test)\n",
    "\n",
    "os.makedirs('Dump_GBPUSD_D1_3112_Buy', exist_ok=True)\n",
    "dump(sc_mt, 'Dump_GBPUSD_D1_3112_Buy/scaler.joblib')\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV with TimeSeriesSplit\n",
    "param_grid = {\n",
    "    'rfe__n_features_to_select': [5, 10, 15],  # RFE hyperparameters\n",
    "    'clf__n_estimators': [50, 100, 150],\n",
    "    'clf__max_depth': [10, 20, None],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 4],\n",
    "    'clf__max_features': ['sqrt', 'log2', None],\n",
    "    'clf__random_state': [0, 27, 42]  # Add multiple random states\n",
    "}\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFE(estimator=RandomForestClassifier(), step=1)),  # RFE with default estimator\n",
    "    ('clf', RandomForestClassifier())  # Classifier\n",
    "])\n",
    "\n",
    "# Use TimeSeriesSplit for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "class LoggingGridSearchCV(GridSearchCV):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        print(\"Starting GridSearchCV...\")\n",
    "        super().fit(X, y, **fit_params)\n",
    "        means = self.cv_results_['mean_test_score']\n",
    "        stds = self.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, self.cv_results_['params']):\n",
    "            print(f\"Mean: {mean:.3f}, Std: {std:.3f}, Params: {params}\")\n",
    "        print(\"GridSearchCV complete.\")\n",
    "\n",
    "grid_search = LoggingGridSearchCV(estimator=pipeline, param_grid=param_grid, cv=tscv, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Retrieve the best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Train Model\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "dump(best_model, 'Dump_GBPUSD_D1_3112_Buy/model.joblib')\n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred = best_model.predict(x_train)\n",
    "\n",
    "print(\"Confusion Matrix (Training Data):\")\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "print(cm_train)\n",
    "\n",
    "train_false_positives = cm_train[0][1]\n",
    "train_true_positives = cm_train[1][1]\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train, best_model.predict_proba(x_train)[:, 1])\n",
    "\n",
    "print('Training Data Results:')\n",
    "print('WIN/LOSS-Diff:', round(100 * (train_precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', train_false_positives)\n",
    "print('True Positives:', train_true_positives)\n",
    "print('Precision:', train_precision)\n",
    "print('Accuracy:', train_accuracy)\n",
    "print('Recall:', train_recall)\n",
    "print('F1 Score:', train_f1)\n",
    "print('ROC AUC:', train_roc_auc)\n",
    "print('Ratio Total:', round(100 * (train_true_positives / (train_false_positives + train_true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n",
    "\n",
    "# Predict on testing data\n",
    "y_test_pred = best_model.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix (Testing Data):\")\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm_test)\n",
    "\n",
    "test_false_positives = cm_test[0][1]\n",
    "test_true_positives = cm_test[1][1]\n",
    "\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, best_model.predict_proba(x_test)[:, 1])\n",
    "\n",
    "print('Testing Data Results:')\n",
    "print('WIN/LOSS-Diff:', round(100 * (test_precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', test_false_positives)\n",
    "print('True Positives:', test_true_positives)\n",
    "print('Precision:', test_precision)\n",
    "print('Accuracy:', test_accuracy)\n",
    "print('Recall:', test_recall)\n",
    "print('F1 Score:', test_f1)\n",
    "print('ROC AUC:', test_roc_auc)\n",
    "print('Ratio Total:', round(100 * (test_true_positives / (test_false_positives + test_true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eae44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(high_corr_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, title):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    plt.show()\n",
    "\n",
    "# Plot Confusion Matrix for Training Data\n",
    "plot_confusion_matrix(cm_train, \"Confusion Matrix (Training Data)\")\n",
    "\n",
    "# Plot Confusion Matrix for Testing Data\n",
    "plot_confusion_matrix(cm_test, \"Confusion Matrix (Testing Data)\")\n",
    "\n",
    "# Metrics to plot\n",
    "metrics = {\n",
    "    'Precision': (train_precision, test_precision),\n",
    "    'Accuracy': (train_accuracy, test_accuracy),\n",
    "    'Recall': (train_recall, test_recall),\n",
    "    'F1 Score': (train_f1, test_f1),\n",
    "    'ROC AUC': (train_roc_auc, test_roc_auc)\n",
    "}\n",
    "\n",
    "# Function to plot metrics\n",
    "def plot_metrics(metrics):\n",
    "    train_metrics = [value[0] for value in metrics.values()]\n",
    "    test_metrics = [value[1] for value in metrics.values()]\n",
    "    metric_names = list(metrics.keys())\n",
    "\n",
    "    x = np.arange(len(metric_names))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    rects1 = ax.bar(x - width/2, train_metrics, width, label='Training')\n",
    "    rects2 = ax.bar(x + width/2, test_metrics, width, label='Testing')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_xlabel('Metrics')\n",
    "    ax.set_title('Performance Metrics (Training vs Testing)')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metric_names)\n",
    "    ax.legend()\n",
    "\n",
    "    # Attach a text label above each bar in *rects*, displaying its height.\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(round(height, 2)),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot Performance Metrics\n",
    "plot_metrics(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to plot learning curves\n",
    "def plot_learning_curves(train_errors, test_errors, param_range, param_name):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(param_range, train_errors, 'o-', color='r', label='Training MSE')\n",
    "    plt.plot(param_range, test_errors, 'o-', color='g', label='Testing MSE')\n",
    "    plt.title(f'Learning Curve ({param_name} vs MSE)')\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Lists to store the errors\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "# Range of estimators to evaluate\n",
    "n_estimators_range = [10, 50, 100, 200, 300, 400, 500]\n",
    "\n",
    "# Evaluate the model performance for different number of estimators\n",
    "for n_estimators in n_estimators_range:\n",
    "    rf_classifier_mt = RandomForestClassifier(n_estimators=n_estimators, random_state=27)\n",
    "    rf_classifier_mt.fit(x_train, y_train)\n",
    "\n",
    "    # Predict on training data\n",
    "    y_train_pred = rf_classifier_mt.predict(x_train)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_errors.append(train_mse)\n",
    "\n",
    "    # Predict on testing data\n",
    "    y_test_pred = rf_classifier_mt.predict(x_test)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_errors.append(test_mse)\n",
    "\n",
    "# Plot learning curves\n",
    "plot_learning_curves(train_errors, test_errors, n_estimators_range, 'Number of Estimators')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d22ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(index=test_data.index)\n",
    "df_pred['prediction'] = y_pred\n",
    "df_pred.to_csv('predictGBPUSD_D1_3112_Buy.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
