{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cbb1f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\forex_env\\Lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Candle: 0.009196304524519085\n"
     ]
    }
   ],
   "source": [
    "import MetaTrader5 as mt\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import talib\n",
    "from talipp.indicators import EMA, SMA, Stoch, DPO\n",
    "from joblib import dump\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, confusion_matrix, classification_report\n",
    "from own_functions import *\n",
    "import os\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, make_forecasting_frame\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "mt.initialize()\n",
    "login = 51708234\n",
    "password =\"4bM&wuVJcBTnjV\"\n",
    "server = \"ICMarketsEU-Demo\"\n",
    "mt.login(login,password,server)\n",
    "\n",
    "symbol = \"EURUSD\"\n",
    "timeframe = mt.TIMEFRAME_D1\n",
    "ohlc_data = pd.DataFrame(mt.copy_rates_range(symbol, timeframe, datetime(2010, 1, 1), datetime(2024, 10, 10)))\n",
    "ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "df = ohlc_data[['time', 'open', 'high', 'low', 'close']].copy()\n",
    "\n",
    "\n",
    "def add_rolling_features(df, window):\n",
    "    df['rolling_mean_open'] = df['open'].rolling(window=window).mean()\n",
    "    df['rolling_std_open'] = df['open'].rolling(window=window).std()\n",
    "    df['rolling_mean_close'] = df['close'].rolling(window=window).mean()\n",
    "    df['rolling_std_close'] = df['close'].rolling(window=window).std()\n",
    "    df['rolling_mean_high'] = df['high'].rolling(window=window).mean()\n",
    "    df['rolling_std_high'] = df['high'].rolling(window=window).std()\n",
    "    df['rolling_mean_low'] = df['low'].rolling(window=window).mean()\n",
    "    df['rolling_std_low'] = df['low'].rolling(window=window).std()\n",
    "    return df\n",
    "\n",
    "# Function to add lag features\n",
    "def add_lag_features(df, lags):\n",
    "    for lag in lags:\n",
    "        df[f'open_lag_{lag}'] = df['open'].shift(lag)\n",
    "        df[f'close_lag_{lag}'] = df['close'].shift(lag)\n",
    "        df[f'high_lag_{lag}'] = df['high'].shift(lag)\n",
    "        df[f'low_lag_{lag}'] = df['low'].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Indicators\n",
    "# Calculate indicators\n",
    "df['WILLR_15'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=15)\n",
    "df['WILLR_23'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=23)\n",
    "df['WILLR_42'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=42)\n",
    "df['WILLR_145'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=145)\n",
    "\n",
    "df = add_rolling_features(df, window=5)\n",
    "df = add_lag_features(df, lags=[1, 2, 3, 4, 5])\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Buy & Sell Flags\n",
    "df['b_flag'] = 0\n",
    "df['s_flag'] = 0\n",
    "\n",
    "# Dropping NaN values and resetting index\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "#csv_file_path = 'EURUSD_D1_2010to101024.csv'  # Specify your desired path\n",
    "#df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "StopLoss = 1\n",
    "TakeProfit = 2\n",
    "BreakEvenRatio=StopLoss/(StopLoss+TakeProfit)\n",
    "label_data(df,[StopLoss],[TakeProfit],80,symbol,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af671f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of 1s:\n",
      "b_flag: 1211\n",
      "s_flag: 1180\n",
      "\n",
      "Counts in segments of 100% data:\n",
      "b_flag: 1211\n",
      "s_flag: 1180\n",
      "\n",
      "Counts in intervals of 10%:\n",
      "0% - 10%: b_flag=139, s_flag=107\n",
      "10% - 20%: b_flag=130, s_flag=121\n",
      "20% - 30%: b_flag=116, s_flag=145\n",
      "30% - 40%: b_flag=117, s_flag=134\n",
      "40% - 50%: b_flag=156, s_flag=79\n",
      "50% - 60%: b_flag=105, s_flag=120\n",
      "60% - 70%: b_flag=119, s_flag=113\n",
      "70% - 80%: b_flag=110, s_flag=138\n",
      "80% - 90%: b_flag=120, s_flag=118\n",
      "90% - 100%: b_flag=99, s_flag=105\n",
      "100% - 110%: b_flag=0, s_flag=0\n"
     ]
    }
   ],
   "source": [
    "# Calculate total number of 1s in b_flag and s_flag columns\n",
    "total_b_flags = df['b_flag'].sum()\n",
    "total_s_flags = df['s_flag'].sum()\n",
    "\n",
    "# Total number of rows in the DataFrame\n",
    "total_rows = len(df)\n",
    "\n",
    "# Calculate counts in segments of complete 100% data\n",
    "count_100_b_flags = total_b_flags\n",
    "count_100_s_flags = total_s_flags\n",
    "\n",
    "# Calculate counts in intervals of 10%\n",
    "interval_counts = []\n",
    "for i in range(0, 101, 10):\n",
    "    start_idx = int(i / 100 * total_rows)\n",
    "    end_idx = int((i + 10) / 100 * total_rows)\n",
    "    \n",
    "    interval_b_flags = df['b_flag'].iloc[start_idx:end_idx].sum()\n",
    "    interval_s_flags = df['s_flag'].iloc[start_idx:end_idx].sum()\n",
    "    \n",
    "    interval_counts.append((f'{i}% - {i+10}%', interval_b_flags, interval_s_flags))\n",
    "\n",
    "# Print results\n",
    "print(\"Total number of 1s:\")\n",
    "print(f\"b_flag: {total_b_flags}\")\n",
    "print(f\"s_flag: {total_s_flags}\")\n",
    "\n",
    "print(\"\\nCounts in segments of 100% data:\")\n",
    "print(f\"b_flag: {count_100_b_flags}\")\n",
    "print(f\"s_flag: {count_100_s_flags}\")\n",
    "\n",
    "print(\"\\nCounts in intervals of 10%:\")\n",
    "for interval, count_b, count_s in interval_counts:\n",
    "    print(f\"{interval}: b_flag={count_b}, s_flag={count_s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27706466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 40/40 [00:03<00:00, 11.04it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\n",
      "Rolling: 100%|██████████| 40/40 [00:03<00:00, 10.46it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:46<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WILLR_42__mean_second_derivative_central', 'WILLR_15', 'WILLR_15__fft_coefficient__attr_\"real\"__coeff_10', 'WILLR_15__fft_coefficient__attr_\"real\"__coeff_9', 'WILLR_15__fft_coefficient__attr_\"imag\"__coeff_6', 'WILLR_15__agg_linear_trend__attr_\"slope\"__chunk_len_10__f_agg_\"mean\"', 'WILLR_42__fft_coefficient__attr_\"imag\"__coeff_8', 'WILLR_15__number_peaks__n_1', 'WILLR_15__fft_coefficient__attr_\"imag\"__coeff_5', 'WILLR_15__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"min\"', 'WILLR_15__fft_coefficient__attr_\"imag\"__coeff_7', 'WILLR_42__fft_coefficient__attr_\"angle\"__coeff_6', 'WILLR_42__agg_linear_trend__attr_\"slope\"__chunk_len_10__f_agg_\"max\"', 'WILLR_15__fft_coefficient__attr_\"real\"__coeff_8', 'WILLR_42__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"', 'WILLR_15__fft_coefficient__attr_\"imag\"__coeff_4', 'WILLR_42__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"max\"', 'WILLR_42__fft_coefficient__attr_\"angle\"__coeff_8', 'WILLR_15__fft_coefficient__attr_\"angle\"__coeff_6', 'WILLR_145', 'WILLR_42__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"min\"', 'WILLR_42__fft_coefficient__attr_\"imag\"__coeff_9', 'WILLR_15__fft_coefficient__attr_\"angle\"__coeff_8', 'WILLR_15__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"', 'WILLR_15__fft_coefficient__attr_\"angle\"__coeff_5', 'WILLR_42__sample_entropy', 'WILLR_15__fft_coefficient__attr_\"angle\"__coeff_7', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.8__ql_0.0', 'WILLR_42__friedrich_coefficients__coeff_3__m_3__r_30', 'rolling_std_high', 'WILLR_15__fft_coefficient__attr_\"angle\"__coeff_4', 'WILLR_42__fft_coefficient__attr_\"angle\"__coeff_7', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.8__ql_0.6', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_1.0__ql_0.2', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_1.0__ql_0.8', 'WILLR_15__index_mass_quantile__q_0.9', 'WILLR_15__approximate_entropy__m_2__r_0.7', 'WILLR_15__fft_coefficient__attr_\"real\"__coeff_7', 'open', 'WILLR_15__partial_autocorrelation__lag_2', 'WILLR_42__percentage_of_reoccurring_datapoints_to_all_datapoints', 'WILLR_42__fft_coefficient__attr_\"angle\"__coeff_9', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_1.0__ql_0.4', 'WILLR_42__fft_coefficient__attr_\"angle\"__coeff_4', 'WILLR_42__energy_ratio_by_chunks__num_segments_10__segment_focus_9', 'WILLR_15__fft_coefficient__attr_\"angle\"__coeff_9', 'WILLR_42__change_quantiles__f_agg_\"mean\"__isabs_False__qh_1.0__ql_0.8', 'WILLR_15__permutation_entropy__dimension_5__tau_1', 'WILLR_15__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"min\"', 'WILLR_42__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.2__ql_0.0', 'WILLR_42__fft_coefficient__attr_\"angle\"__coeff_5', 'WILLR_15__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"max\"', 'WILLR_42__fft_coefficient__attr_\"real\"__coeff_3', 'WILLR_15__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"min\"', 'WILLR_15__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.6__ql_0.0', 'b_flag']\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "df.drop(columns=['s_flag'], inplace=True)\n",
    "\n",
    "selected_signal_1 = 'WILLR_15'\n",
    "df_melted_1 = df[['time', selected_signal_1]].copy()\n",
    "df_melted_1[\"Symbols\"] = symbol\n",
    "\n",
    "df_rolled_1 = roll_time_series(df_melted_1, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                               max_timeshift=20, min_timeshift=5)\n",
    "\n",
    "X1 = extract_features(df_rolled_1.drop(\"Symbols\", axis=1), \n",
    "                      column_id=\"id\", column_sort=\"time\", column_value=selected_signal_1, \n",
    "                      impute_function=impute, show_warnings=False)\n",
    "\n",
    "X1 = X1.set_index(X1.index.map(lambda x: x[1]), drop=True)\n",
    "X1.index.name = \"time\"\n",
    "X1 = X1.dropna()\n",
    "\n",
    "selected_signal_2 = 'WILLR_42'\n",
    "df_melted_2 = df[['time', selected_signal_2]].copy()\n",
    "df_melted_2[\"Symbols\"] = symbol\n",
    "\n",
    "df_rolled_2 = roll_time_series(df_melted_2, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                               max_timeshift=20, min_timeshift=5)\n",
    "\n",
    "X2 = extract_features(df_rolled_2.drop(\"Symbols\", axis=1), \n",
    "                      column_id=\"id\", column_sort=\"time\", column_value=selected_signal_2, \n",
    "                      impute_function=impute, show_warnings=False)\n",
    "\n",
    "X2 = X2.set_index(X2.index.map(lambda x: x[1]), drop=True)\n",
    "X2.index.name = \"time\"\n",
    "X2 = X2.dropna()\n",
    "\n",
    "X = pd.concat([X1, X2], axis=1, join='inner')\n",
    "X = X.dropna()\n",
    "\n",
    "# Align indices\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.set_index('time')\n",
    "df = df[df.index.isin(X.index)]\n",
    "\n",
    "X = pd.concat([X, df], axis=1, join='inner')\n",
    "\n",
    "# Ensure b_flag is at the end after feature selection\n",
    "X_df = select_features(X, X['b_flag'])\n",
    "X_df = X_df[[col for col in X_df if col != 'b_flag'] + ['b_flag']]\n",
    "\n",
    "correlation_matrix = X_df.corr().abs()\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "high_correlation_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.8)]\n",
    "X_df = X_df.drop(columns=high_correlation_features)\n",
    "\n",
    "\n",
    "original_index = X_df.index\n",
    "shifted_X_df = X_df.shift(periods=1, axis=0)  # This shifts both features and target\n",
    "shifted_X_df.index = original_index  # Keep the original index\n",
    "X_df = shifted_X_df.dropna()\n",
    "\n",
    "\n",
    "\n",
    "# Get the list of selected feature names\n",
    "selected_feature_names_X = list(X_df.columns)\n",
    "\n",
    "# Combine lists if you need a single list for all selected features\n",
    "\n",
    "print(selected_feature_names_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef883039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[430  89]\n",
      " [151  67]]\n",
      "WIN/LOSS-Diff: 9.62 %\n",
      "sum_fp: 89\n",
      "sum_tp: 67\n",
      "precision: 0.42948717948717946\n",
      "Ratio total: 42.95\n",
      "BreakEvenRatio: 0.33\n",
      "____________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sum_fp = 0\n",
    "sum_tp = 0\n",
    "\n",
    "# Split into train and test sets\n",
    "split = int(0.80 * len(X_df))  # Use the feature-engineered X_df, not df\n",
    "\n",
    "train_data, test_data = X_df.iloc[:split], X_df.iloc[split:]\n",
    "\n",
    "\n",
    "# Train data\n",
    "# Ensure correct feature and target selection:\n",
    "x_train = train_data.iloc[:, :-1].values  # Features are all columns except the last one (s_flag)\n",
    "y_train = train_data['b_flag'].values  # Target is the s_flag column\n",
    "\n",
    "x_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data['b_flag'].values\n",
    "\n",
    "# Scale Data\n",
    "sc_mt = StandardScaler()\n",
    "\n",
    "x_train = sc_mt.fit_transform(x_train)\n",
    "x_test = sc_mt.transform(x_test)\n",
    "\n",
    "os.makedirs('EURUSD_D1_3112final', exist_ok=True)\n",
    "# Save the scaler\n",
    "dump(sc_mt, 'EURUSD_D1_3112final/scaler.joblib')\n",
    "\n",
    "# Hyperparameters\n",
    "n_estimators = 150\n",
    "class_weight = {0: 10, 1: 15}\n",
    "max_features = 'sqrt'\n",
    "random_state = 0\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_classifier_mt = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    class_weight=class_weight,\n",
    "    max_features=max_features,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_classifier_mt.fit(x_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "dump(rf_classifier_mt, 'EURUSD_D1_3112final/model.joblib')\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = rf_classifier_mt.predict(x_test)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "false_positives = conf_matrix[0][1]\n",
    "true_positives = conf_matrix[1][1]\n",
    "\n",
    "sum_fp += false_positives\n",
    "sum_tp += true_positives\n",
    "\n",
    "# Print additional metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print('WIN/LOSS-Diff:', round(100 * (precision - BreakEvenRatio), 2), '%')\n",
    "print('sum_fp:', sum_fp)\n",
    "print('sum_tp:', sum_tp)\n",
    "print('precision:', precision)\n",
    "print('Ratio total:', round(100 * (sum_tp / (sum_fp + sum_tp)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36887e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "feature_names = X_df.columns\n",
    "with open('EURUSD_D1_3112final/feature_names.json', 'w') as f:\n",
    "    json.dump(list(feature_names), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f65221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to datetime without 'unit' since the format is already date strings\n",
    "X_df.index = pd.to_datetime(X_df.index)\n",
    "\n",
    "# Format datetime to the desired string format\n",
    "X_df.index = X_df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Creating a DataFrame for predictions with the correct index\n",
    "df_pred = pd.DataFrame(index=X_df.iloc[split:].index)  # No need for split+1\n",
    "df_pred['prediction'] = y_pred\n",
    "\n",
    "# Save to CSV\n",
    "df_pred.to_csv('predEURUSD_D1_3112buy.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MetaTrader5 as mt5\n",
    "from backtesting import Backtest, Strategy\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(filename='backtest.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# MetaTrader 5 initialization\n",
    "def init_mt5_connection(login, password, server):\n",
    "    if not mt5.initialize(login=login, password=password, server=server):\n",
    "        logging.error(f\"initialize() failed, error code = {mt5.last_error()}\")\n",
    "        sys.exit()\n",
    "    logging.info(\"Connected to MetaTrader 5\")\n",
    "    print(\"Connected to MetaTrader 5\")\n",
    "\n",
    "# Fetch historical OHLC data from MetaTrader 5\n",
    "def fetch_ohlc_data(symbol, timeframe, start_date, end_date):\n",
    "    data = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    if data is None or len(data) == 0:\n",
    "        logging.error(f\"Failed to fetch data for {symbol}\")\n",
    "        return None\n",
    "    ohlc_data = pd.DataFrame(data)\n",
    "    ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "    ohlc_data.rename(columns={'open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'tick_volume': 'Volume'}, inplace=True)\n",
    "    return ohlc_data[['time', 'Open', 'High', 'Low', 'Close', 'Volume']]  # Include Volume\n",
    "\n",
    "# Load and align prediction data\n",
    "def load_and_align_data(ohlc_data, prediction_file):\n",
    "    try:\n",
    "        predictions = pd.read_csv(prediction_file, parse_dates=['time'])\n",
    "        if 'prediction' not in predictions.columns:\n",
    "            logging.error(f\"'prediction' column not found in {prediction_file}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading prediction file: {e}\")\n",
    "        return None\n",
    "    # Merge predictions with OHLC data\n",
    "    ohlc_data = ohlc_data.merge(predictions[['time', 'prediction']], on='time', how='left')\n",
    "    ohlc_data['prediction'] = ohlc_data['prediction'].fillna(0)  # Fill missing predictions with 0\n",
    "    ohlc_data['prediction'] = ohlc_data['prediction'].shift(1)  # Shift predictions to next date\n",
    "    return ohlc_data\n",
    "\n",
    "# Backtesting strategy for Buy or Sell\n",
    "class PredictionStrategy(Strategy):\n",
    "    risk_reward_ratio = (2, 3)  # Default risk-reward ratio\n",
    "    signal_type = 'Buy'  # Default signal type\n",
    "    mean_candle_size = 0.0105  # Default mean candle size\n",
    "\n",
    "    def init(self):\n",
    "        # Mean candle size now taken from strategy properties set during strategy initialization\n",
    "        pass\n",
    "\n",
    "    def next(self):\n",
    "        entry_price = self.data.Close[-1]\n",
    "        risk_part, reward_part = self.risk_reward_ratio\n",
    "        # Buy signal\n",
    "        if self.data.prediction[-1] == 1 and self.signal_type == 'Buy':\n",
    "            sl_price = entry_price - self.mean_candle_size * risk_part\n",
    "            tp_price = entry_price + self.mean_candle_size * reward_part\n",
    "            self.buy(sl=sl_price, tp=tp_price)\n",
    "        # Sell signal\n",
    "        elif self.data.prediction[-1] == 1 and self.signal_type == 'Sell':\n",
    "            sl_price = entry_price + self.mean_candle_size * risk_part\n",
    "            tp_price = entry_price - self.mean_candle_size * reward_part\n",
    "            self.sell(sl=sl_price, tp=tp_price)\n",
    "\n",
    "# Function to perform backtesting and save stats/plot\n",
    "def run_backtest(ohlc_data, strategy_class, risk_reward_ratio, pair_name, signal_type, mean_candle_size):\n",
    "    strategy_class.risk_reward_ratio = risk_reward_ratio\n",
    "    strategy_class.signal_type = signal_type\n",
    "    strategy_class.mean_candle_size = mean_candle_size  # Set mean candle size for the strategy\n",
    "    bt = Backtest(ohlc_data.set_index('time'), strategy_class, cash=10000, commission=.0003,margin=0.2)\n",
    "    stats = bt.run()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bt.plot()\n",
    "    plt.title(f'Backtest for {pair_name} - {signal_type}')\n",
    "    plt.savefig(f'backtest_plot_{pair_name}_{signal_type}.png')\n",
    "    plt.close()\n",
    "    stats_df = pd.DataFrame([stats])\n",
    "    stats_df.to_csv(f'backtest_stats_{pair_name}_{signal_type}.csv', index=False)\n",
    "    return stats\n",
    "\n",
    "# Main function to fetch OHLC data, align it with prediction data, and run backtest for each buy/sell\n",
    "def main():\n",
    "    config = {\n",
    "        'login': 51988090,\n",
    "        'password': '1fMdV52$74EOcw',\n",
    "        'server': 'ICMarketsEU-Demo',\n",
    "        'EURUSD': {\n",
    "            'symbol': 'EURUSD',\n",
    "            'timeframe': mt5.TIMEFRAME_D1,\n",
    "            'mean_candle_size': 0.009196304524519085,\n",
    "            'buy_prediction_file': 'predEURUSD_D1_3112buy.csv',\n",
    "            'buy_risk_reward_ratio': (1, 1),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    init_mt5_connection(config['login'], config['password'], config['server'])\n",
    "    utc_from = datetime(2021, 5, 9, tzinfo=pytz.utc)\n",
    "    utc_to = datetime(2024, 10, 7, tzinfo=pytz.utc)\n",
    "\n",
    "    for pair_name, pair_config in config.items():\n",
    "        if pair_name in ['login', 'password', 'server']:\n",
    "            continue\n",
    "        logging.info(f\"Processing {pair_name}...\")\n",
    "        ohlc_data = fetch_ohlc_data(pair_config['symbol'], pair_config['timeframe'], utc_from, utc_to)\n",
    "        if ohlc_data is None:\n",
    "            continue\n",
    "\n",
    "        if pair_config['buy_prediction_file']:\n",
    "            ohlc_data_with_predictions = load_and_align_data(ohlc_data, pair_config['buy_prediction_file'])\n",
    "            if ohlc_data_with_predictions is not None:\n",
    "                stats = run_backtest(ohlc_data_with_predictions, PredictionStrategy, pair_config['buy_risk_reward_ratio'], pair_name, 'Buy', pair_config['mean_candle_size'])\n",
    "                print(f\"Backtest results for {pair_name} - Buy:\\n\", stats)\n",
    "        if pair_config.get('sell_prediction_file'):\n",
    "            ohlc_data_with_predictions = load_and_align_data(ohlc_data, pair_config['sell_prediction_file'])\n",
    "            if ohlc_data_with_predictions is not None:\n",
    "                stats = run_backtest(ohlc_data_with_predictions, PredictionStrategy, pair_config['sell_risk_reward_ratio'], pair_name, 'Sell', pair_config['mean_candle_size'])\n",
    "                print(f\"Backtest results for {pair_name} - Sell:\\n\", stats)\n",
    "\n",
    "    mt5.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779fc2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MetaTrader5 as mt5\n",
    "from backtesting import Backtest, Strategy\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(filename='backtest.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# MetaTrader 5 initialization\n",
    "def init_mt5_connection(login, password, server):\n",
    "    if not mt5.initialize(login=login, password=password, server=server):\n",
    "        logging.error(f\"initialize() failed, error code = {mt5.last_error()}\")\n",
    "        sys.exit()\n",
    "    logging.info(\"Connected to MetaTrader 5\")\n",
    "    print(\"Connected to MetaTrader 5\")\n",
    "\n",
    "# Fetch historical OHLC data from MetaTrader 5\n",
    "def fetch_ohlc_data(symbol, timeframe, start_date, end_date):\n",
    "    data = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    if data is None or len(data) == 0:\n",
    "        logging.error(f\"Failed to fetch data for {symbol}\")\n",
    "        return None\n",
    "    ohlc_data = pd.DataFrame(data)\n",
    "    ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "    ohlc_data.rename(columns={'open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'tick_volume': 'Volume'}, inplace=True)\n",
    "    return ohlc_data[['time', 'Open', 'High', 'Low', 'Close', 'Volume']]  # Include Volume, even if it's not mandatory\n",
    "\n",
    "# Load and align prediction data\n",
    "def load_and_align_data(ohlc_data, prediction_file):\n",
    "    try:\n",
    "        predictions = pd.read_csv(prediction_file, parse_dates=['time'])\n",
    "        if 'prediction' not in predictions.columns:\n",
    "            logging.error(f\"'prediction' column not found in {prediction_file}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading prediction file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Merge predictions with OHLC data\n",
    "    ohlc_data = ohlc_data.merge(predictions[['time', 'prediction']], on='time', how='left')\n",
    "    ohlc_data['prediction'] = ohlc_data['prediction'].fillna(0)  # Fill missing predictions with 0\n",
    "    ohlc_data['prediction'] = ohlc_data['prediction'].shift(1)  # Shift predictions by one day to start trade on the next date\n",
    "    return ohlc_data\n",
    "\n",
    "# Backtesting strategy for Buy or Sell\n",
    "class PredictionStrategy(Strategy):\n",
    "    risk_reward_ratio = (2, 3)  # Default risk-reward ratio\n",
    "    signal_type = 'Buy'  # Default signal type\n",
    "    mean_candle_size = 0  # Mean candle size based on historical data\n",
    "\n",
    "    def init(self):\n",
    "        # Calculate mean candle size based on historical data\n",
    "        self.mean_candle_size = 0.0105\n",
    "\n",
    "    def next(self):\n",
    "        entry_price = self.data.Close[-1]\n",
    "        risk_part, reward_part = self.risk_reward_ratio\n",
    "\n",
    "        # Buy signal\n",
    "        if self.data.prediction[-1] == 1 and self.signal_type == 'Buy':\n",
    "            sl_price = entry_price - self.mean_candle_size * risk_part\n",
    "            tp_price = entry_price + self.mean_candle_size * reward_part\n",
    "            self.buy(sl=sl_price, tp=tp_price)\n",
    "\n",
    "        # Sell signal\n",
    "        elif self.data.prediction[-1] == 1 and self.signal_type == 'Sell':\n",
    "            sl_price = entry_price + self.mean_candle_size * risk_part\n",
    "            tp_price = entry_price - self.mean_candle_size * reward_part\n",
    "            self.sell(sl=sl_price, tp=tp_price)\n",
    "\n",
    "# Function to perform backtesting and save stats/plot\n",
    "def run_backtest(ohlc_data, strategy_class, risk_reward_ratio, pair_name, signal_type):\n",
    "    strategy_class.risk_reward_ratio = risk_reward_ratio  # Set specific risk-reward ratio for each pair\n",
    "    strategy_class.signal_type = signal_type  # Set the signal type (Buy or Sell)\n",
    "    bt = Backtest(ohlc_data.set_index('time'), strategy_class, cash=10000, commission=.0003,margin=0.01)\n",
    "    stats = bt.run()\n",
    "\n",
    "    # Generate and save the backtest plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bt.plot()  # This generates the plot using backtesting.py's internal plot function\n",
    "    plt.draw()  # Make sure the plot is rendered properly\n",
    "    plt.pause(0.1)  # Pause to ensure rendering before saving\n",
    "    plt.title(f'Backtest for {pair_name} - {signal_type}')  # Add pair name and signal type to the title\n",
    "    plt.savefig(f'backtest_plot_{pair_name}_{signal_type}.png')  # Save the plot manually using matplotlib\n",
    "    plt.close()  # Close the plot to avoid displaying it in the environment\n",
    "\n",
    "    # Save backtest stats as CSV\n",
    "    stats_df = pd.DataFrame([stats])\n",
    "    stats_df.to_csv(f'backtest_stats_{pair_name}_{signal_type}.csv', index=False)\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "# Main function to fetch OHLC data, align it with prediction data, and run backtest for each buy/sell\n",
    "def main():\n",
    "    # Configuration for MetaTrader 5 connection\n",
    "    config = {\n",
    "        'login': 51988090,\n",
    "        'password': '1fMdV52$74EOcw',\n",
    "        'server': 'ICMarketsEU-Demo'\n",
    "    }\n",
    "\n",
    "    # Initialize MetaTrader 5 connection\n",
    "    init_mt5_connection(config['login'], config['password'], config['server'])\n",
    "\n",
    "    # Define the time period for backtesting\n",
    "    utc_from = datetime(2023, 5, 9, tzinfo=pytz.utc)\n",
    "    utc_to = datetime(2024, 10, 7, tzinfo=pytz.utc)\n",
    "\n",
    "    # Currency pair configurations\n",
    "    currency_pairs = {\n",
    "        'USDCAD': {\n",
    "            'symbol': 'USDCAD',\n",
    "            'timeframe': mt5.TIMEFRAME_D1,\n",
    "            'buy_prediction_file': 'predUSDCAD_D1_3112buy.csv',\n",
    "            'buy_risk_reward_ratio': (1, 1),  # EURUSD Buy Risk-Reward Ratio\n",
    "            'sell_risk_reward_ratio': (1, 2),  # EURUSD Sell Risk-Reward Ratio\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Loop through each currency pair and perform backtest\n",
    "    for pair_name, pair_config in currency_pairs.items():\n",
    "        logging.info(f\"Processing {pair_name}...\")\n",
    "\n",
    "        # Fetch OHLC data\n",
    "        ohlc_data = fetch_ohlc_data(pair_config['symbol'], pair_config['timeframe'], utc_from, utc_to)\n",
    "        if ohlc_data is None:\n",
    "            logging.error(f\"Skipping {pair_name} due to missing OHLC data\")\n",
    "            continue\n",
    "\n",
    "        # Backtest Buy predictions if the file exists\n",
    "        if pair_config['buy_prediction_file']:\n",
    "            ohlc_data_with_predictions = load_and_align_data(ohlc_data, pair_config['buy_prediction_file'])\n",
    "            if ohlc_data_with_predictions is not None:\n",
    "                stats = run_backtest(ohlc_data_with_predictions, PredictionStrategy, pair_config['buy_risk_reward_ratio'], pair_name, 'Buy')\n",
    "                print(f\"Backtest results for {pair_name} - Buy:\\n\", stats)\n",
    "            else:\n",
    "                logging.error(f\"Skipping {pair_name} Buy due to prediction data issue\")\n",
    "\n",
    "        # Backtest Sell predictions if the file exists\n",
    "        if pair_config.get('sell_prediction_file'):\n",
    "            ohlc_data_with_predictions = load_and_align_data(ohlc_data, pair_config['sell_prediction_file'])\n",
    "            if ohlc_data_with_predictions is not None:\n",
    "                stats = run_backtest(ohlc_data_with_predictions, PredictionStrategy, pair_config['sell_risk_reward_ratio'], pair_name, 'Sell')\n",
    "                print(f\"Backtest results for {pair_name} - Sell:\\n\", stats)\n",
    "            else:\n",
    "                logging.error(f\"Skipping {pair_name} Sell due to prediction data issue\")\n",
    "\n",
    "    # Shutdown MetaTrader 5 connection after backtesting\n",
    "    mt5.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MetaTrader5 as mt5\n",
    "from backtesting import Backtest, Strategy\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(filename='backtest.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# MetaTrader 5 initialization\n",
    "def init_mt5_connection(login, password, server):\n",
    "    if not mt5.initialize(login=login, password=password, server=server):\n",
    "        logging.error(f\"initialize() failed, error code = {mt5.last_error()}\")\n",
    "        sys.exit()\n",
    "    logging.info(\"Connected to MetaTrader 5\")\n",
    "    print(\"Connected to MetaTrader 5\")\n",
    "\n",
    "# Fetch historical OHLC data from MetaTrader 5\n",
    "def fetch_ohlc_data(symbol, timeframe, start_date, end_date):\n",
    "    data = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    if data is None or len(data) == 0:\n",
    "        logging.error(f\"Failed to fetch data for {symbol}\")\n",
    "        return None\n",
    "    ohlc_data = pd.DataFrame(data)\n",
    "    ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "    ohlc_data.rename(columns={'open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'tick_volume': 'Volume'}, inplace=True)\n",
    "    return ohlc_data[['time', 'Open', 'High', 'Low', 'Close', 'Volume']]  # Include Volume, even if it's not mandatory\n",
    "\n",
    "# Load and align prediction data\n",
    "def load_and_align_data(ohlc_data, buy_prediction_file, sell_prediction_file):\n",
    "    try:\n",
    "        buy_predictions = pd.read_csv(buy_prediction_file, parse_dates=['time'])\n",
    "        sell_predictions = pd.read_csv(sell_prediction_file, parse_dates=['time'])\n",
    "        if 'prediction' not in buy_predictions.columns or 'prediction' not in sell_predictions.columns:\n",
    "            logging.error(f\"'prediction' column not found in one of the prediction files\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading prediction file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Merge predictions with OHLC data\n",
    "    ohlc_data = ohlc_data.merge(buy_predictions[['time', 'prediction']], on='time', how='left', suffixes=('', '_buy'))\n",
    "    ohlc_data = ohlc_data.merge(sell_predictions[['time', 'prediction']], on='time', how='left', suffixes=('', '_sell'))\n",
    "    ohlc_data['prediction_buy'] = ohlc_data['prediction'].fillna(0)\n",
    "    ohlc_data['prediction_sell'] = ohlc_data['prediction_sell'].fillna(0)\n",
    "    ohlc_data['prediction_buy'] = ohlc_data['prediction_buy'].shift(1)  # Shift predictions by one day to start trade on the next date\n",
    "    ohlc_data['prediction_sell'] = ohlc_data['prediction_sell'].shift(1)\n",
    "    ohlc_data.drop(columns=['prediction'], inplace=True)\n",
    "    return ohlc_data\n",
    "\n",
    "# Backtesting strategy for Buy or Sell\n",
    "class PredictionStrategy(Strategy):\n",
    "    risk_reward_ratio_buy = (2, 3)  # Default risk-reward ratio for Buy\n",
    "    risk_reward_ratio_sell = (2, 3)  # Default risk-reward ratio for Sell\n",
    "    mean_candle_size = 0  # Mean candle size based on historical data\n",
    "\n",
    "    def init(self):\n",
    "        # Calculate mean candle size based on historical data\n",
    "        self.mean_candle_size = (self.data.High - self.data.Low).mean()\n",
    "\n",
    "    def next(self):\n",
    "        entry_price = self.data.Close[-1]\n",
    "        risk_part_buy, reward_part_buy = self.risk_reward_ratio_buy\n",
    "        risk_part_sell, reward_part_sell = self.risk_reward_ratio_sell\n",
    "\n",
    "        # Check if both Buy and Sell are predicted, in which case no trade should be taken\n",
    "        if self.data.prediction_buy[-1] == 1 and self.data.prediction_sell[-1] == 1:\n",
    "            print(f\"Skipping trade on {self.data.index[-1]} due to both Buy and Sell signals\")\n",
    "            return\n",
    "\n",
    "        # Buy signal\n",
    "        if self.data.prediction_buy[-1] == 1:\n",
    "            sl_price = entry_price - self.mean_candle_size * risk_part_buy\n",
    "            tp_price = entry_price + self.mean_candle_size * reward_part_buy\n",
    "            print(f\"Attempting to Buy on {self.data.index[-1]} at {entry_price} with SL={sl_price} TP={tp_price}\")\n",
    "            self.buy(sl=sl_price, tp=tp_price)\n",
    "\n",
    "        # Sell signal\n",
    "        elif self.data.prediction_sell[-1] == 1:\n",
    "            sl_price = entry_price + self.mean_candle_size * risk_part_sell\n",
    "            tp_price = entry_price - self.mean_candle_size * reward_part_sell\n",
    "            print(f\"Attempting to Sell on {self.data.index[-1]} at {entry_price} with SL={sl_price} TP={tp_price}\")\n",
    "            self.sell(sl=sl_price, tp=tp_price)\n",
    "\n",
    "\n",
    "# Function to perform backtesting and save stats/plot\n",
    "def run_backtest(ohlc_data, strategy_class, risk_reward_ratio_buy, risk_reward_ratio_sell, pair_name):\n",
    "    strategy_class.risk_reward_ratio_buy = risk_reward_ratio_buy  # Set specific risk-reward ratio for Buy\n",
    "    strategy_class.risk_reward_ratio_sell = risk_reward_ratio_sell  # Set specific risk-reward ratio for Sell\n",
    "    bt = Backtest(ohlc_data.set_index('time'), strategy_class, cash=10000, commission=.0003)\n",
    "    stats = bt.run()\n",
    "\n",
    "    # Generate and save the backtest plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bt.plot()  # This generates the plot using backtesting.py's internal plot function\n",
    "    plt.draw()  # Make sure the plot is rendered properly\n",
    "    plt.pause(0.1)  # Pause to ensure rendering before saving\n",
    "    plt.title(f'Backtest for {pair_name}')  # Add pair name to the title\n",
    "    plt.savefig(f'backtest_plot_{pair_name}.png')  # Save the plot manually using matplotlib\n",
    "    plt.close()  # Close the plot to avoid displaying it in the environment\n",
    "\n",
    "    # Save backtest stats as CSV\n",
    "    stats_df = pd.DataFrame([stats])\n",
    "    stats_df.to_csv(f'backtest_stats_{pair_name}.csv', index=False)\n",
    "\n",
    "    return stats\n",
    "\n",
    "# Main function to fetch OHLC data, align it with prediction data, and run backtest\n",
    "def main():\n",
    "    # Configuration for MetaTrader 5 connection\n",
    "    config = {\n",
    "        'login': 51988090,\n",
    "        'password': '1fMdV52$74EOcw',\n",
    "        'server': 'ICMarketsEU-Demo'\n",
    "    }\n",
    "\n",
    "    # Initialize MetaTrader 5 connection\n",
    "    init_mt5_connection(config['login'], config['password'], config['server'])\n",
    "\n",
    "    # Define the time period for backtesting\n",
    "    utc_from = datetime(2019, 12, 3, tzinfo=pytz.utc)\n",
    "    utc_to = datetime(2024, 10, 7, tzinfo=pytz.utc)\n",
    "\n",
    "    # Currency pair configurations\n",
    "    currency_pairs = {\n",
    "        'GBPUSD': {\n",
    "            'symbol': 'GBPUSD',\n",
    "            'timeframe': mt5.TIMEFRAME_D1,\n",
    "            'buy_prediction_file': 'GBPUSD_D1_3112_Buy.csv',\n",
    "            'sell_prediction_file': 'predictGBPUSD_D1_3112sell.csv',\n",
    "            'buy_risk_reward_ratio': (1, 2),  # GBPUSD Buy Risk-Reward Ratio\n",
    "            'sell_risk_reward_ratio': (1, 2),  # GBPUSD Sell Risk-Reward Ratio\n",
    "        },\n",
    "        'USDCAD': {\n",
    "            'symbol': 'USDCAD',\n",
    "            'timeframe': mt5.TIMEFRAME_D1,\n",
    "            'buy_prediction_file': 'predictUSDCAD_D1Buy.csv',\n",
    "            'sell_prediction_file': 'predictUSDCAD_D1Sell.csv',\n",
    "            'buy_risk_reward_ratio': (2, 3),  # USDCAD Buy Risk-Reward Ratio\n",
    "            'sell_risk_reward_ratio': (2, 3),  # USDCAD Sell Risk-Reward Ratio\n",
    "        },\n",
    "        'EURUSD': {\n",
    "            'symbol': 'EURUSD',\n",
    "            'timeframe': mt5.TIMEFRAME_D1,\n",
    "            'buy_prediction_file': 'predictEURUSD_D1_3112buy.csv',\n",
    "            'sell_prediction_file': 'predict_EURUSD_D1_3112_Sell.csv',\n",
    "            'buy_risk_reward_ratio': (2, 3),  # EURUSD Buy Risk-Reward Ratio\n",
    "            'sell_risk_reward_ratio': (1, 2),  # EURUSD Sell Risk-Reward Ratio\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Loop through each currency pair and perform backtest\n",
    "    for pair_name, pair_config in currency_pairs.items():\n",
    "        logging.info(f\"Processing {pair_name}...\")\n",
    "\n",
    "        # Fetch OHLC data\n",
    "        ohlc_data = fetch_ohlc_data(pair_config['symbol'], pair_config['timeframe'], utc_from, utc_to)\n",
    "        if ohlc_data is None:\n",
    "            logging.error(f\"Skipping {pair_name} due to missing OHLC data\")\n",
    "            continue\n",
    "\n",
    "        # Load and align data for both Buy and Sell predictions\n",
    "        ohlc_data_with_predictions = load_and_align_data(ohlc_data, pair_config['buy_prediction_file'], pair_config['sell_prediction_file'])\n",
    "        if ohlc_data_with_predictions is not None:\n",
    "            stats = run_backtest(ohlc_data_with_predictions, PredictionStrategy, pair_config['buy_risk_reward_ratio'], pair_config['sell_risk_reward_ratio'], pair_name)\n",
    "            print(f\"Backtest results for {pair_name}:\", stats)\n",
    "        else:\n",
    "            logging.error(f\"Skipping {pair_name} due to prediction data issue\")\n",
    "\n",
    "    # Shutdown MetaTrader 5 connection after backtesting\n",
    "    mt5.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f6f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
