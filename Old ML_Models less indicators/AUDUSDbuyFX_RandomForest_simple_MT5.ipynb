{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import talib\n",
    "from talipp.indicators import EMA, SMA, Stoch, DPO\n",
    "from joblib import dump\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, confusion_matrix, classification_report\n",
    "from own_functions import *\n",
    "import os\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, make_forecasting_frame\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "mt.initialize()\n",
    "login = 51708234\n",
    "password = \"4bM&wuVJcBTnjV\"\n",
    "server = \"ICMarketsEU-Demo\"\n",
    "mt.login(login, password, server)\n",
    "\n",
    "# Fetch historical data\n",
    "symbol = \"AUDUSD\"\n",
    "timeframe = mt.TIMEFRAME_D1\n",
    "ohlc_data = pd.DataFrame(mt.copy_rates_range(symbol, timeframe, datetime(2010, 1, 1), datetime(2024, 10, 10)))\n",
    "ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "df = ohlc_data[['time', 'open', 'high', 'low', 'close']].copy()\n",
    "\n",
    "# Function to add rolling features\n",
    "def add_rolling_features(df, window):\n",
    "    df['rolling_mean_open'] = df['open'].rolling(window=window).mean()\n",
    "    df['rolling_std_open'] = df['open'].rolling(window=window).std()\n",
    "    df['rolling_mean_close'] = df['close'].rolling(window=window).mean()\n",
    "    df['rolling_std_close'] = df['close'].rolling(window=window).std()\n",
    "    df['rolling_mean_high'] = df['high'].rolling(window=window).mean()\n",
    "    df['rolling_std_high'] = df['high'].rolling(window=window).std()\n",
    "    df['rolling_mean_low'] = df['low'].rolling(window=window).mean()\n",
    "    df['rolling_std_low'] = df['low'].rolling(window=window).std()\n",
    "    return df\n",
    "\n",
    "# Function to add lag features\n",
    "def add_lag_features(df, lags):\n",
    "    for lag in lags:\n",
    "        df[f'open_lag_{lag}'] = df['open'].shift(lag)\n",
    "        df[f'close_lag_{lag}'] = df['close'].shift(lag)\n",
    "        df[f'high_lag_{lag}'] = df['high'].shift(lag)\n",
    "        df[f'low_lag_{lag}'] = df['low'].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Calculate Indicators\n",
    "df['EMA_9'] = talib.EMA(df['close'], timeperiod=9)\n",
    "df['EMA_21'] = talib.EMA(df['close'], timeperiod=21)\n",
    "df['EMA_50'] = talib.EMA(df['close'], timeperiod=50)\n",
    "\n",
    "df['RSI_9'] = talib.RSI(df['close'], timeperiod=9)\n",
    "df['RSI_14'] = talib.RSI(df['close'], timeperiod=14)\n",
    "df['RSI_21'] = talib.RSI(df['close'], timeperiod=21)\n",
    "\n",
    "df['WILLR_15'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=15)\n",
    "df['WILLR_23'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=23)\n",
    "df['WILLR_42'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=42)\n",
    "df['WILLR_145'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=145)\n",
    "\n",
    "df['SAR'] = talib.SAR(df['high'], df['low'], acceleration=0.02, maximum=0.2)\n",
    "\n",
    "df['BB_upper'], df['BB_middle'], df['BB_lower'] = talib.BBANDS(df['close'], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "df['BB_width'] = df['BB_upper'] - df['BB_lower']\n",
    "\n",
    "df['MACD'], df['MACD_signal'], df['MACD_hist'] = talib.MACD(df['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "\n",
    "df['CCI_14'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "\n",
    "# Add rolling and lagged features\n",
    "df = add_rolling_features(df, window=5)\n",
    "df = add_lag_features(df, lags=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Drop NaN values caused by rolling and lagged operations\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Buy & Sell Flags\n",
    "df['b_flag'] = 0\n",
    "df['s_flag'] = 0\n",
    "\n",
    "# Dropping NaN values and resetting index\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "csv_file_path = 'EURUSD_D1_2010to101024.csv'  # Specify your desired path\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "StopLoss = 1\n",
    "TakeProfit = 1\n",
    "BreakEvenRatio=StopLoss/(StopLoss+TakeProfit)\n",
    "label_data(df,[StopLoss],[TakeProfit],80,symbol,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af671f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number of 1s in b_flag and s_flag columns\n",
    "total_b_flags = df['b_flag'].sum()\n",
    "total_s_flags = df['s_flag'].sum()\n",
    "\n",
    "# Total number of rows in the DataFrame\n",
    "total_rows = len(df)\n",
    "\n",
    "# Calculate counts in segments of complete 100% data\n",
    "count_100_b_flags = total_b_flags\n",
    "count_100_s_flags = total_s_flags\n",
    "\n",
    "# Calculate counts in intervals of 10%\n",
    "interval_counts = []\n",
    "for i in range(0, 101, 10):\n",
    "    start_idx = int(i / 100 * total_rows)\n",
    "    end_idx = int((i + 10) / 100 * total_rows)\n",
    "    \n",
    "    interval_b_flags = df['b_flag'].iloc[start_idx:end_idx].sum()\n",
    "    interval_s_flags = df['s_flag'].iloc[start_idx:end_idx].sum()\n",
    "    \n",
    "    interval_counts.append((f'{i}% - {i+10}%', interval_b_flags, interval_s_flags))\n",
    "\n",
    "# Print results\n",
    "print(\"Total number of 1s:\")\n",
    "print(f\"b_flag: {total_b_flags}\")\n",
    "print(f\"s_flag: {total_s_flags}\")\n",
    "\n",
    "print(\"\\nCounts in segments of 100% data:\")\n",
    "print(f\"b_flag: {count_100_b_flags}\")\n",
    "print(f\"s_flag: {count_100_s_flags}\")\n",
    "\n",
    "print(\"\\nCounts in intervals of 10%:\")\n",
    "for interval, count_b, count_s in interval_counts:\n",
    "    print(f\"{interval}: b_flag={count_b}, s_flag={count_s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27706466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "# Drop irrelevant columns (s_flag)\n",
    "df.drop(columns=['s_flag'], inplace=True)\n",
    "\n",
    "# Feature extraction helper\n",
    "def extract_rolling_features(df, signal, symbol, max_shift=20, min_shift=5):\n",
    "    df_melted = df[['time', signal]].copy()\n",
    "    df_melted[\"Symbols\"] = symbol\n",
    "    df_rolled = roll_time_series(df_melted, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                                 max_timeshift=max_shift, min_timeshift=min_shift)\n",
    "    X = extract_features(df_rolled.drop(\"Symbols\", axis=1),\n",
    "                         column_id=\"id\", column_sort=\"time\", column_value=signal,\n",
    "                         impute_function=impute, show_warnings=False)\n",
    "    X = X.set_index(X.index.map(lambda x: x[1]), drop=True)\n",
    "    X.index.name = \"time\"\n",
    "    return X.dropna()\n",
    "\n",
    "X1 = extract_rolling_features(df, 'WILLR_15', symbol)\n",
    "X2 = extract_rolling_features(df, 'WILLR_42', symbol)\n",
    "X3 = extract_rolling_features(df, 'RSI_14', symbol)\n",
    "X4 = extract_rolling_features(df, 'MACD_hist', symbol)\n",
    "X5 = extract_rolling_features(df, 'EMA_9', symbol)\n",
    "X6 = extract_rolling_features(df, 'EMA_21', symbol)\n",
    "X7 = extract_rolling_features(df, 'EMA_50', symbol)\n",
    "X9 = extract_rolling_features(df, 'RSI_9', symbol)\n",
    "X10 = extract_rolling_features(df, 'RSI_21', symbol)\n",
    "X11 = extract_rolling_features(df, 'WILLR_23', symbol)\n",
    "X12 = extract_rolling_features(df, 'WILLR_145', symbol)\n",
    "X13 = extract_rolling_features(df, 'SAR', symbol)\n",
    "X14 = extract_rolling_features(df, 'BB_width', symbol)\n",
    "X15 = extract_rolling_features(df, 'MACD_signal', symbol)\n",
    "X16 = extract_rolling_features(df, 'CCI_14', symbol)\n",
    "\n",
    "# Combine all extracted features\n",
    "X = pd.concat([X1, X2, X3, X4, X5, X6, X7, X9, X10, X11, X12, X13, X14, X15, X16], axis=1, join='inner').dropna()\n",
    "\n",
    "# Align features with the main DataFrame\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.set_index('time')\n",
    "df = df[df.index.isin(X.index)]\n",
    "X = pd.concat([X, df], axis=1, join='inner')\n",
    "\n",
    "# Select features and align target (b_flag)\n",
    "X_df = select_features(X, X['b_flag'])\n",
    "X_df = X_df[[col for col in X_df if col != 'b_flag'] + ['b_flag']]\n",
    "\n",
    "# Remove highly correlated features\n",
    "correlation_matrix = X_df.corr().abs()\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "high_correlation_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.8)]\n",
    "X_df = X_df.drop(columns=high_correlation_features)\n",
    "\n",
    "# Shift features to align with the target\n",
    "original_index = X_df.index\n",
    "shifted_X_df = X_df.shift(periods=1, axis=0)\n",
    "shifted_X_df.index = original_index\n",
    "X_df = shifted_X_df.dropna()\n",
    "\n",
    "# Get the list of selected feature names\n",
    "selected_feature_names_X = list(X_df.columns)\n",
    "\n",
    "# Combine lists if you need a single list for all selected features\n",
    "\n",
    "print(selected_feature_names_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef883039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "sum_fp = 0\n",
    "sum_tp = 0\n",
    "\n",
    "# Split into train and test sets\n",
    "split = int(0.90 * len(X_df))  # Use the feature-engineered X_df, not df\n",
    "train_data, test_data = X_df.iloc[:split], X_df.iloc[split:]\n",
    "\n",
    "# Train data\n",
    "# Ensure correct feature and target selection:\n",
    "x_train = train_data.iloc[:, :-1].values  # Features are all columns except the last one (b_flag)\n",
    "y_train = train_data['b_flag'].values  # Target is the b_flag column\n",
    "\n",
    "x_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data['b_flag'].values\n",
    "\n",
    "# Scale Data\n",
    "sc_mt = StandardScaler()\n",
    "x_train = sc_mt.fit_transform(x_train)\n",
    "x_test = sc_mt.transform(x_test)\n",
    "\n",
    "# Hyperparameters\n",
    "n_estimators = 200\n",
    "class_weight = {0: 6, 1: 1}\n",
    "max_features = 'sqrt'\n",
    "random_state = 0\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_classifier_mt = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    class_weight=class_weight,\n",
    "    max_features=max_features,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_classifier_mt.fit(x_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = rf_classifier_mt.predict(x_test)\n",
    "y_pred_proba = rf_classifier_mt.predict_proba(x_test)[:, 1]  # Probability predictions for class 1\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "false_positives = conf_matrix[0][1]\n",
    "true_positives = conf_matrix[1][1]\n",
    "\n",
    "sum_fp += false_positives\n",
    "sum_tp += true_positives\n",
    "\n",
    "# Compute additional metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print('Accuracy:', round(accuracy, 4))\n",
    "print('Precision:', round(precision, 4))\n",
    "print('Recall:', round(recall, 4))\n",
    "print('F1 Score:', round(f1, 4))\n",
    "print('ROC-AUC:', round(roc_auc, 4))\n",
    "print('Classification Report:\\n', classification_rep)\n",
    "\n",
    "# WIN/LOSS Differentials and Other Metrics\n",
    "print('WIN/LOSS-Diff:', round(100 * (precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', sum_fp)\n",
    "print('True Positives:', sum_tp)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('Ratio total:', round(100 * (sum_tp / (sum_fp + sum_tp)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b814e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from talipp.indicators import EMA, SMA, Stoch, DPO\n",
    "from joblib import dump\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, confusion_matrix, classification_report, recall_score, accuracy_score, f1_score, roc_auc_score\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, impute\n",
    "from own_functions import label_data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Hardcoded credentials - as requested\n",
    "login = 51708234\n",
    "password = \"4bM&wuVJcBTnjV\"\n",
    "server = \"ICMarketsEU-Demo\"\n",
    "\n",
    "mt.initialize()\n",
    "mt.login(login, password, server)\n",
    "\n",
    "symbol = \"AUDUSD\"\n",
    "timeframe = mt.TIMEFRAME_D1\n",
    "start_date = datetime(2010, 1, 1)\n",
    "end_date = datetime(2024, 11, 10)\n",
    "StopLoss = 1\n",
    "TakeProfit = 1\n",
    "BreakEvenRatio = StopLoss / (StopLoss + TakeProfit)\n",
    "\n",
    "def add_rolling_features(df, window):\n",
    "    df['rolling_mean_open'] = df['open'].rolling(window=window).mean()\n",
    "    df['rolling_std_open'] = df['open'].rolling(window=window).std()\n",
    "    df['rolling_mean_close'] = df['close'].rolling(window=window).mean()\n",
    "    df['rolling_std_close'] = df['close'].rolling(window=window).std()\n",
    "    df['rolling_mean_high'] = df['high'].rolling(window=window).mean()\n",
    "    df['rolling_std_high'] = df['high'].rolling(window=window).std()\n",
    "    df['rolling_mean_low'] = df['low'].rolling(window=window).mean()\n",
    "    df['rolling_std_low'] = df['low'].rolling(window=window).std()\n",
    "    return df\n",
    "\n",
    "def add_lag_features(df, lags):\n",
    "    for lag in lags:\n",
    "        df[f'open_lag_{lag}'] = df['open'].shift(lag)\n",
    "        df[f'close_lag_{lag}'] = df['close'].shift(lag)\n",
    "        df[f'high_lag_{lag}'] = df['high'].shift(lag)\n",
    "        df[f'low_lag_{lag}'] = df['low'].shift(lag)\n",
    "    return df\n",
    "\n",
    "def extract_rolling_features(df, signal, symbol, max_shift=20, min_shift=5):\n",
    "    df_melted = df[['time', signal]].copy()\n",
    "    df_melted[\"Symbols\"] = symbol\n",
    "    df_rolled = roll_time_series(df_melted, column_id=\"Symbols\", column_sort=\"time\",\n",
    "                                 max_timeshift=max_shift, min_timeshift=min_shift)\n",
    "    X = extract_features(df_rolled.drop(\"Symbols\", axis=1),\n",
    "                         column_id=\"id\", column_sort=\"time\", column_value=signal,\n",
    "                         impute_function=impute, show_warnings=False)\n",
    "    X = X.set_index(X.index.map(lambda x: x[1]), drop=True)\n",
    "    X.index.name = \"time\"\n",
    "    return X.dropna()\n",
    "\n",
    "# Fetch historical data\n",
    "ohlc_data = pd.DataFrame(mt.copy_rates_range(symbol, timeframe, start_date, end_date))\n",
    "ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "df = ohlc_data[['time', 'open', 'high', 'low', 'close']].copy()\n",
    "\n",
    "df['EMA_9'] = talib.EMA(df['close'], timeperiod=9)\n",
    "df['EMA_21'] = talib.EMA(df['close'], timeperiod=21)\n",
    "df['EMA_50'] = talib.EMA(df['close'], timeperiod=50)\n",
    "\n",
    "df['RSI_9'] = talib.RSI(df['close'], timeperiod=9)\n",
    "df['RSI_14'] = talib.RSI(df['close'], timeperiod=14)\n",
    "df['RSI_21'] = talib.RSI(df['close'], timeperiod=21)\n",
    "\n",
    "df['WILLR_15'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=15)\n",
    "df['WILLR_23'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=23)\n",
    "df['WILLR_42'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=42)\n",
    "df['WILLR_145'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=145)\n",
    "\n",
    "df['SAR'] = talib.SAR(df['high'], df['low'], acceleration=0.02, maximum=0.2)\n",
    "\n",
    "df['BB_upper'], df['BB_middle'], df['BB_lower'] = talib.BBANDS(df['close'], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "df['BB_width'] = df['BB_upper'] - df['BB_lower']\n",
    "\n",
    "df['MACD'], df['MACD_signal'], df['MACD_hist'] = talib.MACD(df['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "df['CCI_14'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "\n",
    "df = add_rolling_features(df, window=5)\n",
    "df = add_lag_features(df, lags=[1, 2, 3, 4, 5])\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['b_flag'] = 0\n",
    "df['s_flag'] = 0\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "#csv_file_path = 'EURUSD_D1_2010to101124.csv'  # Specify your desired path\n",
    "#df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "label_data(df, [StopLoss], [TakeProfit], 80, symbol, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdd415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['s_flag'], inplace=True)\n",
    "\n",
    "X1 = extract_rolling_features(df, 'WILLR_15', symbol)\n",
    "X2 = extract_rolling_features(df, 'WILLR_42', symbol)\n",
    "X3 = extract_rolling_features(df, 'RSI_14', symbol)\n",
    "X4 = extract_rolling_features(df, 'MACD_hist', symbol)\n",
    "X5 = extract_rolling_features(df, 'EMA_9', symbol)\n",
    "X6 = extract_rolling_features(df, 'EMA_21', symbol)\n",
    "X7 = extract_rolling_features(df, 'EMA_50', symbol)\n",
    "X9 = extract_rolling_features(df, 'RSI_9', symbol)\n",
    "X10 = extract_rolling_features(df, 'RSI_21', symbol)\n",
    "X11 = extract_rolling_features(df, 'WILLR_23', symbol)\n",
    "X12 = extract_rolling_features(df, 'WILLR_145', symbol)\n",
    "X13 = extract_rolling_features(df, 'SAR', symbol)\n",
    "X14 = extract_rolling_features(df, 'BB_width', symbol)\n",
    "X15 = extract_rolling_features(df, 'MACD_signal', symbol)\n",
    "X16 = extract_rolling_features(df, 'CCI_14', symbol)\n",
    "\n",
    "# Combine all extracted features\n",
    "X = pd.concat([X1, X2, X3, X4, X5, X6, X7, X9, X10, X11, X12, X13, X14, X15, X16], axis=1, join='inner').dropna()\n",
    "\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.set_index('time')\n",
    "X = X[X.index.isin(df.index)]\n",
    "X = pd.concat([df,X], axis=1, join='inner')\n",
    "\n",
    "X_df = select_features(X, X['b_flag'])\n",
    "X_df = X_df[[col for col in X_df if col != 'b_flag'] + ['b_flag']]\n",
    "\n",
    "correlation_matrix = X_df.corr().abs()\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "high_correlation_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.9)]\n",
    "X_df = X_df.drop(columns=high_correlation_features)\n",
    "\n",
    "original_index = X_df.index\n",
    "X_df = X_df.shift(periods=1, axis=0)\n",
    "X_df.index = original_index\n",
    "X_df = X_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de92c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.90 * len(X_df))\n",
    "train_data, test_data = X_df.iloc[:split], X_df.iloc[split:]\n",
    "\n",
    "x_train = train_data.iloc[:, :-1].values\n",
    "y_train = train_data['b_flag'].values\n",
    "x_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data['b_flag'].values\n",
    "\n",
    "sc_mt = StandardScaler()\n",
    "x_train = sc_mt.fit_transform(x_train)\n",
    "x_test = sc_mt.transform(x_test)\n",
    "\n",
    "print(\"Number of features before PCA:\", x_train.shape[1])\n",
    "\n",
    "# Apply PCA to reduce dimensionality\n",
    "\n",
    "pca = PCA(n_components=15, svd_solver='randomized', random_state=0)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "\n",
    "print(\"Number of features after PCA:\", x_train.shape[1])\n",
    "\n",
    "n_estimators = 150\n",
    "class_weight = {0: 1, 1: 5}\n",
    "max_features = 'sqrt'\n",
    "random_state = 0\n",
    "\n",
    "rf_classifier_mt = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    class_weight=class_weight,\n",
    "    max_features=max_features,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "rf_classifier_mt.fit(x_train, y_train)\n",
    "y_pred_proba = rf_classifier_mt.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Add probability threshold for predicting class 1\n",
    "threshold = 0.6  # Adjust as needed to increase precision\n",
    "y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "false_positives = conf_matrix[0][1]\n",
    "true_positives = conf_matrix[1][1]\n",
    "\n",
    "precision = precision_score(y_test, y_pred) if (false_positives+true_positives) > 0 else 0\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print('Accuracy:', round(accuracy, 4))\n",
    "print('Precision:', round(precision, 4))\n",
    "print('Recall:', round(recall, 4))\n",
    "print('F1 Score:', round(f1, 4))\n",
    "print('ROC-AUC:', round(roc_auc, 4))\n",
    "print('Classification Report:\\n', classification_rep)\n",
    "print('WIN/LOSS-Diff:', round(100 * (precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', false_positives)\n",
    "print('True Positives:', true_positives)\n",
    "if (false_positives + true_positives) > 0:\n",
    "    print('Ratio total:', round(100 * (true_positives / (false_positives + true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36887e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "feature_names = X_df.columns\n",
    "with open('AUDUSD_D1_3112buy/feature_names.json', 'w') as f:\n",
    "    json.dump(list(feature_names), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f65221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to datetime without 'unit' since the format is already date strings\n",
    "X_df.index = pd.to_datetime(X_df.index)\n",
    "\n",
    "# Format datetime to the desired string format\n",
    "X_df.index = X_df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Creating a DataFrame for predictions with the correct index\n",
    "df_pred = pd.DataFrame(index=X_df.iloc[split:].index)  # No need for split+1\n",
    "df_pred['prediction'] = y_pred\n",
    "\n",
    "# Save to CSV\n",
    "df_pred.to_csv('predAUDUSD_D1_3112buy.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MetaTrader5 as mt5\n",
    "from backtesting import Backtest, Strategy\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(filename='backtest.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# MetaTrader 5 initialization\n",
    "def init_mt5_connection(login, password, server):\n",
    "    if not mt5.initialize(login=login, password=password, server=server):\n",
    "        logging.error(f\"initialize() failed, error code = {mt5.last_error()}\")\n",
    "        sys.exit()\n",
    "    logging.info(\"Connected to MetaTrader 5\")\n",
    "    print(\"Connected to MetaTrader 5\")\n",
    "\n",
    "# Fetch historical OHLC data from MetaTrader 5\n",
    "def fetch_ohlc_data(symbol, timeframe, start_date, end_date):\n",
    "    data = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    if data is None or len(data) == 0:\n",
    "        logging.error(f\"Failed to fetch data for {symbol}\")\n",
    "        return None\n",
    "    ohlc_data = pd.DataFrame(data)\n",
    "    ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "    ohlc_data.rename(columns={'open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'tick_volume': 'Volume'}, inplace=True)\n",
    "    return ohlc_data[['time', 'Open', 'High', 'Low', 'Close', 'Volume']]  # Include Volume\n",
    "\n",
    "# Load and align prediction data\n",
    "def load_and_align_data(ohlc_data, prediction_file):\n",
    "    try:\n",
    "        predictions = pd.read_csv(prediction_file, parse_dates=['time'])\n",
    "        if 'prediction' not in predictions.columns:\n",
    "            logging.error(f\"'prediction' column not found in {prediction_file}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading prediction file: {e}\")\n",
    "        return None\n",
    "    # Merge predictions with OHLC data\n",
    "    ohlc_data = ohlc_data.merge(predictions[['time', 'prediction']], on='time', how='left')\n",
    "    ohlc_data['prediction'] = ohlc_data['prediction'].fillna(0)  # Fill missing predictions with 0\n",
    "    ohlc_data['prediction'] = ohlc_data['prediction'].shift(1)  # Shift predictions to next date\n",
    "    return ohlc_data\n",
    "\n",
    "# Backtesting strategy for Buy or Sell\n",
    "class PredictionStrategy(Strategy):\n",
    "    risk_reward_ratio = (2, 3)  # Default risk-reward ratio\n",
    "    signal_type = 'Buy'  # Default signal type\n",
    "    mean_candle_size = 0.0105  # Default mean candle size\n",
    "\n",
    "    def init(self):\n",
    "        # Mean candle size now taken from strategy properties set during strategy initialization\n",
    "        pass\n",
    "\n",
    "    def next(self):\n",
    "        entry_price = self.data.Close[-1]\n",
    "        risk_part, reward_part = self.risk_reward_ratio\n",
    "        # Buy signal\n",
    "        if self.data.prediction[-1] == 1 and self.signal_type == 'Buy':\n",
    "            sl_price = entry_price - self.mean_candle_size * risk_part\n",
    "            tp_price = entry_price + self.mean_candle_size * reward_part\n",
    "            self.buy(sl=sl_price, tp=tp_price)\n",
    "        # Sell signal\n",
    "        elif self.data.prediction[-1] == 1 and self.signal_type == 'Sell':\n",
    "            sl_price = entry_price + self.mean_candle_size * risk_part\n",
    "            tp_price = entry_price - self.mean_candle_size * reward_part\n",
    "            self.sell(sl=sl_price, tp=tp_price)\n",
    "\n",
    "# Function to perform backtesting and save stats/plot\n",
    "def run_backtest(ohlc_data, strategy_class, risk_reward_ratio, pair_name, signal_type, mean_candle_size):\n",
    "    strategy_class.risk_reward_ratio = risk_reward_ratio\n",
    "    strategy_class.signal_type = signal_type\n",
    "    strategy_class.mean_candle_size = mean_candle_size  # Set mean candle size for the strategy\n",
    "    bt = Backtest(ohlc_data.set_index('time'), strategy_class, cash=10000, commission=.0003,margin=0.2)\n",
    "    stats = bt.run()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bt.plot()\n",
    "    plt.title(f'Backtest for {pair_name} - {signal_type}')\n",
    "    plt.savefig(f'backtest_plot_{pair_name}_{signal_type}.png')\n",
    "    plt.close()\n",
    "    stats_df = pd.DataFrame([stats])\n",
    "    stats_df.to_csv(f'backtest_stats_{pair_name}_{signal_type}.csv', index=False)\n",
    "    return stats\n",
    "\n",
    "# Main function to fetch OHLC data, align it with prediction data, and run backtest for each buy/sell\n",
    "def main():\n",
    "    config = {\n",
    "        'login': 51988090,\n",
    "        'password': '1fMdV52$74EOcw',\n",
    "        'server': 'ICMarketsEU-Demo',\n",
    "        'EURUSD': {\n",
    "            'symbol': 'EURUSD',\n",
    "            'timeframe': mt5.TIMEFRAME_D1,\n",
    "            'mean_candle_size': 0.009196304524519085,\n",
    "            'buy_prediction_file': 'predEURUSD_D1_3112buy.csv',\n",
    "            'buy_risk_reward_ratio': (1, 1),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    init_mt5_connection(config['login'], config['password'], config['server'])\n",
    "    utc_from = datetime(2021, 5, 9, tzinfo=pytz.utc)\n",
    "    utc_to = datetime(2024, 10, 7, tzinfo=pytz.utc)\n",
    "\n",
    "    for pair_name, pair_config in config.items():\n",
    "        if pair_name in ['login', 'password', 'server']:\n",
    "            continue\n",
    "        logging.info(f\"Processing {pair_name}...\")\n",
    "        ohlc_data = fetch_ohlc_data(pair_config['symbol'], pair_config['timeframe'], utc_from, utc_to)\n",
    "        if ohlc_data is None:\n",
    "            continue\n",
    "\n",
    "        if pair_config['buy_prediction_file']:\n",
    "            ohlc_data_with_predictions = load_and_align_data(ohlc_data, pair_config['buy_prediction_file'])\n",
    "            if ohlc_data_with_predictions is not None:\n",
    "                stats = run_backtest(ohlc_data_with_predictions, PredictionStrategy, pair_config['buy_risk_reward_ratio'], pair_name, 'Buy', pair_config['mean_candle_size'])\n",
    "                print(f\"Backtest results for {pair_name} - Buy:\\n\", stats)\n",
    "        if pair_config.get('sell_prediction_file'):\n",
    "            ohlc_data_with_predictions = load_and_align_data(ohlc_data, pair_config['sell_prediction_file'])\n",
    "            if ohlc_data_with_predictions is not None:\n",
    "                stats = run_backtest(ohlc_data_with_predictions, PredictionStrategy, pair_config['sell_risk_reward_ratio'], pair_name, 'Sell', pair_config['mean_candle_size'])\n",
    "                print(f\"Backtest results for {pair_name} - Sell:\\n\", stats)\n",
    "\n",
    "    mt5.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779fc2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MetaTrader5 as mt5\n",
    "from backtesting import Backtest, Strategy\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(filename='backtest.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# MetaTrader 5 initialization\n",
    "def init_mt5_connection(login, password, server):\n",
    "    if not mt5.initialize(login=login, password=password, server=server):\n",
    "        logging.error(f\"initialize() failed, error code = {mt5.last_error()}\")\n",
    "        sys.exit()\n",
    "    logging.info(\"Connected to MetaTrader 5\")\n",
    "    print(\"Connected to MetaTrader 5\")\n",
    "\n",
    "# Fetch historical OHLC data from MetaTrader 5\n",
    "def fetch_ohlc_data(symbol, timeframe, start_date, end_date):\n",
    "    data = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    if data is None or len(data) == 0:\n",
    "        logging.error(f\"Failed to fetch data for {symbol}\")\n",
    "        return None\n",
    "    ohlc_data = pd.DataFrame(data)\n",
    "    ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "    ohlc_data.rename(columns={'open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'tick_volume': 'Volume'}, inplace=True)\n",
    "    return ohlc_data[['time', 'Open', 'High', 'Low', 'Close', 'Volume']]  # Include Volume, even if it's not mandatory\n",
    "\n",
    "# Load and align prediction data\n",
    "def load_and_align_data(ohlc_data, prediction_file):\n",
    "    try:\n",
    "        predictions = pd.read_csv(prediction_file, parse_dates=['time'])\n",
    "        if 'prediction' not in predictions.columns:\n",
    "            logging.error(f\"'prediction' column not found in {prediction_file}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading prediction file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Merge predictions with OHLC data\n",
    "    ohlc_data = ohlc_data.merge(predictions[['time', 'prediction']], on='time', how='left')\n",
    "    ohlc_data['prediction'] = ohlc_data['prediction'].fillna(0)  # Fill missing predictions with 0\n",
    "    ohlc_data['prediction'] = ohlc_data['prediction'].shift(1)  # Shift predictions by one day to start trade on the next date\n",
    "    return ohlc_data\n",
    "\n",
    "# Backtesting strategy for Buy or Sell\n",
    "class PredictionStrategy(Strategy):\n",
    "    risk_reward_ratio = (2, 3)  # Default risk-reward ratio\n",
    "    signal_type = 'Buy'  # Default signal type\n",
    "    mean_candle_size = 0  # Mean candle size based on historical data\n",
    "\n",
    "    def init(self):\n",
    "        # Calculate mean candle size based on historical data\n",
    "        self.mean_candle_size = 0.0105\n",
    "\n",
    "    def next(self):\n",
    "        entry_price = self.data.Close[-1]\n",
    "        risk_part, reward_part = self.risk_reward_ratio\n",
    "\n",
    "        # Buy signal\n",
    "        if self.data.prediction[-1] == 1 and self.signal_type == 'Buy':\n",
    "            sl_price = entry_price - self.mean_candle_size * risk_part\n",
    "            tp_price = entry_price + self.mean_candle_size * reward_part\n",
    "            self.buy(sl=sl_price, tp=tp_price)\n",
    "\n",
    "        # Sell signal\n",
    "        elif self.data.prediction[-1] == 1 and self.signal_type == 'Sell':\n",
    "            sl_price = entry_price + self.mean_candle_size * risk_part\n",
    "            tp_price = entry_price - self.mean_candle_size * reward_part\n",
    "            self.sell(sl=sl_price, tp=tp_price)\n",
    "\n",
    "# Function to perform backtesting and save stats/plot\n",
    "def run_backtest(ohlc_data, strategy_class, risk_reward_ratio, pair_name, signal_type):\n",
    "    strategy_class.risk_reward_ratio = risk_reward_ratio  # Set specific risk-reward ratio for each pair\n",
    "    strategy_class.signal_type = signal_type  # Set the signal type (Buy or Sell)\n",
    "    bt = Backtest(ohlc_data.set_index('time'), strategy_class, cash=10000, commission=.0003,margin=0.01)\n",
    "    stats = bt.run()\n",
    "\n",
    "    # Generate and save the backtest plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bt.plot()  # This generates the plot using backtesting.py's internal plot function\n",
    "    plt.draw()  # Make sure the plot is rendered properly\n",
    "    plt.pause(0.1)  # Pause to ensure rendering before saving\n",
    "    plt.title(f'Backtest for {pair_name} - {signal_type}')  # Add pair name and signal type to the title\n",
    "    plt.savefig(f'backtest_plot_{pair_name}_{signal_type}.png')  # Save the plot manually using matplotlib\n",
    "    plt.close()  # Close the plot to avoid displaying it in the environment\n",
    "\n",
    "    # Save backtest stats as CSV\n",
    "    stats_df = pd.DataFrame([stats])\n",
    "    stats_df.to_csv(f'backtest_stats_{pair_name}_{signal_type}.csv', index=False)\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "# Main function to fetch OHLC data, align it with prediction data, and run backtest for each buy/sell\n",
    "def main():\n",
    "    # Configuration for MetaTrader 5 connection\n",
    "    config = {\n",
    "        'login': 51988090,\n",
    "        'password': '1fMdV52$74EOcw',\n",
    "        'server': 'ICMarketsEU-Demo'\n",
    "    }\n",
    "\n",
    "    # Initialize MetaTrader 5 connection\n",
    "    init_mt5_connection(config['login'], config['password'], config['server'])\n",
    "\n",
    "    # Define the time period for backtesting\n",
    "    utc_from = datetime(2023, 5, 9, tzinfo=pytz.utc)\n",
    "    utc_to = datetime(2024, 10, 7, tzinfo=pytz.utc)\n",
    "\n",
    "    # Currency pair configurations\n",
    "    currency_pairs = {\n",
    "        'USDCAD': {\n",
    "            'symbol': 'USDCAD',\n",
    "            'timeframe': mt5.TIMEFRAME_D1,\n",
    "            'buy_prediction_file': 'predUSDCAD_D1_3112buy.csv',\n",
    "            'buy_risk_reward_ratio': (1, 1),  # EURUSD Buy Risk-Reward Ratio\n",
    "            'sell_risk_reward_ratio': (1, 2),  # EURUSD Sell Risk-Reward Ratio\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Loop through each currency pair and perform backtest\n",
    "    for pair_name, pair_config in currency_pairs.items():\n",
    "        logging.info(f\"Processing {pair_name}...\")\n",
    "\n",
    "        # Fetch OHLC data\n",
    "        ohlc_data = fetch_ohlc_data(pair_config['symbol'], pair_config['timeframe'], utc_from, utc_to)\n",
    "        if ohlc_data is None:\n",
    "            logging.error(f\"Skipping {pair_name} due to missing OHLC data\")\n",
    "            continue\n",
    "\n",
    "        # Backtest Buy predictions if the file exists\n",
    "        if pair_config['buy_prediction_file']:\n",
    "            ohlc_data_with_predictions = load_and_align_data(ohlc_data, pair_config['buy_prediction_file'])\n",
    "            if ohlc_data_with_predictions is not None:\n",
    "                stats = run_backtest(ohlc_data_with_predictions, PredictionStrategy, pair_config['buy_risk_reward_ratio'], pair_name, 'Buy')\n",
    "                print(f\"Backtest results for {pair_name} - Buy:\\n\", stats)\n",
    "            else:\n",
    "                logging.error(f\"Skipping {pair_name} Buy due to prediction data issue\")\n",
    "\n",
    "        # Backtest Sell predictions if the file exists\n",
    "        if pair_config.get('sell_prediction_file'):\n",
    "            ohlc_data_with_predictions = load_and_align_data(ohlc_data, pair_config['sell_prediction_file'])\n",
    "            if ohlc_data_with_predictions is not None:\n",
    "                stats = run_backtest(ohlc_data_with_predictions, PredictionStrategy, pair_config['sell_risk_reward_ratio'], pair_name, 'Sell')\n",
    "                print(f\"Backtest results for {pair_name} - Sell:\\n\", stats)\n",
    "            else:\n",
    "                logging.error(f\"Skipping {pair_name} Sell due to prediction data issue\")\n",
    "\n",
    "    # Shutdown MetaTrader 5 connection after backtesting\n",
    "    mt5.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MetaTrader5 as mt5\n",
    "from backtesting import Backtest, Strategy\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(filename='backtest.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# MetaTrader 5 initialization\n",
    "def init_mt5_connection(login, password, server):\n",
    "    if not mt5.initialize(login=login, password=password, server=server):\n",
    "        logging.error(f\"initialize() failed, error code = {mt5.last_error()}\")\n",
    "        sys.exit()\n",
    "    logging.info(\"Connected to MetaTrader 5\")\n",
    "    print(\"Connected to MetaTrader 5\")\n",
    "\n",
    "# Fetch historical OHLC data from MetaTrader 5\n",
    "def fetch_ohlc_data(symbol, timeframe, start_date, end_date):\n",
    "    data = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    if data is None or len(data) == 0:\n",
    "        logging.error(f\"Failed to fetch data for {symbol}\")\n",
    "        return None\n",
    "    ohlc_data = pd.DataFrame(data)\n",
    "    ohlc_data['time'] = pd.to_datetime(ohlc_data['time'], unit='s')\n",
    "    ohlc_data.rename(columns={'open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'tick_volume': 'Volume'}, inplace=True)\n",
    "    return ohlc_data[['time', 'Open', 'High', 'Low', 'Close', 'Volume']]  # Include Volume, even if it's not mandatory\n",
    "\n",
    "# Load and align prediction data\n",
    "def load_and_align_data(ohlc_data, buy_prediction_file, sell_prediction_file):\n",
    "    try:\n",
    "        buy_predictions = pd.read_csv(buy_prediction_file, parse_dates=['time'])\n",
    "        sell_predictions = pd.read_csv(sell_prediction_file, parse_dates=['time'])\n",
    "        if 'prediction' not in buy_predictions.columns or 'prediction' not in sell_predictions.columns:\n",
    "            logging.error(f\"'prediction' column not found in one of the prediction files\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading prediction file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Merge predictions with OHLC data\n",
    "    ohlc_data = ohlc_data.merge(buy_predictions[['time', 'prediction']], on='time', how='left', suffixes=('', '_buy'))\n",
    "    ohlc_data = ohlc_data.merge(sell_predictions[['time', 'prediction']], on='time', how='left', suffixes=('', '_sell'))\n",
    "    ohlc_data['prediction_buy'] = ohlc_data['prediction'].fillna(0)\n",
    "    ohlc_data['prediction_sell'] = ohlc_data['prediction_sell'].fillna(0)\n",
    "    ohlc_data['prediction_buy'] = ohlc_data['prediction_buy'].shift(1)  # Shift predictions by one day to start trade on the next date\n",
    "    ohlc_data['prediction_sell'] = ohlc_data['prediction_sell'].shift(1)\n",
    "    ohlc_data.drop(columns=['prediction'], inplace=True)\n",
    "    return ohlc_data\n",
    "\n",
    "# Backtesting strategy for Buy or Sell\n",
    "class PredictionStrategy(Strategy):\n",
    "    risk_reward_ratio_buy = (2, 3)  # Default risk-reward ratio for Buy\n",
    "    risk_reward_ratio_sell = (2, 3)  # Default risk-reward ratio for Sell\n",
    "    mean_candle_size = 0  # Mean candle size based on historical data\n",
    "\n",
    "    def init(self):\n",
    "        # Calculate mean candle size based on historical data\n",
    "        self.mean_candle_size = (self.data.High - self.data.Low).mean()\n",
    "\n",
    "    def next(self):\n",
    "        entry_price = self.data.Close[-1]\n",
    "        risk_part_buy, reward_part_buy = self.risk_reward_ratio_buy\n",
    "        risk_part_sell, reward_part_sell = self.risk_reward_ratio_sell\n",
    "\n",
    "        # Check if both Buy and Sell are predicted, in which case no trade should be taken\n",
    "        if self.data.prediction_buy[-1] == 1 and self.data.prediction_sell[-1] == 1:\n",
    "            print(f\"Skipping trade on {self.data.index[-1]} due to both Buy and Sell signals\")\n",
    "            return\n",
    "\n",
    "        # Buy signal\n",
    "        if self.data.prediction_buy[-1] == 1:\n",
    "            sl_price = entry_price - self.mean_candle_size * risk_part_buy\n",
    "            tp_price = entry_price + self.mean_candle_size * reward_part_buy\n",
    "            print(f\"Attempting to Buy on {self.data.index[-1]} at {entry_price} with SL={sl_price} TP={tp_price}\")\n",
    "            self.buy(sl=sl_price, tp=tp_price)\n",
    "\n",
    "        # Sell signal\n",
    "        elif self.data.prediction_sell[-1] == 1:\n",
    "            sl_price = entry_price + self.mean_candle_size * risk_part_sell\n",
    "            tp_price = entry_price - self.mean_candle_size * reward_part_sell\n",
    "            print(f\"Attempting to Sell on {self.data.index[-1]} at {entry_price} with SL={sl_price} TP={tp_price}\")\n",
    "            self.sell(sl=sl_price, tp=tp_price)\n",
    "\n",
    "\n",
    "# Function to perform backtesting and save stats/plot\n",
    "def run_backtest(ohlc_data, strategy_class, risk_reward_ratio_buy, risk_reward_ratio_sell, pair_name):\n",
    "    strategy_class.risk_reward_ratio_buy = risk_reward_ratio_buy  # Set specific risk-reward ratio for Buy\n",
    "    strategy_class.risk_reward_ratio_sell = risk_reward_ratio_sell  # Set specific risk-reward ratio for Sell\n",
    "    bt = Backtest(ohlc_data.set_index('time'), strategy_class, cash=10000, commission=.0003)\n",
    "    stats = bt.run()\n",
    "\n",
    "    # Generate and save the backtest plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bt.plot()  # This generates the plot using backtesting.py's internal plot function\n",
    "    plt.draw()  # Make sure the plot is rendered properly\n",
    "    plt.pause(0.1)  # Pause to ensure rendering before saving\n",
    "    plt.title(f'Backtest for {pair_name}')  # Add pair name to the title\n",
    "    plt.savefig(f'backtest_plot_{pair_name}.png')  # Save the plot manually using matplotlib\n",
    "    plt.close()  # Close the plot to avoid displaying it in the environment\n",
    "\n",
    "    # Save backtest stats as CSV\n",
    "    stats_df = pd.DataFrame([stats])\n",
    "    stats_df.to_csv(f'backtest_stats_{pair_name}.csv', index=False)\n",
    "\n",
    "    return stats\n",
    "\n",
    "# Main function to fetch OHLC data, align it with prediction data, and run backtest\n",
    "def main():\n",
    "    # Configuration for MetaTrader 5 connection\n",
    "    config = {\n",
    "        'login': 51988090,\n",
    "        'password': '1fMdV52$74EOcw',\n",
    "        'server': 'ICMarketsEU-Demo'\n",
    "    }\n",
    "\n",
    "    # Initialize MetaTrader 5 connection\n",
    "    init_mt5_connection(config['login'], config['password'], config['server'])\n",
    "\n",
    "    # Define the time period for backtesting\n",
    "    utc_from = datetime(2019, 12, 3, tzinfo=pytz.utc)\n",
    "    utc_to = datetime(2024, 10, 7, tzinfo=pytz.utc)\n",
    "\n",
    "    # Currency pair configurations\n",
    "    currency_pairs = {\n",
    "        'GBPUSD': {\n",
    "            'symbol': 'GBPUSD',\n",
    "            'timeframe': mt5.TIMEFRAME_D1,\n",
    "            'buy_prediction_file': 'GBPUSD_D1_3112_Buy.csv',\n",
    "            'sell_prediction_file': 'predictGBPUSD_D1_3112sell.csv',\n",
    "            'buy_risk_reward_ratio': (1, 2),  # GBPUSD Buy Risk-Reward Ratio\n",
    "            'sell_risk_reward_ratio': (1, 2),  # GBPUSD Sell Risk-Reward Ratio\n",
    "        },\n",
    "        'USDCAD': {\n",
    "            'symbol': 'USDCAD',\n",
    "            'timeframe': mt5.TIMEFRAME_D1,\n",
    "            'buy_prediction_file': 'predictUSDCAD_D1Buy.csv',\n",
    "            'sell_prediction_file': 'predictUSDCAD_D1Sell.csv',\n",
    "            'buy_risk_reward_ratio': (2, 3),  # USDCAD Buy Risk-Reward Ratio\n",
    "            'sell_risk_reward_ratio': (2, 3),  # USDCAD Sell Risk-Reward Ratio\n",
    "        },\n",
    "        'EURUSD': {\n",
    "            'symbol': 'EURUSD',\n",
    "            'timeframe': mt5.TIMEFRAME_D1,\n",
    "            'buy_prediction_file': 'predictEURUSD_D1_3112buy.csv',\n",
    "            'sell_prediction_file': 'predict_EURUSD_D1_3112_Sell.csv',\n",
    "            'buy_risk_reward_ratio': (2, 3),  # EURUSD Buy Risk-Reward Ratio\n",
    "            'sell_risk_reward_ratio': (1, 2),  # EURUSD Sell Risk-Reward Ratio\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Loop through each currency pair and perform backtest\n",
    "    for pair_name, pair_config in currency_pairs.items():\n",
    "        logging.info(f\"Processing {pair_name}...\")\n",
    "\n",
    "        # Fetch OHLC data\n",
    "        ohlc_data = fetch_ohlc_data(pair_config['symbol'], pair_config['timeframe'], utc_from, utc_to)\n",
    "        if ohlc_data is None:\n",
    "            logging.error(f\"Skipping {pair_name} due to missing OHLC data\")\n",
    "            continue\n",
    "\n",
    "        # Load and align data for both Buy and Sell predictions\n",
    "        ohlc_data_with_predictions = load_and_align_data(ohlc_data, pair_config['buy_prediction_file'], pair_config['sell_prediction_file'])\n",
    "        if ohlc_data_with_predictions is not None:\n",
    "            stats = run_backtest(ohlc_data_with_predictions, PredictionStrategy, pair_config['buy_risk_reward_ratio'], pair_config['sell_risk_reward_ratio'], pair_name)\n",
    "            print(f\"Backtest results for {pair_name}:\", stats)\n",
    "        else:\n",
    "            logging.error(f\"Skipping {pair_name} due to prediction data issue\")\n",
    "\n",
    "    # Shutdown MetaTrader 5 connection after backtesting\n",
    "    mt5.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f6f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
