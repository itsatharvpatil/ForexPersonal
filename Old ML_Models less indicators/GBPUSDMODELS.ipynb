{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from joblib import dump\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sum_fp = 0\n",
    "sum_tp = 0\n",
    "\n",
    "# TimeSeriesSplit for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Directory to save model and scaler\n",
    "os.makedirs('Dump_GBPUSD_D1_3112_Buy', exist_ok=True)\n",
    "\n",
    "# Initialise RandomForestClassifier with fixed hyperparameters\n",
    "rf_classifier_mt = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=40,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=0,\n",
    "    max_leaf_nodes=20,\n",
    "    bootstrap=True,\n",
    "    oob_score=True,\n",
    "    ccp_alpha=0,\n",
    "    class_weight={0: 10, 1: 15}\n",
    ")\n",
    "\n",
    "# Ensure the time series order is preserved in the split\n",
    "X = X_df.iloc[:, :-1].values\n",
    "y = X_df['b_flag'].values\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(X_df)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    # Train data\n",
    "    x_train, y_train = X[train_index], y[train_index]\n",
    "    # Test data\n",
    "    x_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "    # Scale Data\n",
    "    sc_mt = StandardScaler()\n",
    "    x_train = sc_mt.fit_transform(x_train)\n",
    "    x_test = sc_mt.transform(x_test)\n",
    "\n",
    "    # Save scaler\n",
    "    dump(sc_mt, f'GBPUSD_D1_3112_Buy/scaler_fold_{fold + 1}.joblib')\n",
    "\n",
    "    # Train Model\n",
    "    rf_classifier_mt.fit(x_train, y_train)\n",
    "\n",
    "    # Save the trained model\n",
    "    dump(rf_classifier_mt, f'GBPUSD_D1_3112_Buy/model_fold_{fold + 1}.joblib')\n",
    "\n",
    "    # Predict on training data\n",
    "    y_train_pred = rf_classifier_mt.predict(x_train)\n",
    "\n",
    "    print(\"Confusion Matrix (Training Data):\")\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    print(cm_train)\n",
    "\n",
    "    train_false_positives = cm_train[0][1]\n",
    "    train_true_positives = cm_train[1][1]\n",
    "\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    train_roc_auc = roc_auc_score(y_train, rf_classifier_mt.predict_proba(x_train)[:, 1])\n",
    "\n",
    "    print('Training Data Results:')\n",
    "    print('WIN/LOSS-Diff:', round(100 * (train_precision - BreakEvenRatio), 2), '%')\n",
    "    print('False Positives:', train_false_positives)\n",
    "    print('True Positives:', train_true_positives)\n",
    "    print('Precision:', train_precision)\n",
    "    print('Accuracy:', train_accuracy)\n",
    "    print('Recall:', train_recall)\n",
    "    print('F1 Score:', train_f1)\n",
    "    print('ROC AUC:', train_roc_auc)\n",
    "    print('Ratio Total:', round(100 * (train_true_positives / (train_false_positives + train_true_positives)), 2))\n",
    "    print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "    print('____________________________________________________________________________________________________________________________')\n",
    "\n",
    "    # Predict on testing data\n",
    "    y_test_pred = rf_classifier_mt.predict(x_test)\n",
    "\n",
    "    print(\"Confusion Matrix (Testing Data):\")\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "    print(cm_test)\n",
    "\n",
    "    test_false_positives = cm_test[0][1]\n",
    "    test_true_positives = cm_test[1][1]\n",
    "\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    test_roc_auc = roc_auc_score(y_test, rf_classifier_mt.predict_proba(x_test)[:, 1])\n",
    "\n",
    "    print('Testing Data Results:')\n",
    "    print('WIN/LOSS-Diff:', round(100 * (test_precision - BreakEvenRatio), 2), '%')\n",
    "    print('False Positives:', test_false_positives)\n",
    "    print('True Positives:', test_true_positives)\n",
    "    print('Precision:', test_precision)\n",
    "    print('Accuracy:', test_accuracy)\n",
    "    print('Recall:', test_recall)\n",
    "    print('F1 Score:', test_f1)\n",
    "    print('ROC AUC:', test_roc_auc)\n",
    "    print('Ratio Total:', round(100 * (test_true_positives / (test_false_positives + test_true_positives)), 2))\n",
    "    print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "    print('____________________________________________________________________________________________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "from joblib import dump\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sum_fp = 0\n",
    "sum_tp = 0\n",
    "\n",
    "# Ensure the time series order is preserved in the split\n",
    "split = int(0.80 * len(X_df))\n",
    "train_data, test_data = X_df.iloc[:split], X_df.iloc[split:]\n",
    "\n",
    "# Train data\n",
    "x_train = train_data.iloc[:, :-1].values\n",
    "y_train = train_data['b_flag'].values\n",
    "# Test data\n",
    "x_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data['b_flag'].values\n",
    "\n",
    "# Scale Data\n",
    "sc_mt = StandardScaler()\n",
    "x_train = sc_mt.fit_transform(x_train)\n",
    "x_test = sc_mt.transform(x_test)\n",
    "\n",
    "os.makedirs('Dump_GBPUSD_D1_3112_Buy', exist_ok=True)\n",
    "dump(sc_mt, 'Dump_GBPUSD_D1_3112_Buy/scaler.joblib')\n",
    "\n",
    "# Initialise RandomForestClassifier with fixed hyperparameters\n",
    "rf_classifier_mt = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "rf_classifier_mt.fit(x_train, y_train)\n",
    "\n",
    "dump(rf_classifier_mt, 'Dump_GBPUSD_D1_3112_Buy/model.joblib')\n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred = rf_classifier_mt.predict(x_train)\n",
    "\n",
    "print(\"Confusion Matrix (Training Data):\")\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "print(cm_train)\n",
    "\n",
    "train_false_positives = cm_train[0][1]\n",
    "train_true_positives = cm_train[1][1]\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train, rf_classifier_mt.predict_proba(x_train)[:, 1])\n",
    "\n",
    "print('Training Data Results:')\n",
    "print('WIN/LOSS-Diff:', round(100 * (train_precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', train_false_positives)\n",
    "print('True Positives:', train_true_positives)\n",
    "print('Precision:', train_precision)\n",
    "print('Accuracy:', train_accuracy)\n",
    "print('Recall:', train_recall)\n",
    "print('F1 Score:', train_f1)\n",
    "print('ROC AUC:', train_roc_auc)\n",
    "print('Ratio Total:', round(100 * (train_true_positives / (train_false_positives + train_true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n",
    "\n",
    "# Predict on testing data\n",
    "y_test_pred = rf_classifier_mt.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix (Testing Data):\")\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm_test)\n",
    "\n",
    "test_false_positives = cm_test[0][1]\n",
    "test_true_positives = cm_test[1][1]\n",
    "\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, rf_classifier_mt.predict_proba(x_test)[:, 1])\n",
    "\n",
    "print('Testing Data Results:')\n",
    "print('WIN/LOSS-Diff:', round(100 * (test_precision - BreakEvenRatio), 2), '%')\n",
    "print('False Positives:', test_false_positives)\n",
    "print('True Positives:', test_true_positives)\n",
    "print('Precision:', test_precision)\n",
    "print('Accuracy:', test_accuracy)\n",
    "print('Recall:', test_recall)\n",
    "print('F1 Score:', test_f1)\n",
    "print('ROC AUC:', test_roc_auc)\n",
    "print('Ratio Total:', round(100 * (test_true_positives / (test_false_positives + test_true_positives)), 2))\n",
    "print('BreakEvenRatio:', round(BreakEvenRatio, 2))\n",
    "print('____________________________________________________________________________________________________________________________')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
